{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AFzL-PCdJU8-"
      },
      "outputs": [],
      "source": [
        "%run ./AnnModel1.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2Koe2owaJcNY"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def multiple_main(epoch_count = 10, mb_size = 10, report=1, train_ratio = 0.6):\n",
        "    multiple_load_dataset()\n",
        "    init_param()\n",
        "    train_and_test(epoch_count,mb_size,report,train_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "msTkqcMMJeoP"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def multiple_load_dataset():\n",
        "    with open('./data/mulit_classification_data.csv') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)\n",
        "        rows = []\n",
        "        for row in csvreader:\n",
        "            rows.append(row)\n",
        "\n",
        "    global data, input_cnt, output_cnt\n",
        "\n",
        "    input_cnt, output_cnt = 27, 7\n",
        "    data = np.asarray(rows, dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PBzu6Z5DJrug"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def forward_postproc(y_hat, y_real):\n",
        "    entropy  = softmax_cross_entropy(y_real, y_hat)\n",
        "    loss     = np.mean(entropy)\n",
        "        \n",
        "    return loss, [y_real, y_hat, entropy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vCuGFYtWJj8K"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax_cross_entropy(y_real, y_hat):\n",
        "\n",
        "    probs = softmax(y_hat)\n",
        "    \n",
        "    #기존 확률값에 아주 작은 양수를 더해 log함수의 폭주 방지\n",
        "    return - np.sum(y_real * np.log(probs+1.0e-10), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BkQXypCdJoQc"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax(x):\n",
        "\n",
        "    max_elem = np.max(x, axis = 1)\n",
        "    \n",
        "    diff = (x.transpose() - max_elem).transpose()\n",
        "    exp = np.exp(diff)\n",
        "    \n",
        "    sum_exp = np.sum(exp, axis = 1)\n",
        "    \n",
        "    probs = (exp.transpose()/sum_exp).transpose()\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xv-4uAgGJkn5"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def backprop_postproc(aux_pp):\n",
        "    y_real, y_hat, entropy = aux_pp\n",
        "\n",
        "    g_loss_entropy = 1.0/np.prod(entropy.shape)\n",
        "    g_entropy_output = softmax_cross_entropy_with_derv(y_real,y_hat)\n",
        "    \n",
        "    G_output = g_entropy_output * g_loss_entropy \n",
        "    \n",
        "    return G_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y5Lr3TOgJtxd"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax_cross_entropy_with_derv(y_real,y_hat):\n",
        "    \n",
        "    return softmax(y_hat) - y_real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ty-DSGNNJ2kO"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def eval_accuracy(y_hat,y_real):\n",
        "    estimate = np.argmax(y_hat,axis=1)\n",
        "    answer = np.argmax(y_real,axis=1)\n",
        "    \n",
        "    correct = np.equal(estimate, answer)\n",
        "\n",
        "    return np.mean(correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1   : Train - Loss = 15.979, Accuracy = 0.306 / Test - Accuracy = 0.204\n",
            "Epoch 2   : Train - Loss = 15.741, Accuracy = 0.316 / Test - Accuracy = 0.239\n",
            "Epoch 3   : Train - Loss = 16.078, Accuracy = 0.302 / Test - Accuracy = 0.391\n",
            "Epoch 4   : Train - Loss = 15.483, Accuracy = 0.328 / Test - Accuracy = 0.337\n",
            "Epoch 5   : Train - Loss = 15.265, Accuracy = 0.337 / Test - Accuracy = 0.307\n",
            "Epoch 6   : Train - Loss = 14.907, Accuracy = 0.353 / Test - Accuracy = 0.396\n",
            "Epoch 7   : Train - Loss = 15.622, Accuracy = 0.322 / Test - Accuracy = 0.323\n",
            "Epoch 8   : Train - Loss = 15.245, Accuracy = 0.338 / Test - Accuracy = 0.287\n",
            "Epoch 9   : Train - Loss = 15.423, Accuracy = 0.330 / Test - Accuracy = 0.200\n",
            "Epoch 10   : Train - Loss = 15.265, Accuracy = 0.337 / Test - Accuracy = 0.410\n",
            "==============================  Final TEST  ==============================\n",
            "\n",
            "Final Accuracy = 0.410\n"
          ]
        }
      ],
      "source": [
        "# multiple_main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
