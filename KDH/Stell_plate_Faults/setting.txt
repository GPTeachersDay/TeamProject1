model = tf.keras.Sequential([
        tf.keras.layers.Dense(units=1024, activation='relu', input_shape=(len(X_train.keys()),), kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=7, activation='softmax') # 출력 유닛의 수를 클래스 수에 맞추고, softmax 활성화 함수를 사용
    ])

Test Loss: 1.101
Test Accuracy: 0.707 (과적합 작음)



model = tf.keras.Sequential([
        tf.keras.layers.Dense(units=1024, activation='relu', input_shape=(len(X_train.keys()),), kernel_regularizer=regularizers.l2(0.000)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.005)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.015)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.02)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.025)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.03)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.03)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=7, activation='softmax') # 출력 유닛의 수를 클래스 수에 맞추고, softmax 활성화 함수를 사용
    ])

Test Loss: 1.14
Test Accuracy: 0.771 (과적합 발생)



EDA


1. 상관계수가 낮은 6개 feature 제거

TypeOfSteel_A300         0.034799
Log_Y_Index             -0.012180
Y_Perimeter             -0.017472
SigmoidOfAreas          -0.019097
Luminosity_Index        -0.034650
TypeOfSteel_A400        -0.034799



2. 비슷한 feature중에 대표값만 선별

'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Log_X_Index', 'Log_Y_Index' 제거



3. 비슷한 feature 대표값 선별 및 통합

'Minimum_of_Luminosity' + 'Maximum_of_Luminosity' = 'Mean_of_Luminosity'
'X_Minimum' + 'X_Maximum' = 'X_Mean'
'Y_Minimum' + 'Y_Maximum' = 'Y_Mean'
'Log_X_Index', 'Log_Y_Index' 제거
'TypeOfSteel_A300' + 'TypeOfSteel_400', = 'TypeOfSteel'



4. 이상치 제거(조건에 해당하면 이상치)
'Pixels_Areas' > 35000
'X_Perimeter' > 2000
'Y_Perimeter' > 2500
'Sum_of_Luminosity' > 0.5e7



5. 이상치 제거하고 특성공학
Minimum_of_Luminosity' + 'Maximum_of_Luminosity' = 'Mean_of_Luminosity'
'X_Minimum' + 'X_Maximum' = 'X_Mean'
'Y_Minimum', Y_Maximum' 제거 (수치가 대체로 너무 작아서 영향이 적을 수 있음)
'Log_X_Index', 'Log_Y_Index' 제거
'TypeOfSteel_A300' + 'TypeOfSteel_400', = 'TypeOfSteel'



6. 관측치 범위가 큰 피처들 로그 스케일링
'Log_Pixels_Areas', 'Log_Sum_of_Luminosity'



7. 대표값 통합하지 않기


8. 7에서 'Log_X_Index', 'Log_Y_Index'도 포함