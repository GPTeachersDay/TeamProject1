{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 10) (836, 10) (3341,) (836,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_dataset(csv_path, TRAIN_RATIO=0.8):\n",
    "    \n",
    "    global X, y, X_train, X_test, y_train, y_test, df\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 성별 원핫 인코딩\n",
    "    df=pd.get_dummies(df,columns=['Sex'])\n",
    "    \n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop('Rings', axis=1)\n",
    "    y = df['Rings']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "csv_path = '../colabo/Data/Regression_data.csv'\n",
    "X_train, X_test, y_train, y_test = load_dataset(csv_path)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,) (37,)\n"
     ]
    }
   ],
   "source": [
    "# 전복 전체 무게가 살 + 내장 + 껍질보다 적게 나가는 경우는 말이 안됨\n",
    "body = X_train['Whole weight'] - (X_train['Shucked weight'] + X_train['Viscera weight'] + X_train['Shell weight'])\n",
    "X_train['body'] = body\n",
    "\n",
    "index = X_train[X_train['body'] < 0].index\n",
    "\n",
    "body = X_test['Whole weight'] - (X_test['Shucked weight'] + X_test['Viscera weight'] + X_test['Shell weight'])\n",
    "X_test['body'] = body\n",
    "\n",
    "index2 = X_test[X_test['body'] < 0].index\n",
    "\n",
    "print(index.shape, index2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(index, axis=0, inplace=True)\n",
    "X_test.drop(index2, axis=0, inplace=True)\n",
    "y_train.drop(index, axis=0, inplace=True)\n",
    "y_test.drop(index2, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#2. 샘플 노이즈 추가 (기존 데이터셋에 완전히 랜덤한 노이즈 샘플을 추가하는 방법)\\nn_samples = len(df)\\nn_features = len(df.columns)\\n\\n# 연속형 특성\\ncontinuous_columns = ['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\\ncontinuous_noise_samples = np.zeros((n_samples, len(continuous_columns))) # 노이즈 샘플 초기화\\nfor i, column in enumerate(continuous_columns):\\n    min_val = df[column].min() # df[column]의 최소값\\n    max_val = df[column].max() # df[column]의 최대값\\n    noise = np.random.uniform(min_val, max_val, size=n_samples) # 최소값과 최대값 사이로 노이즈 값 생성\\n    continuous_noise_samples[:, i] = noise # 초기화 해놓은 샘플 배열에 노이즈 추가\\n\\n# 범주형 특성\\ncategorical_columns = ['Sex_F', 'Sex_M', 'Sex_I']\\ncategorical_noise_samples = np.zeros((n_samples, len(categorical_columns)))\\nfor i, column in enumerate(categorical_columns):\\n    # 원본 데이터 분포에 기반하여 랜덤 카테고리 생성\\n    probabilities = df[column].value_counts(normalize=True).values # 원본 데이터 분포 확인\\n    categories = np.random.choice([0, 1], size=n_samples, p=probabilities)\\n    categorical_noise_samples[:, i] = categories\\n\\n# 연속형 특성과 범주형 특성 합침\\nnoise_samples = np.hstack([continuous_noise_samples, categorical_noise_samples])\\n\\n# 데이터 프레임으로 타입 변경 후 원본 데이터에 추가\\nnoise_df = pd.DataFrame(noise_samples, columns=df.columns)\\naugmented_df = pd.concat([df, noise_df])\\n\\naugmented_df.shape\\n\\n# 학습 데이터 분리\\nX = augmented_df.drop('Rings', axis=1)\\ny = augmented_df['Rings']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 83)\\n\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#2. 샘플 노이즈 추가 (기존 데이터셋에 완전히 랜덤한 노이즈 샘플을 추가하는 방법)\n",
    "n_samples = len(df)\n",
    "n_features = len(df.columns)\n",
    "\n",
    "# 연속형 특성\n",
    "continuous_columns = ['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "continuous_noise_samples = np.zeros((n_samples, len(continuous_columns))) # 노이즈 샘플 초기화\n",
    "for i, column in enumerate(continuous_columns):\n",
    "    min_val = df[column].min() # df[column]의 최소값\n",
    "    max_val = df[column].max() # df[column]의 최대값\n",
    "    noise = np.random.uniform(min_val, max_val, size=n_samples) # 최소값과 최대값 사이로 노이즈 값 생성\n",
    "    continuous_noise_samples[:, i] = noise # 초기화 해놓은 샘플 배열에 노이즈 추가\n",
    "\n",
    "# 범주형 특성\n",
    "categorical_columns = ['Sex_F', 'Sex_M', 'Sex_I']\n",
    "categorical_noise_samples = np.zeros((n_samples, len(categorical_columns)))\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    # 원본 데이터 분포에 기반하여 랜덤 카테고리 생성\n",
    "    probabilities = df[column].value_counts(normalize=True).values # 원본 데이터 분포 확인\n",
    "    categories = np.random.choice([0, 1], size=n_samples, p=probabilities)\n",
    "    categorical_noise_samples[:, i] = categories\n",
    "\n",
    "# 연속형 특성과 범주형 특성 합침\n",
    "noise_samples = np.hstack([continuous_noise_samples, categorical_noise_samples])\n",
    "\n",
    "# 데이터 프레임으로 타입 변경 후 원본 데이터에 추가\n",
    "noise_df = pd.DataFrame(noise_samples, columns=df.columns)\n",
    "augmented_df = pd.concat([df, noise_df])\n",
    "\n",
    "augmented_df.shape\n",
    "\n",
    "# 학습 데이터 분리\n",
    "X = augmented_df.drop('Rings', axis=1)\n",
    "y = augmented_df['Rings']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 83)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train 껍질의 넓이 ( a * b * π)\n",
    "area = 0.5 * X_train['Length'] * 0.5 * X_train['Diameter'] * np.pi\n",
    "X_train['Area'] = area\n",
    "\n",
    "# test 껍질의 넓이 \n",
    "area2 = 0.5 * X_test['Length'] * 0.5 * X_test['Diameter'] * np.pi\n",
    "X_test['Area'] = area2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>1.660072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>1.572837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.769361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>1.277329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.974085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M    body      Area  Perimeter  \n",
       "461          0.265      1      0      0  0.1160  0.213648   1.660072  \n",
       "2835         0.250      0      0      1  0.0435  0.188024   1.572837  \n",
       "1378         0.354      1      0      0  0.0295  0.243473   1.769361  \n",
       "2569         0.111      0      1      0  0.0190  0.124643   1.277329  \n",
       "369          0.470      1      0      0  0.2700  0.303478   1.974085  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter = np.pi * np.sqrt(0.5 * ((X_train['Length'] ** 2) + (X_train['Diameter'] ** 2)))\n",
    "X_train['Perimeter'] = perimeter\n",
    "\n",
    "# test 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter2 = np.pi * np.sqrt(0.5 * ((X_test['Length'] ** 2) + (X_test['Diameter'] ** 2)))\n",
    "X_test['Perimeter'] = perimeter2\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell weight      0.619796\n",
      "Diameter          0.559512\n",
      "Perimeter         0.548978\n",
      "Length            0.539317\n",
      "Height            0.534439\n",
      "body              0.533203\n",
      "Area              0.532949\n",
      "Whole weight      0.525487\n",
      "Viscera weight    0.489945\n",
      "Shucked weight    0.403014\n",
      "Sex_F             0.242466\n",
      "Sex_M             0.178722\n",
      "Sex_I            -0.431255\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟값과 각 변수들 간의 상관관계\n",
    "co = X_train.corrwith(y_train)\n",
    "\n",
    "# 상관계수를 내림차순으로 정리\n",
    "print(co.sort_values(ascending=False))\n",
    "\n",
    "# 절대값\n",
    "co_abs = abs(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>Area</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Sex_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.572837</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.769361</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1.277329</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.974085</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height      Area  \\\n",
       "461          0.265     0.465   1.660072   0.585   0.170  0.213648   \n",
       "2835         0.250     0.420   1.572837   0.570   0.140  0.188024   \n",
       "1378         0.354     0.500   1.769361   0.620   0.150  0.243473   \n",
       "2569         0.111     0.345   1.277329   0.460   0.115  0.124643   \n",
       "369          0.470     0.560   1.974085   0.690   0.215  0.303478   \n",
       "\n",
       "      Viscera weight  Shucked weight  Whole weight  Sex_F  Sex_M  Sex_I  \n",
       "461           0.2240          0.3865        0.9915      1      0      0  \n",
       "2835          0.1650          0.4160        0.8745      0      1      0  \n",
       "1378          0.3135          0.5960        1.2930      1      0      0  \n",
       "2569          0.1020          0.1895        0.4215      0      0      1  \n",
       "369           0.2990          0.6800        1.7190      1      0      0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'Area', 'Viscera weight', 'Shucked weight', 'Whole weight', 'Sex_F', 'Sex_M', 'Sex_I']\n",
    "X_train_2 = X_train[columns]\n",
    "X_test_2 = X_test[columns]\n",
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일링할 피처 선택\n",
    "scaling_features = columns[:-3]  # 원핫인코딩되지 않은 연속형 또는 순서형 변수들\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = X_train_2.copy()  # 원본 데이터 복사\n",
    "X_test_scaled = X_test_2.copy()    # 원본 데이터 복사\n",
    "X_train_scaled[scaling_features] = scaler.fit_transform(X_train_2[scaling_features])\n",
    "X_test_scaled[scaling_features] = scaler.transform(X_test_2[scaling_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 노이즈 데이터 추가\\n# 1. 특성 노이즈 추가 (기존 데이터셋의 특성들에 랜덤 노이즈를 직접 추가하는 방법)\\n# 노이즈 팩터 설정\\nnoise_factor = 0.001\\nnumeric_columns = ['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'Area', 'Viscera weight', 'Shucked weight', 'Whole weight'] # 수치형 데이터에만 적용해야 함\\n\\n# feature에 노이즈 적용\\nX_train_noisy = X_train_scaled.copy()\\nX_train_noisy[numeric_columns] = X_train_noisy[numeric_columns] + noise_factor * np.random.randn(*X_train_noisy[numeric_columns].shape)\\n\\n# 노이즈 값을 원본 데이터의 최솟값과 최댓값 사이로 제한\\nfor col in numeric_columns:\\n    X_train_noisy[col] = X_train_noisy[col] + noise_factor * np.random.randn(*X_train_noisy[col].shape)\\n    X_train_noisy[col] = np.clip(X_train_noisy[col], X_train[col].min(), X_train[col].max())\\n\\nX_train_noisy\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 노이즈 데이터 추가\n",
    "# 1. 특성 노이즈 추가 (기존 데이터셋의 특성들에 랜덤 노이즈를 직접 추가하는 방법)\n",
    "# 노이즈 팩터 설정\n",
    "noise_factor = 0.001\n",
    "numeric_columns = ['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'Area', 'Viscera weight', 'Shucked weight', 'Whole weight'] # 수치형 데이터에만 적용해야 함\n",
    "\n",
    "# feature에 노이즈 적용\n",
    "X_train_noisy = X_train_scaled.copy()\n",
    "X_train_noisy[numeric_columns] = X_train_noisy[numeric_columns] + noise_factor * np.random.randn(*X_train_noisy[numeric_columns].shape)\n",
    "\n",
    "# 노이즈 값을 원본 데이터의 최솟값과 최댓값 사이로 제한\n",
    "for col in numeric_columns:\n",
    "    X_train_noisy[col] = X_train_noisy[col] + noise_factor * np.random.randn(*X_train_noisy[col].shape)\n",
    "    X_train_noisy[col] = np.clip(X_train_noisy[col], X_train[col].min(), X_train[col].max())\n",
    "\n",
    "X_train_noisy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 평가 지표 클래스\n",
    "import tensorflow as tf\n",
    "\n",
    "class EvalAccuracy(tf.keras.metrics.Metric): # TensorFlow의 Metric 클래스를 상속 받음\n",
    "\n",
    "    def __init__(self, name=\"eval_accuracy\", **kwargs): # 부모 클래스의 __init__() 메소드를 호출하여 필요한 초기화를 수행\n",
    "        super(EvalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.correct = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "        # add_weight() 메소드를 사용하여 평가 지표를 계산하는데 필요한 변수를 생성(각 배치에서의 평가 결과를 누적하기 위해)\n",
    "        # add_weight() 는 텐서플로우 Layer 클래스의 메서드(새로운 가중치를 추가하는 기능, 여기서는 평가 지표를 계산하는 데 사용되는 일종의 내부 변수를 의미)\n",
    "        # 이 구문이 실행되면, EvalAccuracy 인스턴스는 새로운 가중치를 추가하고 그 가중치를 self.correct에 저장한다.\n",
    "        # 이 self.correct는 update_state() 메서드에서 업데이트되며, '현재까지 처리한 모든 배치에 대한 평가 지표의 평균을 저장'한다.\n",
    "\n",
    "    def update_state(self, y_true, y_predict, sample_weight=None):\n",
    "        value = tf.abs((y_predict - y_true) / y_true)\n",
    "        self.correct.assign(tf.reduce_mean(value)) # 오차율을 계산해서 correct 변수에 누적한 후, assign() 메소드를 사용하여 correct 변수의 값을 업데이트\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - self.correct\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 에포크마다 평가 지표 초기화\n",
    "        self.correct.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346,305\n",
      "Trainable params: 346,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 베이스모델\n",
    "import numpy as np\n",
    "\n",
    "def Base_Model(LEARNING_RATE=0.01):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    global X, y, X_train, X_test, y_train, y_test, df\n",
    "    \n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, activation='relu', input_shape=(len(X_train_2.keys()),)),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, input_shape=(len(X_train_2.keys()),)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=512),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.01,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.99,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[EvalAccuracy()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = Base_Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 33ms/step - loss: 3.1530 - eval_accuracy: 0.8718 - val_loss: 4.7379 - val_eval_accuracy: 0.8401 - lr: 4.0000e-04\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1573 - eval_accuracy: 0.8736 - val_loss: 4.7426 - val_eval_accuracy: 0.8372 - lr: 4.0000e-04\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.1633 - eval_accuracy: 0.8605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1633 - eval_accuracy: 0.8605 - val_loss: 4.7998 - val_eval_accuracy: 0.8354 - lr: 4.0000e-04\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1498 - eval_accuracy: 0.8775 - val_loss: 4.7419 - val_eval_accuracy: 0.8396 - lr: 4.0000e-04\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1669 - eval_accuracy: 0.8609 - val_loss: 4.7301 - val_eval_accuracy: 0.8400 - lr: 4.0000e-04\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1338 - eval_accuracy: 0.8694 - val_loss: 4.7493 - val_eval_accuracy: 0.8409 - lr: 4.0000e-04\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1565 - eval_accuracy: 0.8756 - val_loss: 4.7070 - val_eval_accuracy: 0.8413 - lr: 4.0000e-04\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1554 - eval_accuracy: 0.8877 - val_loss: 4.7640 - val_eval_accuracy: 0.8380 - lr: 4.0000e-04\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1475 - eval_accuracy: 0.8674 - val_loss: 4.8532 - val_eval_accuracy: 0.8368 - lr: 4.0000e-04\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.1696 - eval_accuracy: 0.8846 - val_loss: 4.7932 - val_eval_accuracy: 0.8380 - lr: 4.0000e-04\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1426 - eval_accuracy: 0.8688 - val_loss: 4.7124 - val_eval_accuracy: 0.8417 - lr: 4.0000e-04\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1883 - eval_accuracy: 0.8643 - val_loss: 4.7574 - val_eval_accuracy: 0.8376 - lr: 4.0000e-04\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1595 - eval_accuracy: 0.8739 - val_loss: 4.7484 - val_eval_accuracy: 0.8392 - lr: 4.0000e-04\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1514 - eval_accuracy: 0.8586 - val_loss: 4.8093 - val_eval_accuracy: 0.8363 - lr: 4.0000e-04\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1371 - eval_accuracy: 0.8808 - val_loss: 4.7830 - val_eval_accuracy: 0.8408 - lr: 4.0000e-04\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1432 - eval_accuracy: 0.8961 - val_loss: 4.8436 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.2082 - eval_accuracy: 0.8677 - val_loss: 4.7798 - val_eval_accuracy: 0.8401 - lr: 4.0000e-04\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1745 - eval_accuracy: 0.8800 - val_loss: 4.8426 - val_eval_accuracy: 0.8387 - lr: 4.0000e-04\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1693 - eval_accuracy: 0.8672 - val_loss: 4.8880 - val_eval_accuracy: 0.8363 - lr: 4.0000e-04\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1701 - eval_accuracy: 0.8731 - val_loss: 4.7697 - val_eval_accuracy: 0.8397 - lr: 4.0000e-04\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1474 - eval_accuracy: 0.8761 - val_loss: 4.6901 - val_eval_accuracy: 0.8413 - lr: 4.0000e-04\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1567 - eval_accuracy: 0.8690 - val_loss: 4.7939 - val_eval_accuracy: 0.8359 - lr: 4.0000e-04\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2179 - eval_accuracy: 0.8707 - val_loss: 4.8024 - val_eval_accuracy: 0.8378 - lr: 4.0000e-04\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.2026 - eval_accuracy: 0.8736 - val_loss: 4.7849 - val_eval_accuracy: 0.8392 - lr: 4.0000e-04\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1545 - eval_accuracy: 0.8479 - val_loss: 4.8552 - val_eval_accuracy: 0.8365 - lr: 4.0000e-04\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.1220 - eval_accuracy: 0.8750 - val_loss: 4.7556 - val_eval_accuracy: 0.8449 - lr: 4.0000e-04\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1584 - eval_accuracy: 0.8801 - val_loss: 4.8963 - val_eval_accuracy: 0.8362 - lr: 4.0000e-04\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1558 - eval_accuracy: 0.8629 - val_loss: 4.7785 - val_eval_accuracy: 0.8424 - lr: 4.0000e-04\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1356 - eval_accuracy: 0.8536 - val_loss: 4.7570 - val_eval_accuracy: 0.8394 - lr: 4.0000e-04\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1120 - eval_accuracy: 0.8740 - val_loss: 4.8356 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1149 - eval_accuracy: 0.8822 - val_loss: 4.8204 - val_eval_accuracy: 0.8411 - lr: 4.0000e-04\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1210 - eval_accuracy: 0.8794 - val_loss: 4.8964 - val_eval_accuracy: 0.8359 - lr: 4.0000e-04\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1130 - eval_accuracy: 0.8478 - val_loss: 4.7785 - val_eval_accuracy: 0.8399 - lr: 4.0000e-04\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1266 - eval_accuracy: 0.8674 - val_loss: 4.8021 - val_eval_accuracy: 0.8395 - lr: 4.0000e-04\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1364 - eval_accuracy: 0.8737 - val_loss: 4.8181 - val_eval_accuracy: 0.8423 - lr: 4.0000e-04\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1379 - eval_accuracy: 0.8770 - val_loss: 4.8878 - val_eval_accuracy: 0.8383 - lr: 4.0000e-04\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1466 - eval_accuracy: 0.8751 - val_loss: 4.8066 - val_eval_accuracy: 0.8404 - lr: 4.0000e-04\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1183 - eval_accuracy: 0.8717 - val_loss: 4.8566 - val_eval_accuracy: 0.8394 - lr: 4.0000e-04\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1071 - eval_accuracy: 0.8771 - val_loss: 4.9398 - val_eval_accuracy: 0.8343 - lr: 4.0000e-04\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1221 - eval_accuracy: 0.8748 - val_loss: 4.8657 - val_eval_accuracy: 0.8388 - lr: 4.0000e-04\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1405 - eval_accuracy: 0.8958 - val_loss: 4.8939 - val_eval_accuracy: 0.8341 - lr: 4.0000e-04\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0935 - eval_accuracy: 0.8675 - val_loss: 4.7560 - val_eval_accuracy: 0.8422 - lr: 4.0000e-04\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1622 - eval_accuracy: 0.8834 - val_loss: 4.8962 - val_eval_accuracy: 0.8373 - lr: 4.0000e-04\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1220 - eval_accuracy: 0.8716 - val_loss: 4.8586 - val_eval_accuracy: 0.8388 - lr: 4.0000e-04\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1351 - eval_accuracy: 0.8651 - val_loss: 4.8664 - val_eval_accuracy: 0.8350 - lr: 4.0000e-04\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.2412 - eval_accuracy: 0.8710 - val_loss: 4.8287 - val_eval_accuracy: 0.8383 - lr: 4.0000e-04\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1341 - eval_accuracy: 0.8644 - val_loss: 4.8598 - val_eval_accuracy: 0.8401 - lr: 4.0000e-04\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1232 - eval_accuracy: 0.8694 - val_loss: 4.8681 - val_eval_accuracy: 0.8343 - lr: 4.0000e-04\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1190 - eval_accuracy: 0.8703 - val_loss: 4.8477 - val_eval_accuracy: 0.8341 - lr: 4.0000e-04\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.1693 - eval_accuracy: 0.8680 - val_loss: 4.8072 - val_eval_accuracy: 0.8412 - lr: 4.0000e-04\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1782 - eval_accuracy: 0.8805 - val_loss: 4.8592 - val_eval_accuracy: 0.8418 - lr: 4.0000e-04\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1469 - eval_accuracy: 0.8705 - val_loss: 4.9126 - val_eval_accuracy: 0.8360 - lr: 4.0000e-04\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1269 - eval_accuracy: 0.8647 - val_loss: 4.8410 - val_eval_accuracy: 0.8399 - lr: 4.0000e-04\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1155 - eval_accuracy: 0.8794 - val_loss: 4.9111 - val_eval_accuracy: 0.8357 - lr: 4.0000e-04\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1075 - eval_accuracy: 0.8933 - val_loss: 4.7846 - val_eval_accuracy: 0.8440 - lr: 4.0000e-04\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1013 - eval_accuracy: 0.8747 - val_loss: 4.9663 - val_eval_accuracy: 0.8351 - lr: 4.0000e-04\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1131 - eval_accuracy: 0.8731 - val_loss: 4.8618 - val_eval_accuracy: 0.8383 - lr: 4.0000e-04\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1401 - eval_accuracy: 0.8751 - val_loss: 4.9328 - val_eval_accuracy: 0.8327 - lr: 4.0000e-04\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1012 - eval_accuracy: 0.8673 - val_loss: 4.9205 - val_eval_accuracy: 0.8366 - lr: 4.0000e-04\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0908 - eval_accuracy: 0.8758 - val_loss: 4.8791 - val_eval_accuracy: 0.8391 - lr: 4.0000e-04\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0841 - eval_accuracy: 0.9065 - val_loss: 4.9121 - val_eval_accuracy: 0.8361 - lr: 4.0000e-04\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0881 - eval_accuracy: 0.8442 - val_loss: 4.8857 - val_eval_accuracy: 0.8389 - lr: 4.0000e-04\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1029 - eval_accuracy: 0.8727 - val_loss: 4.9442 - val_eval_accuracy: 0.8358 - lr: 4.0000e-04\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1481 - eval_accuracy: 0.8751 - val_loss: 4.8762 - val_eval_accuracy: 0.8423 - lr: 4.0000e-04\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1160 - eval_accuracy: 0.8872 - val_loss: 4.9575 - val_eval_accuracy: 0.8347 - lr: 4.0000e-04\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1420 - eval_accuracy: 0.8778 - val_loss: 4.8647 - val_eval_accuracy: 0.8405 - lr: 4.0000e-04\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2199 - eval_accuracy: 0.8785 - val_loss: 4.8533 - val_eval_accuracy: 0.8390 - lr: 4.0000e-04\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1873 - eval_accuracy: 0.8689 - val_loss: 4.9447 - val_eval_accuracy: 0.8326 - lr: 4.0000e-04\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1293 - eval_accuracy: 0.8911 - val_loss: 4.8563 - val_eval_accuracy: 0.8408 - lr: 4.0000e-04\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1169 - eval_accuracy: 0.8483 - val_loss: 4.9294 - val_eval_accuracy: 0.8344 - lr: 4.0000e-04\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0890 - eval_accuracy: 0.8489 - val_loss: 4.8502 - val_eval_accuracy: 0.8423 - lr: 4.0000e-04\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1071 - eval_accuracy: 0.8962 - val_loss: 4.9082 - val_eval_accuracy: 0.8375 - lr: 4.0000e-04\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0824 - eval_accuracy: 0.8726 - val_loss: 4.8298 - val_eval_accuracy: 0.8398 - lr: 4.0000e-04\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0677 - eval_accuracy: 0.8628 - val_loss: 4.9096 - val_eval_accuracy: 0.8365 - lr: 4.0000e-04\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0663 - eval_accuracy: 0.8662 - val_loss: 4.8916 - val_eval_accuracy: 0.8373 - lr: 4.0000e-04\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0688 - eval_accuracy: 0.8731 - val_loss: 4.8898 - val_eval_accuracy: 0.8364 - lr: 4.0000e-04\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0712 - eval_accuracy: 0.8736 - val_loss: 4.8995 - val_eval_accuracy: 0.8371 - lr: 4.0000e-04\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0786 - eval_accuracy: 0.8746 - val_loss: 4.9563 - val_eval_accuracy: 0.8391 - lr: 4.0000e-04\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0999 - eval_accuracy: 0.8390 - val_loss: 4.9574 - val_eval_accuracy: 0.8372 - lr: 4.0000e-04\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0748 - eval_accuracy: 0.8787 - val_loss: 4.8774 - val_eval_accuracy: 0.8411 - lr: 4.0000e-04\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0680 - eval_accuracy: 0.8618 - val_loss: 4.9086 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0961 - eval_accuracy: 0.8884 - val_loss: 4.9421 - val_eval_accuracy: 0.8373 - lr: 4.0000e-04\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0873 - eval_accuracy: 0.8655 - val_loss: 4.9011 - val_eval_accuracy: 0.8390 - lr: 4.0000e-04\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1016 - eval_accuracy: 0.8707 - val_loss: 5.0164 - val_eval_accuracy: 0.8366 - lr: 4.0000e-04\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0958 - eval_accuracy: 0.8804 - val_loss: 4.9391 - val_eval_accuracy: 0.8391 - lr: 4.0000e-04\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1045 - eval_accuracy: 0.8807 - val_loss: 4.9069 - val_eval_accuracy: 0.8374 - lr: 4.0000e-04\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0952 - eval_accuracy: 0.8694 - val_loss: 4.9377 - val_eval_accuracy: 0.8379 - lr: 4.0000e-04\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0792 - eval_accuracy: 0.8680 - val_loss: 4.9615 - val_eval_accuracy: 0.8392 - lr: 4.0000e-04\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0765 - eval_accuracy: 0.8510 - val_loss: 4.9857 - val_eval_accuracy: 0.8375 - lr: 4.0000e-04\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0995 - eval_accuracy: 0.8515 - val_loss: 4.9197 - val_eval_accuracy: 0.8368 - lr: 4.0000e-04\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1237 - eval_accuracy: 0.8809 - val_loss: 4.9072 - val_eval_accuracy: 0.8372 - lr: 4.0000e-04\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1079 - eval_accuracy: 0.8818 - val_loss: 4.9080 - val_eval_accuracy: 0.8416 - lr: 4.0000e-04\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1198 - eval_accuracy: 0.8527 - val_loss: 5.0488 - val_eval_accuracy: 0.8336 - lr: 4.0000e-04\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1478 - eval_accuracy: 0.8816 - val_loss: 4.9163 - val_eval_accuracy: 0.8412 - lr: 4.0000e-04\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1189 - eval_accuracy: 0.8638 - val_loss: 4.8798 - val_eval_accuracy: 0.8420 - lr: 4.0000e-04\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0814 - eval_accuracy: 0.8625 - val_loss: 4.9400 - val_eval_accuracy: 0.8391 - lr: 4.0000e-04\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0828 - eval_accuracy: 0.8848 - val_loss: 4.9635 - val_eval_accuracy: 0.8377 - lr: 4.0000e-04\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0855 - eval_accuracy: 0.8516 - val_loss: 4.9576 - val_eval_accuracy: 0.8383 - lr: 4.0000e-04\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0638 - eval_accuracy: 0.8968 - val_loss: 4.9914 - val_eval_accuracy: 0.8410 - lr: 4.0000e-04\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0889 - eval_accuracy: 0.8810 - val_loss: 5.0861 - val_eval_accuracy: 0.8361 - lr: 4.0000e-04\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0743 - eval_accuracy: 0.8745 - val_loss: 4.9728 - val_eval_accuracy: 0.8391 - lr: 4.0000e-04\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0875 - eval_accuracy: 0.8670 - val_loss: 4.9418 - val_eval_accuracy: 0.8376 - lr: 4.0000e-04\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0994 - eval_accuracy: 0.8748 - val_loss: 5.0330 - val_eval_accuracy: 0.8378 - lr: 4.0000e-04\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0804 - eval_accuracy: 0.8786 - val_loss: 5.0624 - val_eval_accuracy: 0.8369 - lr: 4.0000e-04\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0750 - eval_accuracy: 0.8676 - val_loss: 5.0512 - val_eval_accuracy: 0.8384 - lr: 4.0000e-04\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0598 - eval_accuracy: 0.8580 - val_loss: 5.0503 - val_eval_accuracy: 0.8396 - lr: 4.0000e-04\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0994 - eval_accuracy: 0.8850 - val_loss: 5.0882 - val_eval_accuracy: 0.8338 - lr: 4.0000e-04\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1330 - eval_accuracy: 0.8403 - val_loss: 4.9586 - val_eval_accuracy: 0.8429 - lr: 4.0000e-04\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.2306 - eval_accuracy: 0.8799 - val_loss: 4.9875 - val_eval_accuracy: 0.8369 - lr: 4.0000e-04\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.2948 - eval_accuracy: 0.8679 - val_loss: 5.0674 - val_eval_accuracy: 0.8350 - lr: 4.0000e-04\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1163 - eval_accuracy: 0.8611 - val_loss: 4.9870 - val_eval_accuracy: 0.8411 - lr: 4.0000e-04\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1100 - eval_accuracy: 0.8596 - val_loss: 5.1299 - val_eval_accuracy: 0.8330 - lr: 4.0000e-04\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1253 - eval_accuracy: 0.8717 - val_loss: 4.9402 - val_eval_accuracy: 0.8417 - lr: 4.0000e-04\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0837 - eval_accuracy: 0.8670 - val_loss: 5.0352 - val_eval_accuracy: 0.8396 - lr: 4.0000e-04\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0613 - eval_accuracy: 0.8913 - val_loss: 5.0255 - val_eval_accuracy: 0.8356 - lr: 4.0000e-04\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0598 - eval_accuracy: 0.8633 - val_loss: 4.9545 - val_eval_accuracy: 0.8382 - lr: 4.0000e-04\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0642 - eval_accuracy: 0.8476 - val_loss: 4.9932 - val_eval_accuracy: 0.8387 - lr: 4.0000e-04\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0372 - eval_accuracy: 0.8583 - val_loss: 5.0535 - val_eval_accuracy: 0.8380 - lr: 4.0000e-04\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0545 - eval_accuracy: 0.8925 - val_loss: 4.9965 - val_eval_accuracy: 0.8389 - lr: 4.0000e-04\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0648 - eval_accuracy: 0.8955 - val_loss: 5.0174 - val_eval_accuracy: 0.8377 - lr: 4.0000e-04\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0497 - eval_accuracy: 0.8684 - val_loss: 5.0048 - val_eval_accuracy: 0.8376 - lr: 4.0000e-04\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0345 - eval_accuracy: 0.8631 - val_loss: 5.0021 - val_eval_accuracy: 0.8374 - lr: 4.0000e-04\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0511 - eval_accuracy: 0.8752 - val_loss: 5.0102 - val_eval_accuracy: 0.8364 - lr: 4.0000e-04\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0384 - eval_accuracy: 0.8760 - val_loss: 5.0351 - val_eval_accuracy: 0.8364 - lr: 4.0000e-04\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0629 - eval_accuracy: 0.8681 - val_loss: 5.0370 - val_eval_accuracy: 0.8354 - lr: 4.0000e-04\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0849 - eval_accuracy: 0.8872 - val_loss: 4.9790 - val_eval_accuracy: 0.8392 - lr: 4.0000e-04\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0609 - eval_accuracy: 0.8882 - val_loss: 5.0330 - val_eval_accuracy: 0.8366 - lr: 4.0000e-04\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0410 - eval_accuracy: 0.8545 - val_loss: 5.1200 - val_eval_accuracy: 0.8362 - lr: 4.0000e-04\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0405 - eval_accuracy: 0.8851 - val_loss: 5.0813 - val_eval_accuracy: 0.8390 - lr: 4.0000e-04\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0300 - eval_accuracy: 0.8832 - val_loss: 5.0829 - val_eval_accuracy: 0.8367 - lr: 4.0000e-04\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0337 - eval_accuracy: 0.8786 - val_loss: 5.0530 - val_eval_accuracy: 0.8374 - lr: 4.0000e-04\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0732 - eval_accuracy: 0.8898 - val_loss: 5.0309 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0766 - eval_accuracy: 0.8483 - val_loss: 5.0578 - val_eval_accuracy: 0.8356 - lr: 4.0000e-04\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0476 - eval_accuracy: 0.8769 - val_loss: 5.0169 - val_eval_accuracy: 0.8374 - lr: 4.0000e-04\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0573 - eval_accuracy: 0.8752 - val_loss: 5.0760 - val_eval_accuracy: 0.8358 - lr: 4.0000e-04\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0597 - eval_accuracy: 0.8486 - val_loss: 5.0703 - val_eval_accuracy: 0.8387 - lr: 4.0000e-04\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0487 - eval_accuracy: 0.8888 - val_loss: 5.0087 - val_eval_accuracy: 0.8363 - lr: 4.0000e-04\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0497 - eval_accuracy: 0.8718 - val_loss: 4.9923 - val_eval_accuracy: 0.8379 - lr: 4.0000e-04\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0728 - eval_accuracy: 0.8860 - val_loss: 5.0809 - val_eval_accuracy: 0.8365 - lr: 4.0000e-04\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0581 - eval_accuracy: 0.8729 - val_loss: 5.0335 - val_eval_accuracy: 0.8382 - lr: 4.0000e-04\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0260 - eval_accuracy: 0.8785 - val_loss: 5.1387 - val_eval_accuracy: 0.8342 - lr: 4.0000e-04\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0406 - eval_accuracy: 0.8726 - val_loss: 4.9904 - val_eval_accuracy: 0.8403 - lr: 4.0000e-04\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0478 - eval_accuracy: 0.8770 - val_loss: 5.0756 - val_eval_accuracy: 0.8366 - lr: 4.0000e-04\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0313 - eval_accuracy: 0.8771 - val_loss: 5.0562 - val_eval_accuracy: 0.8375 - lr: 4.0000e-04\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0215 - eval_accuracy: 0.8672 - val_loss: 5.0103 - val_eval_accuracy: 0.8377 - lr: 4.0000e-04\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0147 - eval_accuracy: 0.8943 - val_loss: 5.1425 - val_eval_accuracy: 0.8335 - lr: 4.0000e-04\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0263 - eval_accuracy: 0.8815 - val_loss: 5.0439 - val_eval_accuracy: 0.8389 - lr: 4.0000e-04\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0108 - eval_accuracy: 0.8817 - val_loss: 5.1022 - val_eval_accuracy: 0.8390 - lr: 4.0000e-04\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0124 - eval_accuracy: 0.8798 - val_loss: 5.0308 - val_eval_accuracy: 0.8370 - lr: 4.0000e-04\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0099 - eval_accuracy: 0.8717 - val_loss: 5.0978 - val_eval_accuracy: 0.8342 - lr: 4.0000e-04\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0293 - eval_accuracy: 0.8742 - val_loss: 5.1216 - val_eval_accuracy: 0.8393 - lr: 4.0000e-04\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0370 - eval_accuracy: 0.8606 - val_loss: 5.1423 - val_eval_accuracy: 0.8370 - lr: 4.0000e-04\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0242 - eval_accuracy: 0.8594 - val_loss: 5.0794 - val_eval_accuracy: 0.8372 - lr: 4.0000e-04\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0516 - eval_accuracy: 0.8641 - val_loss: 5.0168 - val_eval_accuracy: 0.8368 - lr: 4.0000e-04\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0372 - eval_accuracy: 0.8879 - val_loss: 5.0929 - val_eval_accuracy: 0.8379 - lr: 4.0000e-04\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0195 - eval_accuracy: 0.8594 - val_loss: 5.1339 - val_eval_accuracy: 0.8387 - lr: 4.0000e-04\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0142 - eval_accuracy: 0.8751 - val_loss: 5.2160 - val_eval_accuracy: 0.8311 - lr: 4.0000e-04\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0541 - eval_accuracy: 0.8866 - val_loss: 5.0709 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0189 - eval_accuracy: 0.8633 - val_loss: 5.1674 - val_eval_accuracy: 0.8348 - lr: 4.0000e-04\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0254 - eval_accuracy: 0.8782 - val_loss: 5.1063 - val_eval_accuracy: 0.8395 - lr: 4.0000e-04\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0125 - eval_accuracy: 0.8907 - val_loss: 5.2061 - val_eval_accuracy: 0.8359 - lr: 4.0000e-04\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0027 - eval_accuracy: 0.8968 - val_loss: 5.1544 - val_eval_accuracy: 0.8373 - lr: 4.0000e-04\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0098 - eval_accuracy: 0.8876 - val_loss: 5.1388 - val_eval_accuracy: 0.8380 - lr: 4.0000e-04\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0112 - eval_accuracy: 0.8837 - val_loss: 5.1933 - val_eval_accuracy: 0.8350 - lr: 4.0000e-04\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0151 - eval_accuracy: 0.8715 - val_loss: 5.1248 - val_eval_accuracy: 0.8363 - lr: 4.0000e-04\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0387 - eval_accuracy: 0.8655 - val_loss: 5.1386 - val_eval_accuracy: 0.8360 - lr: 4.0000e-04\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.0200 - eval_accuracy: 0.8784 - val_loss: 5.1847 - val_eval_accuracy: 0.8347 - lr: 4.0000e-04\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0143 - eval_accuracy: 0.8978 - val_loss: 5.1643 - val_eval_accuracy: 0.8326 - lr: 4.0000e-04\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0201 - eval_accuracy: 0.8763 - val_loss: 5.1407 - val_eval_accuracy: 0.8362 - lr: 4.0000e-04\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0015 - eval_accuracy: 0.8675 - val_loss: 5.1178 - val_eval_accuracy: 0.8382 - lr: 4.0000e-04\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0233 - eval_accuracy: 0.8802 - val_loss: 5.1109 - val_eval_accuracy: 0.8406 - lr: 4.0000e-04\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0252 - eval_accuracy: 0.8736 - val_loss: 5.3047 - val_eval_accuracy: 0.8311 - lr: 4.0000e-04\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0581 - eval_accuracy: 0.8757 - val_loss: 5.0820 - val_eval_accuracy: 0.8416 - lr: 4.0000e-04\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0198 - eval_accuracy: 0.8800 - val_loss: 5.2838 - val_eval_accuracy: 0.8341 - lr: 4.0000e-04\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0471 - eval_accuracy: 0.8901 - val_loss: 5.2630 - val_eval_accuracy: 0.8365 - lr: 4.0000e-04\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9940 - eval_accuracy: 0.8655 - val_loss: 5.2384 - val_eval_accuracy: 0.8361 - lr: 4.0000e-04\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9926 - eval_accuracy: 0.8597 - val_loss: 5.1676 - val_eval_accuracy: 0.8397 - lr: 4.0000e-04\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0016 - eval_accuracy: 0.8677 - val_loss: 5.3330 - val_eval_accuracy: 0.8326 - lr: 4.0000e-04\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.9927 - eval_accuracy: 0.8926 - val_loss: 5.2246 - val_eval_accuracy: 0.8368 - lr: 4.0000e-04\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9871 - eval_accuracy: 0.8929 - val_loss: 5.1927 - val_eval_accuracy: 0.8390 - lr: 4.0000e-04\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0020 - eval_accuracy: 0.8820 - val_loss: 5.2179 - val_eval_accuracy: 0.8372 - lr: 4.0000e-04\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9968 - eval_accuracy: 0.8846 - val_loss: 5.1795 - val_eval_accuracy: 0.8368 - lr: 4.0000e-04\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0080 - eval_accuracy: 0.8938 - val_loss: 5.1004 - val_eval_accuracy: 0.8375 - lr: 4.0000e-04\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9974 - eval_accuracy: 0.8617 - val_loss: 5.2669 - val_eval_accuracy: 0.8313 - lr: 4.0000e-04\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0629 - eval_accuracy: 0.8722 - val_loss: 5.1471 - val_eval_accuracy: 0.8376 - lr: 4.0000e-04\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.9793 - eval_accuracy: 0.8580 - val_loss: 5.2362 - val_eval_accuracy: 0.8323 - lr: 4.0000e-04\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0124 - eval_accuracy: 0.8767 - val_loss: 5.0837 - val_eval_accuracy: 0.8386 - lr: 4.0000e-04\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0054 - eval_accuracy: 0.8695 - val_loss: 5.1493 - val_eval_accuracy: 0.8354 - lr: 4.0000e-04\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0249 - eval_accuracy: 0.8697 - val_loss: 5.2285 - val_eval_accuracy: 0.8370 - lr: 4.0000e-04\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0130 - eval_accuracy: 0.8970 - val_loss: 5.2929 - val_eval_accuracy: 0.8356 - lr: 4.0000e-04\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0120 - eval_accuracy: 0.8791 - val_loss: 5.2787 - val_eval_accuracy: 0.8346 - lr: 4.0000e-04\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0080 - eval_accuracy: 0.8588 - val_loss: 5.2374 - val_eval_accuracy: 0.8378 - lr: 4.0000e-04\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0122 - eval_accuracy: 0.8792 - val_loss: 5.2231 - val_eval_accuracy: 0.8369 - lr: 4.0000e-04\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.9974 - eval_accuracy: 0.8597 - val_loss: 5.2930 - val_eval_accuracy: 0.8342 - lr: 4.0000e-04\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9929 - eval_accuracy: 0.8730 - val_loss: 5.3061 - val_eval_accuracy: 0.8389 - lr: 4.0000e-04\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9933 - eval_accuracy: 0.9025 - val_loss: 5.3866 - val_eval_accuracy: 0.8335 - lr: 4.0000e-04\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9872 - eval_accuracy: 0.8813 - val_loss: 5.1421 - val_eval_accuracy: 0.8418 - lr: 4.0000e-04\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0224 - eval_accuracy: 0.8662 - val_loss: 5.2738 - val_eval_accuracy: 0.8341 - lr: 4.0000e-04\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9920 - eval_accuracy: 0.8818 - val_loss: 5.2021 - val_eval_accuracy: 0.8400 - lr: 4.0000e-04\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.9821 - eval_accuracy: 0.8846 - val_loss: 5.3508 - val_eval_accuracy: 0.8328 - lr: 4.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 세팅\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 200\n",
    "MB_SIZE = 500 # (5000)\n",
    "REPORT = 1\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "  X_train_scaled, y_train,\n",
    "  batch_size=MB_SIZE,\n",
    "  validation_split = 0.2,\n",
    "  verbose=1,\n",
    "  epochs=EPOCHS,\n",
    "  callbacks=[es, rlrp]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2419 - eval_accuracy: 0.8736\n",
      "Test Loss: 5.242\n",
      "Test Accuracy: 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "# 손실 그래프\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 훈련 및 검증 평가 지표 추출\n",
    "train_accuracy = history.history['eval_accuracy']\n",
    "val_accuracy = history.history['val_eval_accuracy']\n",
    "\n",
    "# 평가 지표 그래프 그리기\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# 테스트 세트 평가\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치 및 편향 저장 (save_weights 메서드를 사용하면 가중치와 편향 모두를 저장)\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# 다음과 같이 저장한 가중치 호출 가능\n",
    "new_model = Base_Model()\n",
    "new_model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 4.3920 - eval_accuracy: 0.8879\n",
      "Test Loss: 4.392\n",
      "Test Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 평가\n",
    "loss, accuracy = new_model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
