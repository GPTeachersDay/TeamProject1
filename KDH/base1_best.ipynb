{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 10) (836, 10) (3341,) (836,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_dataset(csv_path, TRAIN_RATIO=0.8):\n",
    "    \n",
    "    global X, y, X_train, X_test, y_train, y_test, df\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 성별 원핫 인코딩\n",
    "    df=pd.get_dummies(df,columns=['Sex'])\n",
    "    \n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop('Rings', axis=1)\n",
    "    y = df['Rings']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "csv_path = '../colabo/Data/Regression_data.csv'\n",
    "X_train, X_test, y_train, y_test = load_dataset(csv_path)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,) (37,)\n"
     ]
    }
   ],
   "source": [
    "# 전복 전체 무게가 살 + 내장 + 껍질보다 적게 나가는 경우는 말이 안됨\n",
    "body = X_train['Whole weight'] - (X_train['Shucked weight'] + X_train['Viscera weight'] + X_train['Shell weight'])\n",
    "X_train['body'] = body\n",
    "\n",
    "index = X_train[X_train['body'] < 0].index\n",
    "\n",
    "body = X_test['Whole weight'] - (X_test['Shucked weight'] + X_test['Viscera weight'] + X_test['Shell weight'])\n",
    "X_test['body'] = body\n",
    "\n",
    "index2 = X_test[X_test['body'] < 0].index\n",
    "\n",
    "print(index.shape, index2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(index, axis=0, inplace=True)\n",
    "X_test.drop(index2, axis=0, inplace=True)\n",
    "y_train.drop(index, axis=0, inplace=True)\n",
    "y_test.drop(index2, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train 껍질의 넓이 ( a * b * π)\n",
    "area = 0.5 * X_train['Length'] * 0.5 * X_train['Diameter'] * np.pi\n",
    "X_train['Area'] = area\n",
    "\n",
    "# test 껍질의 넓이 \n",
    "area2 = 0.5 * X_test['Length'] * 0.5 * X_test['Diameter'] * np.pi\n",
    "X_test['Area'] = area2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>1.660072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>1.572837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.769361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>1.277329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.974085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M    body      Area  Perimeter  \n",
       "461          0.265      1      0      0  0.1160  0.213648   1.660072  \n",
       "2835         0.250      0      0      1  0.0435  0.188024   1.572837  \n",
       "1378         0.354      1      0      0  0.0295  0.243473   1.769361  \n",
       "2569         0.111      0      1      0  0.0190  0.124643   1.277329  \n",
       "369          0.470      1      0      0  0.2700  0.303478   1.974085  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter = np.pi * np.sqrt(0.5 * ((X_train['Length'] ** 2) + (X_train['Diameter'] ** 2)))\n",
    "X_train['Perimeter'] = perimeter\n",
    "\n",
    "# test 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter2 = np.pi * np.sqrt(0.5 * ((X_test['Length'] ** 2) + (X_test['Diameter'] ** 2)))\n",
    "X_test['Perimeter'] = perimeter2\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell weight      0.619796\n",
      "Diameter          0.559512\n",
      "Perimeter         0.548978\n",
      "Length            0.539317\n",
      "Height            0.534439\n",
      "body              0.533203\n",
      "Area              0.532949\n",
      "Whole weight      0.525487\n",
      "Viscera weight    0.489945\n",
      "Shucked weight    0.403014\n",
      "Sex_F             0.242466\n",
      "Sex_M             0.178722\n",
      "Sex_I            -0.431255\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟값과 각 변수들 간의 상관관계\n",
    "co = X_train.corrwith(y_train)\n",
    "\n",
    "# 상관계수를 내림차순으로 정리\n",
    "print(co.sort_values(ascending=False))\n",
    "\n",
    "# 절대값\n",
    "co_abs = abs(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>Area</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Sex_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.572837</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.769361</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1.277329</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.974085</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height      Area  \\\n",
       "461          0.265     0.465   1.660072   0.585   0.170  0.213648   \n",
       "2835         0.250     0.420   1.572837   0.570   0.140  0.188024   \n",
       "1378         0.354     0.500   1.769361   0.620   0.150  0.243473   \n",
       "2569         0.111     0.345   1.277329   0.460   0.115  0.124643   \n",
       "369          0.470     0.560   1.974085   0.690   0.215  0.303478   \n",
       "\n",
       "      Viscera weight  Shucked weight  Whole weight  Sex_F  Sex_M  Sex_I  \n",
       "461           0.2240          0.3865        0.9915      1      0      0  \n",
       "2835          0.1650          0.4160        0.8745      0      1      0  \n",
       "1378          0.3135          0.5960        1.2930      1      0      0  \n",
       "2569          0.1020          0.1895        0.4215      0      0      1  \n",
       "369           0.2990          0.6800        1.7190      1      0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'Area', 'Viscera weight', 'Shucked weight', 'Whole weight', 'Sex_F', 'Sex_M', 'Sex_I']\n",
    "X_train_2 = X_train[columns]\n",
    "X_test_2 = X_test[columns]\n",
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일링할 피처 선택\n",
    "scaling_features = columns[:-3]  # 원핫인코딩되지 않은 연속형 또는 순서형 변수들\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = X_train_2.copy()  # 원본 데이터 복사\n",
    "X_test_scaled = X_test_2.copy()    # 원본 데이터 복사\n",
    "X_train_scaled[scaling_features] = scaler.fit_transform(X_train_2[scaling_features])\n",
    "X_test_scaled[scaling_features] = scaler.transform(X_test_2[scaling_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 평가 지표 클래스\n",
    "import tensorflow as tf\n",
    "\n",
    "class EvalAccuracy(tf.keras.metrics.Metric): # TensorFlow의 Metric 클래스를 상속 받음\n",
    "\n",
    "    def __init__(self, name=\"eval_accuracy\", **kwargs): # 부모 클래스의 __init__() 메소드를 호출하여 필요한 초기화를 수행\n",
    "        super(EvalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.correct = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "        # add_weight() 메소드를 사용하여 평가 지표를 계산하는데 필요한 변수를 생성(각 배치에서의 평가 결과를 누적하기 위해)\n",
    "        # add_weight() 는 텐서플로우 Layer 클래스의 메서드(새로운 가중치를 추가하는 기능, 여기서는 평가 지표를 계산하는 데 사용되는 일종의 내부 변수를 의미)\n",
    "        # 이 구문이 실행되면, EvalAccuracy 인스턴스는 새로운 가중치를 추가하고 그 가중치를 self.correct에 저장한다.\n",
    "        # 이 self.correct는 update_state() 메서드에서 업데이트되며, '현재까지 처리한 모든 배치에 대한 평가 지표의 평균을 저장'한다.\n",
    "\n",
    "    def update_state(self, y_true, y_predict, sample_weight=None):\n",
    "        value = tf.abs((y_predict - y_true) / y_true)\n",
    "        self.correct.assign(tf.reduce_mean(value)) # 오차율을 계산해서 correct 변수에 누적한 후, assign() 메소드를 사용하여 correct 변수의 값을 업데이트\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - self.correct\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 에포크마다 평가 지표 초기화\n",
    "        self.correct.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346,305\n",
      "Trainable params: 346,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 베이스모델\n",
    "import numpy as np\n",
    "\n",
    "def Base_Model(LEARNING_RATE=0.01):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    global X, y, X_train, X_test, y_train, y_test, df\n",
    "    \n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, activation='relu', input_shape=(len(X_train_2.keys()),)),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, input_shape=(len(X_train_2.keys()),)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=512),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=128),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.01,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.99,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[EvalAccuracy()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = Base_Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 31ms/step - loss: 3.9008 - eval_accuracy: 0.8561 - val_loss: 4.3820 - val_eval_accuracy: 0.8428 - lr: 0.0020\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.9023 - eval_accuracy: 0.8544 - val_loss: 4.4287 - val_eval_accuracy: 0.8341 - lr: 0.0020\n",
      "Epoch 3/200\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 3.6081 - eval_accuracy: 0.8658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8834 - eval_accuracy: 0.8530 - val_loss: 4.8319 - val_eval_accuracy: 0.8104 - lr: 0.0020\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1411 - eval_accuracy: 0.8868 - val_loss: 4.2886 - val_eval_accuracy: 0.8487 - lr: 0.0020\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9778 - eval_accuracy: 0.8552 - val_loss: 4.3948 - val_eval_accuracy: 0.8505 - lr: 0.0020\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0006 - eval_accuracy: 0.8361 - val_loss: 4.7248 - val_eval_accuracy: 0.8135 - lr: 0.0020\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.0320 - eval_accuracy: 0.8704 - val_loss: 4.5294 - val_eval_accuracy: 0.8313 - lr: 0.0020\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0460 - eval_accuracy: 0.8813 - val_loss: 4.4091 - val_eval_accuracy: 0.8487 - lr: 0.0020\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.9765 - eval_accuracy: 0.8566 - val_loss: 4.4711 - val_eval_accuracy: 0.8336 - lr: 0.0020\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9288 - eval_accuracy: 0.8748 - val_loss: 4.5173 - val_eval_accuracy: 0.8339 - lr: 0.0020\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.9319 - eval_accuracy: 0.8564 - val_loss: 4.5116 - val_eval_accuracy: 0.8460 - lr: 0.0020\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.0201 - eval_accuracy: 0.8414 - val_loss: 4.3200 - val_eval_accuracy: 0.8345 - lr: 0.0020\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9424 - eval_accuracy: 0.8606 - val_loss: 4.4546 - val_eval_accuracy: 0.8318 - lr: 0.0020\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9614 - eval_accuracy: 0.8511 - val_loss: 4.4056 - val_eval_accuracy: 0.8339 - lr: 0.0020\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8948 - eval_accuracy: 0.8734 - val_loss: 4.2715 - val_eval_accuracy: 0.8467 - lr: 0.0020\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9617 - eval_accuracy: 0.8918 - val_loss: 4.5821 - val_eval_accuracy: 0.8214 - lr: 0.0020\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.0188 - eval_accuracy: 0.8602 - val_loss: 4.3823 - val_eval_accuracy: 0.8413 - lr: 0.0020\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8864 - eval_accuracy: 0.8742 - val_loss: 4.3456 - val_eval_accuracy: 0.8497 - lr: 0.0020\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9550 - eval_accuracy: 0.8443 - val_loss: 4.6791 - val_eval_accuracy: 0.8170 - lr: 0.0020\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.0173 - eval_accuracy: 0.8564 - val_loss: 4.4690 - val_eval_accuracy: 0.8290 - lr: 0.0020\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.0640 - eval_accuracy: 0.8790 - val_loss: 4.4161 - val_eval_accuracy: 0.8459 - lr: 0.0020\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9161 - eval_accuracy: 0.8530 - val_loss: 4.6400 - val_eval_accuracy: 0.8193 - lr: 0.0020\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9790 - eval_accuracy: 0.8730 - val_loss: 4.3845 - val_eval_accuracy: 0.8401 - lr: 0.0020\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.0003 - eval_accuracy: 0.8640 - val_loss: 4.2961 - val_eval_accuracy: 0.8450 - lr: 0.0020\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8661 - eval_accuracy: 0.8406 - val_loss: 4.3286 - val_eval_accuracy: 0.8409 - lr: 0.0020\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8561 - eval_accuracy: 0.8648 - val_loss: 4.3554 - val_eval_accuracy: 0.8496 - lr: 0.0020\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.9172 - eval_accuracy: 0.8633 - val_loss: 4.4478 - val_eval_accuracy: 0.8348 - lr: 0.0020\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9149 - eval_accuracy: 0.8618 - val_loss: 4.5636 - val_eval_accuracy: 0.8311 - lr: 0.0020\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8629 - eval_accuracy: 0.8524 - val_loss: 4.3245 - val_eval_accuracy: 0.8431 - lr: 0.0020\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8804 - eval_accuracy: 0.8704 - val_loss: 4.3193 - val_eval_accuracy: 0.8466 - lr: 0.0020\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.8664 - eval_accuracy: 0.8741 - val_loss: 4.2579 - val_eval_accuracy: 0.8449 - lr: 0.0020\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8836 - eval_accuracy: 0.8675 - val_loss: 4.4283 - val_eval_accuracy: 0.8237 - lr: 0.0020\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8802 - eval_accuracy: 0.8402 - val_loss: 4.4352 - val_eval_accuracy: 0.8396 - lr: 0.0020\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9552 - eval_accuracy: 0.8540 - val_loss: 4.4417 - val_eval_accuracy: 0.8369 - lr: 0.0020\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.9370 - eval_accuracy: 0.8718 - val_loss: 4.3210 - val_eval_accuracy: 0.8439 - lr: 0.0020\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.8301 - eval_accuracy: 0.8644 - val_loss: 4.4905 - val_eval_accuracy: 0.8368 - lr: 0.0020\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8594 - eval_accuracy: 0.8753 - val_loss: 4.2807 - val_eval_accuracy: 0.8400 - lr: 0.0020\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8856 - eval_accuracy: 0.8523 - val_loss: 4.2946 - val_eval_accuracy: 0.8419 - lr: 0.0020\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8183 - eval_accuracy: 0.8680 - val_loss: 4.6689 - val_eval_accuracy: 0.8251 - lr: 0.0020\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8655 - eval_accuracy: 0.8589 - val_loss: 4.3664 - val_eval_accuracy: 0.8330 - lr: 0.0020\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8720 - eval_accuracy: 0.8896 - val_loss: 4.3920 - val_eval_accuracy: 0.8476 - lr: 0.0020\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8969 - eval_accuracy: 0.8662 - val_loss: 4.5814 - val_eval_accuracy: 0.8562 - lr: 0.0020\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9467 - eval_accuracy: 0.8776 - val_loss: 4.3127 - val_eval_accuracy: 0.8379 - lr: 0.0020\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9564 - eval_accuracy: 0.8565 - val_loss: 4.4979 - val_eval_accuracy: 0.8257 - lr: 0.0020\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8425 - eval_accuracy: 0.8609 - val_loss: 4.6924 - val_eval_accuracy: 0.8241 - lr: 0.0020\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9526 - eval_accuracy: 0.8629 - val_loss: 4.3475 - val_eval_accuracy: 0.8453 - lr: 0.0020\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.0158 - eval_accuracy: 0.8469 - val_loss: 4.3917 - val_eval_accuracy: 0.8453 - lr: 0.0020\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9440 - eval_accuracy: 0.8523 - val_loss: 4.3414 - val_eval_accuracy: 0.8456 - lr: 0.0020\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.1043 - eval_accuracy: 0.8304 - val_loss: 5.3056 - val_eval_accuracy: 0.7997 - lr: 0.0020\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.3387 - eval_accuracy: 0.8768 - val_loss: 4.6886 - val_eval_accuracy: 0.8537 - lr: 0.0020\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.1233 - eval_accuracy: 0.8600 - val_loss: 4.3488 - val_eval_accuracy: 0.8381 - lr: 0.0020\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.9562 - eval_accuracy: 0.8585 - val_loss: 4.3816 - val_eval_accuracy: 0.8392 - lr: 0.0020\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8714 - eval_accuracy: 0.8525 - val_loss: 4.4251 - val_eval_accuracy: 0.8360 - lr: 0.0020\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8539 - eval_accuracy: 0.8731 - val_loss: 4.2967 - val_eval_accuracy: 0.8421 - lr: 0.0020\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8114 - eval_accuracy: 0.8822 - val_loss: 4.3359 - val_eval_accuracy: 0.8469 - lr: 0.0020\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8478 - eval_accuracy: 0.8727 - val_loss: 4.3873 - val_eval_accuracy: 0.8352 - lr: 0.0020\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7946 - eval_accuracy: 0.8564 - val_loss: 4.3103 - val_eval_accuracy: 0.8415 - lr: 0.0020\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8179 - eval_accuracy: 0.8675 - val_loss: 4.3773 - val_eval_accuracy: 0.8339 - lr: 0.0020\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8446 - eval_accuracy: 0.8458 - val_loss: 4.3147 - val_eval_accuracy: 0.8424 - lr: 0.0020\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7892 - eval_accuracy: 0.8690 - val_loss: 4.3338 - val_eval_accuracy: 0.8349 - lr: 0.0020\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8272 - eval_accuracy: 0.8931 - val_loss: 4.3591 - val_eval_accuracy: 0.8415 - lr: 0.0020\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7983 - eval_accuracy: 0.8381 - val_loss: 4.2428 - val_eval_accuracy: 0.8451 - lr: 0.0020\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8472 - eval_accuracy: 0.8692 - val_loss: 4.3441 - val_eval_accuracy: 0.8466 - lr: 0.0020\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8688 - eval_accuracy: 0.8584 - val_loss: 4.3836 - val_eval_accuracy: 0.8392 - lr: 0.0020\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8424 - eval_accuracy: 0.8704 - val_loss: 4.6206 - val_eval_accuracy: 0.8215 - lr: 0.0020\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.0587 - eval_accuracy: 0.8833 - val_loss: 4.3762 - val_eval_accuracy: 0.8537 - lr: 0.0020\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0012 - eval_accuracy: 0.8610 - val_loss: 4.3942 - val_eval_accuracy: 0.8348 - lr: 0.0020\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8976 - eval_accuracy: 0.8613 - val_loss: 4.7101 - val_eval_accuracy: 0.8290 - lr: 0.0020\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9491 - eval_accuracy: 0.8792 - val_loss: 4.1880 - val_eval_accuracy: 0.8470 - lr: 0.0020\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.9460 - eval_accuracy: 0.8468 - val_loss: 4.2688 - val_eval_accuracy: 0.8488 - lr: 0.0020\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8656 - eval_accuracy: 0.8311 - val_loss: 4.5130 - val_eval_accuracy: 0.8381 - lr: 0.0020\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8243 - eval_accuracy: 0.8857 - val_loss: 4.2549 - val_eval_accuracy: 0.8396 - lr: 0.0020\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8453 - eval_accuracy: 0.8686 - val_loss: 4.2795 - val_eval_accuracy: 0.8451 - lr: 0.0020\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8419 - eval_accuracy: 0.8677 - val_loss: 4.3579 - val_eval_accuracy: 0.8523 - lr: 0.0020\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8531 - eval_accuracy: 0.8644 - val_loss: 4.2303 - val_eval_accuracy: 0.8468 - lr: 0.0020\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.8089 - eval_accuracy: 0.8627 - val_loss: 4.3418 - val_eval_accuracy: 0.8411 - lr: 0.0020\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7903 - eval_accuracy: 0.8604 - val_loss: 4.4494 - val_eval_accuracy: 0.8347 - lr: 0.0020\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8651 - eval_accuracy: 0.8613 - val_loss: 4.2743 - val_eval_accuracy: 0.8400 - lr: 0.0020\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9041 - eval_accuracy: 0.8504 - val_loss: 4.3021 - val_eval_accuracy: 0.8538 - lr: 0.0020\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9381 - eval_accuracy: 0.8702 - val_loss: 4.4226 - val_eval_accuracy: 0.8561 - lr: 0.0020\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9158 - eval_accuracy: 0.8345 - val_loss: 4.3684 - val_eval_accuracy: 0.8568 - lr: 0.0020\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.1962 - eval_accuracy: 0.8651 - val_loss: 5.6066 - val_eval_accuracy: 0.7905 - lr: 0.0020\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3842 - eval_accuracy: 0.8639 - val_loss: 4.2047 - val_eval_accuracy: 0.8535 - lr: 0.0020\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.0307 - eval_accuracy: 0.8472 - val_loss: 4.2894 - val_eval_accuracy: 0.8544 - lr: 0.0020\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9079 - eval_accuracy: 0.8496 - val_loss: 4.3411 - val_eval_accuracy: 0.8343 - lr: 0.0020\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8223 - eval_accuracy: 0.8654 - val_loss: 4.2894 - val_eval_accuracy: 0.8391 - lr: 0.0020\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.8471 - eval_accuracy: 0.8660 - val_loss: 4.1696 - val_eval_accuracy: 0.8531 - lr: 0.0020\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8274 - eval_accuracy: 0.8531 - val_loss: 4.2962 - val_eval_accuracy: 0.8578 - lr: 0.0020\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.9335 - eval_accuracy: 0.8365 - val_loss: 4.4073 - val_eval_accuracy: 0.8315 - lr: 0.0020\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8386 - eval_accuracy: 0.8273 - val_loss: 4.3172 - val_eval_accuracy: 0.8365 - lr: 0.0020\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8734 - eval_accuracy: 0.8890 - val_loss: 4.2525 - val_eval_accuracy: 0.8508 - lr: 0.0020\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8890 - eval_accuracy: 0.8673 - val_loss: 4.2288 - val_eval_accuracy: 0.8532 - lr: 0.0020\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8574 - eval_accuracy: 0.8438 - val_loss: 4.9565 - val_eval_accuracy: 0.8121 - lr: 0.0020\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0266 - eval_accuracy: 0.8818 - val_loss: 4.2427 - val_eval_accuracy: 0.8523 - lr: 0.0020\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9572 - eval_accuracy: 0.8612 - val_loss: 4.6198 - val_eval_accuracy: 0.8594 - lr: 0.0020\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.1400 - eval_accuracy: 0.8386 - val_loss: 4.4848 - val_eval_accuracy: 0.8248 - lr: 0.0020\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9982 - eval_accuracy: 0.8777 - val_loss: 4.3275 - val_eval_accuracy: 0.8456 - lr: 0.0020\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8738 - eval_accuracy: 0.8444 - val_loss: 4.2721 - val_eval_accuracy: 0.8556 - lr: 0.0020\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8470 - eval_accuracy: 0.8809 - val_loss: 4.5177 - val_eval_accuracy: 0.8347 - lr: 0.0020\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8499 - eval_accuracy: 0.8640 - val_loss: 4.2070 - val_eval_accuracy: 0.8529 - lr: 0.0020\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.8172 - eval_accuracy: 0.8673 - val_loss: 4.2303 - val_eval_accuracy: 0.8430 - lr: 4.0000e-04\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7565 - eval_accuracy: 0.8564 - val_loss: 4.2289 - val_eval_accuracy: 0.8425 - lr: 4.0000e-04\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.7291 - eval_accuracy: 0.8607 - val_loss: 4.2554 - val_eval_accuracy: 0.8476 - lr: 4.0000e-04\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.7231 - eval_accuracy: 0.8713 - val_loss: 4.2453 - val_eval_accuracy: 0.8474 - lr: 4.0000e-04\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6933 - eval_accuracy: 0.8507 - val_loss: 4.2123 - val_eval_accuracy: 0.8453 - lr: 4.0000e-04\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6829 - eval_accuracy: 0.8502 - val_loss: 4.2148 - val_eval_accuracy: 0.8459 - lr: 4.0000e-04\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7049 - eval_accuracy: 0.8805 - val_loss: 4.1849 - val_eval_accuracy: 0.8501 - lr: 4.0000e-04\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6969 - eval_accuracy: 0.8466 - val_loss: 4.2585 - val_eval_accuracy: 0.8435 - lr: 4.0000e-04\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.6872 - eval_accuracy: 0.8729 - val_loss: 4.2280 - val_eval_accuracy: 0.8492 - lr: 4.0000e-04\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6893 - eval_accuracy: 0.8592 - val_loss: 4.2703 - val_eval_accuracy: 0.8420 - lr: 4.0000e-04\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.6797 - eval_accuracy: 0.8557 - val_loss: 4.2425 - val_eval_accuracy: 0.8462 - lr: 4.0000e-04\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7093 - eval_accuracy: 0.8534 - val_loss: 4.2602 - val_eval_accuracy: 0.8479 - lr: 4.0000e-04\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.6777 - eval_accuracy: 0.8567 - val_loss: 4.3264 - val_eval_accuracy: 0.8397 - lr: 4.0000e-04\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.6668 - eval_accuracy: 0.8689 - val_loss: 4.2459 - val_eval_accuracy: 0.8492 - lr: 4.0000e-04\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6747 - eval_accuracy: 0.8844 - val_loss: 4.2980 - val_eval_accuracy: 0.8407 - lr: 4.0000e-04\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6941 - eval_accuracy: 0.8562 - val_loss: 4.3155 - val_eval_accuracy: 0.8433 - lr: 4.0000e-04\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6681 - eval_accuracy: 0.8535 - val_loss: 4.2809 - val_eval_accuracy: 0.8506 - lr: 4.0000e-04\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6722 - eval_accuracy: 0.8561 - val_loss: 4.3253 - val_eval_accuracy: 0.8409 - lr: 4.0000e-04\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6732 - eval_accuracy: 0.8876 - val_loss: 4.2683 - val_eval_accuracy: 0.8452 - lr: 4.0000e-04\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6552 - eval_accuracy: 0.8804 - val_loss: 4.2662 - val_eval_accuracy: 0.8461 - lr: 4.0000e-04\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6555 - eval_accuracy: 0.8583 - val_loss: 4.2846 - val_eval_accuracy: 0.8445 - lr: 4.0000e-04\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6514 - eval_accuracy: 0.8515 - val_loss: 4.2993 - val_eval_accuracy: 0.8468 - lr: 4.0000e-04\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6512 - eval_accuracy: 0.8589 - val_loss: 4.2662 - val_eval_accuracy: 0.8445 - lr: 4.0000e-04\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6554 - eval_accuracy: 0.8575 - val_loss: 4.2797 - val_eval_accuracy: 0.8447 - lr: 4.0000e-04\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6475 - eval_accuracy: 0.8653 - val_loss: 4.3005 - val_eval_accuracy: 0.8430 - lr: 4.0000e-04\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6523 - eval_accuracy: 0.8895 - val_loss: 4.3108 - val_eval_accuracy: 0.8445 - lr: 4.0000e-04\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6499 - eval_accuracy: 0.8784 - val_loss: 4.2920 - val_eval_accuracy: 0.8443 - lr: 4.0000e-04\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6451 - eval_accuracy: 0.8469 - val_loss: 4.2463 - val_eval_accuracy: 0.8449 - lr: 4.0000e-04\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6516 - eval_accuracy: 0.8859 - val_loss: 4.2474 - val_eval_accuracy: 0.8425 - lr: 4.0000e-04\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.6522 - eval_accuracy: 0.8744 - val_loss: 4.2918 - val_eval_accuracy: 0.8451 - lr: 4.0000e-04\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6537 - eval_accuracy: 0.8737 - val_loss: 4.3365 - val_eval_accuracy: 0.8447 - lr: 4.0000e-04\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6525 - eval_accuracy: 0.8826 - val_loss: 4.3079 - val_eval_accuracy: 0.8469 - lr: 4.0000e-04\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6717 - eval_accuracy: 0.8491 - val_loss: 4.3005 - val_eval_accuracy: 0.8452 - lr: 4.0000e-04\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6529 - eval_accuracy: 0.8566 - val_loss: 4.3139 - val_eval_accuracy: 0.8430 - lr: 4.0000e-04\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6575 - eval_accuracy: 0.8659 - val_loss: 4.2462 - val_eval_accuracy: 0.8459 - lr: 4.0000e-04\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6393 - eval_accuracy: 0.8444 - val_loss: 4.3245 - val_eval_accuracy: 0.8421 - lr: 4.0000e-04\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6498 - eval_accuracy: 0.8861 - val_loss: 4.3104 - val_eval_accuracy: 0.8483 - lr: 4.0000e-04\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6534 - eval_accuracy: 0.8614 - val_loss: 4.3217 - val_eval_accuracy: 0.8418 - lr: 4.0000e-04\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6374 - eval_accuracy: 0.8853 - val_loss: 4.2723 - val_eval_accuracy: 0.8437 - lr: 4.0000e-04\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6317 - eval_accuracy: 0.8624 - val_loss: 4.2799 - val_eval_accuracy: 0.8421 - lr: 4.0000e-04\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6424 - eval_accuracy: 0.8705 - val_loss: 4.2675 - val_eval_accuracy: 0.8465 - lr: 4.0000e-04\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.6378 - eval_accuracy: 0.8588 - val_loss: 4.2967 - val_eval_accuracy: 0.8476 - lr: 4.0000e-04\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6544 - eval_accuracy: 0.8599 - val_loss: 4.3108 - val_eval_accuracy: 0.8453 - lr: 4.0000e-04\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6489 - eval_accuracy: 0.8644 - val_loss: 4.3221 - val_eval_accuracy: 0.8415 - lr: 4.0000e-04\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6466 - eval_accuracy: 0.8616 - val_loss: 4.2751 - val_eval_accuracy: 0.8456 - lr: 4.0000e-04\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6235 - eval_accuracy: 0.8979 - val_loss: 4.3509 - val_eval_accuracy: 0.8407 - lr: 4.0000e-04\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6333 - eval_accuracy: 0.8695 - val_loss: 4.3035 - val_eval_accuracy: 0.8457 - lr: 4.0000e-04\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6209 - eval_accuracy: 0.8753 - val_loss: 4.2971 - val_eval_accuracy: 0.8460 - lr: 4.0000e-04\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6310 - eval_accuracy: 0.8747 - val_loss: 4.2939 - val_eval_accuracy: 0.8443 - lr: 4.0000e-04\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6235 - eval_accuracy: 0.8646 - val_loss: 4.3146 - val_eval_accuracy: 0.8427 - lr: 4.0000e-04\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6241 - eval_accuracy: 0.8453 - val_loss: 4.3429 - val_eval_accuracy: 0.8457 - lr: 4.0000e-04\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.6551 - eval_accuracy: 0.8529 - val_loss: 4.2961 - val_eval_accuracy: 0.8461 - lr: 4.0000e-04\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6262 - eval_accuracy: 0.8560 - val_loss: 4.2801 - val_eval_accuracy: 0.8420 - lr: 4.0000e-04\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6306 - eval_accuracy: 0.8722 - val_loss: 4.2723 - val_eval_accuracy: 0.8452 - lr: 4.0000e-04\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6300 - eval_accuracy: 0.8778 - val_loss: 4.3102 - val_eval_accuracy: 0.8437 - lr: 4.0000e-04\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6176 - eval_accuracy: 0.8558 - val_loss: 4.3009 - val_eval_accuracy: 0.8455 - lr: 4.0000e-04\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6149 - eval_accuracy: 0.8634 - val_loss: 4.3091 - val_eval_accuracy: 0.8394 - lr: 4.0000e-04\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6480 - eval_accuracy: 0.8702 - val_loss: 4.2701 - val_eval_accuracy: 0.8469 - lr: 4.0000e-04\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6226 - eval_accuracy: 0.8610 - val_loss: 4.3140 - val_eval_accuracy: 0.8459 - lr: 4.0000e-04\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6377 - eval_accuracy: 0.8663 - val_loss: 4.3308 - val_eval_accuracy: 0.8480 - lr: 4.0000e-04\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6363 - eval_accuracy: 0.8952 - val_loss: 4.2704 - val_eval_accuracy: 0.8475 - lr: 4.0000e-04\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6078 - eval_accuracy: 0.8904 - val_loss: 4.3277 - val_eval_accuracy: 0.8399 - lr: 4.0000e-04\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6250 - eval_accuracy: 0.8786 - val_loss: 4.3250 - val_eval_accuracy: 0.8471 - lr: 4.0000e-04\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6377 - eval_accuracy: 0.8735 - val_loss: 4.3507 - val_eval_accuracy: 0.8439 - lr: 4.0000e-04\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6176 - eval_accuracy: 0.8565 - val_loss: 4.2876 - val_eval_accuracy: 0.8431 - lr: 4.0000e-04\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6162 - eval_accuracy: 0.8536 - val_loss: 4.2940 - val_eval_accuracy: 0.8426 - lr: 4.0000e-04\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6239 - eval_accuracy: 0.8703 - val_loss: 4.3445 - val_eval_accuracy: 0.8421 - lr: 4.0000e-04\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6162 - eval_accuracy: 0.8903 - val_loss: 4.3321 - val_eval_accuracy: 0.8404 - lr: 4.0000e-04\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6089 - eval_accuracy: 0.8676 - val_loss: 4.3068 - val_eval_accuracy: 0.8432 - lr: 4.0000e-04\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6181 - eval_accuracy: 0.8602 - val_loss: 4.3191 - val_eval_accuracy: 0.8444 - lr: 4.0000e-04\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6188 - eval_accuracy: 0.8644 - val_loss: 4.3199 - val_eval_accuracy: 0.8458 - lr: 4.0000e-04\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6462 - eval_accuracy: 0.8654 - val_loss: 4.3122 - val_eval_accuracy: 0.8444 - lr: 4.0000e-04\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6777 - eval_accuracy: 0.8644 - val_loss: 4.3120 - val_eval_accuracy: 0.8441 - lr: 4.0000e-04\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6397 - eval_accuracy: 0.8876 - val_loss: 4.3154 - val_eval_accuracy: 0.8486 - lr: 4.0000e-04\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6251 - eval_accuracy: 0.8773 - val_loss: 4.5146 - val_eval_accuracy: 0.8387 - lr: 4.0000e-04\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6331 - eval_accuracy: 0.8611 - val_loss: 4.3091 - val_eval_accuracy: 0.8477 - lr: 4.0000e-04\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6205 - eval_accuracy: 0.8462 - val_loss: 4.2992 - val_eval_accuracy: 0.8440 - lr: 4.0000e-04\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.6260 - eval_accuracy: 0.8568 - val_loss: 4.2816 - val_eval_accuracy: 0.8455 - lr: 4.0000e-04\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6098 - eval_accuracy: 0.8926 - val_loss: 4.3160 - val_eval_accuracy: 0.8420 - lr: 4.0000e-04\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6134 - eval_accuracy: 0.8744 - val_loss: 4.3220 - val_eval_accuracy: 0.8457 - lr: 4.0000e-04\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6311 - eval_accuracy: 0.8773 - val_loss: 4.3066 - val_eval_accuracy: 0.8461 - lr: 4.0000e-04\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6173 - eval_accuracy: 0.8771 - val_loss: 4.3476 - val_eval_accuracy: 0.8405 - lr: 4.0000e-04\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6159 - eval_accuracy: 0.8822 - val_loss: 4.3290 - val_eval_accuracy: 0.8453 - lr: 4.0000e-04\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6134 - eval_accuracy: 0.8508 - val_loss: 4.3720 - val_eval_accuracy: 0.8385 - lr: 4.0000e-04\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.6391 - eval_accuracy: 0.8564 - val_loss: 4.3316 - val_eval_accuracy: 0.8407 - lr: 4.0000e-04\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6012 - eval_accuracy: 0.8513 - val_loss: 4.2952 - val_eval_accuracy: 0.8454 - lr: 4.0000e-04\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6115 - eval_accuracy: 0.8728 - val_loss: 4.3775 - val_eval_accuracy: 0.8404 - lr: 4.0000e-04\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6031 - eval_accuracy: 0.8604 - val_loss: 4.3169 - val_eval_accuracy: 0.8438 - lr: 4.0000e-04\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5955 - eval_accuracy: 0.8570 - val_loss: 4.3253 - val_eval_accuracy: 0.8392 - lr: 4.0000e-04\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6059 - eval_accuracy: 0.8804 - val_loss: 4.3089 - val_eval_accuracy: 0.8450 - lr: 4.0000e-04\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5841 - eval_accuracy: 0.8735 - val_loss: 4.3606 - val_eval_accuracy: 0.8435 - lr: 4.0000e-04\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6110 - eval_accuracy: 0.8524 - val_loss: 4.3304 - val_eval_accuracy: 0.8435 - lr: 4.0000e-04\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6033 - eval_accuracy: 0.8664 - val_loss: 4.3122 - val_eval_accuracy: 0.8456 - lr: 4.0000e-04\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.6039 - eval_accuracy: 0.8582 - val_loss: 4.3818 - val_eval_accuracy: 0.8409 - lr: 4.0000e-04\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6215 - eval_accuracy: 0.8623 - val_loss: 4.3256 - val_eval_accuracy: 0.8463 - lr: 4.0000e-04\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6100 - eval_accuracy: 0.8980 - val_loss: 4.2862 - val_eval_accuracy: 0.8438 - lr: 4.0000e-04\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.6021 - eval_accuracy: 0.8756 - val_loss: 4.2960 - val_eval_accuracy: 0.8412 - lr: 4.0000e-04\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6022 - eval_accuracy: 0.8602 - val_loss: 4.3028 - val_eval_accuracy: 0.8464 - lr: 4.0000e-04\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5761 - eval_accuracy: 0.8639 - val_loss: 4.3945 - val_eval_accuracy: 0.8439 - lr: 4.0000e-04\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5933 - eval_accuracy: 0.8714 - val_loss: 4.4017 - val_eval_accuracy: 0.8425 - lr: 4.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 세팅\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 200\n",
    "MB_SIZE = 500 # (5000)\n",
    "REPORT = 1\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "  X_train_scaled, y_train,\n",
    "  batch_size=MB_SIZE,\n",
    "  validation_split = 0.2,\n",
    "  verbose=1,\n",
    "  epochs=EPOCHS,\n",
    "  callbacks=[es, rlrp]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 5.0043 - eval_accuracy: 0.8764\n",
      "Test Loss: 5.004\n",
      "Test Accuracy: 0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k10dh\\anaconda3\\envs\\TeamProject\\lib\\site-packages\\keras\\engine\\training.py:2448: UserWarning: Metric EvalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "# 손실 그래프\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 훈련 및 검증 평가 지표 추출\n",
    "train_accuracy = history.history['eval_accuracy']\n",
    "val_accuracy = history.history['val_eval_accuracy']\n",
    "\n",
    "# 평가 지표 그래프 그리기\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# 테스트 세트 평가\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치 및 편향 저장 (save_weights 메서드를 사용하면 가중치와 편향 모두를 저장)\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# 다음과 같이 저장한 가중치 호출 가능\n",
    "new_model = Base_Model()\n",
    "new_model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 4.3920 - eval_accuracy: 0.8879\n",
      "Test Loss: 4.392\n",
      "Test Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 평가\n",
    "loss, accuracy = new_model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
