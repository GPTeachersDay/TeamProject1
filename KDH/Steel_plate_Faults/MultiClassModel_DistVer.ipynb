{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중분류모델 - 강판 결함 예측"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def load_dataset(csv_path):\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 인코딩 방식 변경\n",
    "    # idxmax 함수는 각 행의 최대값을 가진 열의 인덱스를 반환한다. 따라서 원핫인코딩된 피쳐를 하나의 카테고리 변수로 복원할 수 있음\n",
    "    df['Fault'] = df[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].idxmax(axis=1)\n",
    "    \n",
    "    # 라벨 인코딩\n",
    "    encoder = LabelEncoder()\n",
    "    df['Fault'] = encoder.fit_transform(df['Fault'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 20) (388, 20) (1551,) (388,)\n"
     ]
    }
   ],
   "source": [
    "# 특성공학\n",
    "csv_path = '/mnt/c/Users/k10dh/AppData/Local/Packages/CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc/k10dh/TeamProject/TeamProject1/KDH/Dataset/mulit_classification_data.csv'\n",
    "df = load_dataset(csv_path)\n",
    "\n",
    "# 이상치 제거\n",
    "df = df[~((df['Pixels_Areas'] > 35000) |\n",
    "          (df['X_Perimeter'] > 2000) |\n",
    "          (df['Y_Perimeter'] > 2500) |\n",
    "          (df['Sum_of_Luminosity'] > 0.5e7))]\n",
    "\n",
    "# 'TypeOfSteel_A300'과 'TypeOfSteel_400'로 나누어진 특성을 하나로 통합\n",
    "df['TypeOfSteel'] = df['TypeOfSteel_A300']\n",
    "df.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400'], axis=1, inplace=True)\n",
    "\n",
    "# 다중공선성 문제 해결을 위해 상관관계가 높은 feature 확인 후 제거 (상관계수 절대값 0.9이상)\n",
    "# 'X_Perimeter' -> 'Pixels_Areas'\n",
    "# 'Y_Perimeter' -> 'X_Perimeter'\n",
    "# 'Sum_of_Luminosity' -> 'Pixels_Areas', 'X_Perimeter'\n",
    "# 'Pixels_Areas'는 특성중요도가 높으므로 활용하고 상관관계가 높은 나머지 특성들 제거\n",
    "df.drop(['Sum_of_Luminosity', 'X_Perimeter', 'Y_Perimeter'], axis=1, inplace=True)\n",
    "\n",
    "# 로그 스케일링(관측치 측정 범위가 넓음)\n",
    "df['Log_Pixels_Areas'] = np.log(df['Pixels_Areas'])\n",
    "df.drop(['Pixels_Areas'], axis=1, inplace=True)\n",
    "\n",
    "# 중요도 낮은 특성 제거(머신러닝 분류모델에서 사용하는 기법인데 딥러닝에도 적용이 가능한가? -> 우선 모델 성능 개선은 되었음, 더 알아보면 좋을 것 같음)\n",
    "df.drop(['Outside_Global_Index', 'SigmoidOfAreas', 'Log_Y_Index'], axis=1, inplace=True)\n",
    "\n",
    "# 학습 데이터 분리\n",
    "X = df.drop(['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults', 'Fault'], axis=1)\n",
    "y = df['Fault']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 83)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum',\n",
       "       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
       "       'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index',\n",
       "       'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'LogOfAreas',\n",
       "       'Log_X_Index', 'Orientation_Index', 'Luminosity_Index', 'Pastry',\n",
       "       'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults',\n",
       "       'Fault', 'TypeOfSteel', 'Log_Pixels_Areas'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>...</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "      <th>Fault</th>\n",
       "      <th>TypeOfSteel</th>\n",
       "      <th>Log_Pixels_Areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1.939000e+03</td>\n",
       "      <td>1.939000e+03</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.00000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>571.707581</td>\n",
       "      <td>618.437855</td>\n",
       "      <td>1.649048e+06</td>\n",
       "      <td>1.649092e+06</td>\n",
       "      <td>84.626096</td>\n",
       "      <td>130.178442</td>\n",
       "      <td>1459.260959</td>\n",
       "      <td>78.777720</td>\n",
       "      <td>0.332032</td>\n",
       "      <td>0.413977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081485</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>0.201135</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.028365</td>\n",
       "      <td>0.207323</td>\n",
       "      <td>0.34657</td>\n",
       "      <td>2.569881</td>\n",
       "      <td>0.400722</td>\n",
       "      <td>5.733272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>520.654729</td>\n",
       "      <td>497.665430</td>\n",
       "      <td>1.774493e+06</td>\n",
       "      <td>1.774491e+06</td>\n",
       "      <td>32.058785</td>\n",
       "      <td>18.691238</td>\n",
       "      <td>144.616025</td>\n",
       "      <td>55.100383</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273650</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>0.400952</td>\n",
       "      <td>0.189135</td>\n",
       "      <td>0.166057</td>\n",
       "      <td>0.405494</td>\n",
       "      <td>0.47600</td>\n",
       "      <td>1.763241</td>\n",
       "      <td>0.490171</td>\n",
       "      <td>1.808779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.712000e+03</td>\n",
       "      <td>6.724000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>4.701220e+05</td>\n",
       "      <td>4.701520e+05</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1358.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.315750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.430817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>1.199744e+06</td>\n",
       "      <td>1.199753e+06</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.153292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1053.000000</td>\n",
       "      <td>1072.500000</td>\n",
       "      <td>2.182309e+06</td>\n",
       "      <td>2.182322e+06</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.695792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1705.000000</td>\n",
       "      <td>1713.000000</td>\n",
       "      <td>1.298766e+07</td>\n",
       "      <td>1.298769e+07</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>1794.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.145374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_Minimum    X_Maximum     Y_Minimum     Y_Maximum   \n",
       "count  1939.000000  1939.000000  1.939000e+03  1.939000e+03  \\\n",
       "mean    571.707581   618.437855  1.649048e+06  1.649092e+06   \n",
       "std     520.654729   497.665430  1.774493e+06  1.774491e+06   \n",
       "min       0.000000     4.000000  6.712000e+03  6.724000e+03   \n",
       "25%      52.000000   192.500000  4.701220e+05  4.701520e+05   \n",
       "50%     436.000000   470.000000  1.199744e+06  1.199753e+06   \n",
       "75%    1053.000000  1072.500000  2.182309e+06  2.182322e+06   \n",
       "max    1705.000000  1713.000000  1.298766e+07  1.298769e+07   \n",
       "\n",
       "       Minimum_of_Luminosity  Maximum_of_Luminosity  Length_of_Conveyer   \n",
       "count            1939.000000            1939.000000         1939.000000  \\\n",
       "mean               84.626096             130.178442         1459.260959   \n",
       "std                32.058785              18.691238          144.616025   \n",
       "min                 0.000000              37.000000         1227.000000   \n",
       "25%                63.000000             124.000000         1358.000000   \n",
       "50%                90.000000             127.000000         1364.000000   \n",
       "75%               106.000000             140.000000         1650.000000   \n",
       "max               203.000000             253.000000         1794.000000   \n",
       "\n",
       "       Steel_Plate_Thickness  Edges_Index  Empty_Index  ...       Pastry   \n",
       "count            1939.000000  1939.000000  1939.000000  ...  1939.000000  \\\n",
       "mean               78.777720     0.332032     0.413977  ...     0.081485   \n",
       "std                55.100383     0.299704     0.136789  ...     0.273650   \n",
       "min                40.000000     0.000000     0.000000  ...     0.000000   \n",
       "25%                40.000000     0.060400     0.315750  ...     0.000000   \n",
       "50%                70.000000     0.227800     0.412100  ...     0.000000   \n",
       "75%                80.000000     0.575500     0.501400  ...     0.000000   \n",
       "max               300.000000     0.995200     0.927500  ...     1.000000   \n",
       "\n",
       "         Z_Scratch     K_Scatch       Stains    Dirtiness        Bumps   \n",
       "count  1939.000000  1939.000000  1939.000000  1939.000000  1939.000000  \\\n",
       "mean      0.097989     0.201135     0.037133     0.028365     0.207323   \n",
       "std       0.297376     0.400952     0.189135     0.166057     0.405494   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Other_Faults        Fault  TypeOfSteel  Log_Pixels_Areas  \n",
       "count    1939.00000  1939.000000  1939.000000       1939.000000  \n",
       "mean        0.34657     2.569881     0.400722          5.733272  \n",
       "std         0.47600     1.763241     0.490171          1.808779  \n",
       "min         0.00000     0.000000     0.000000          0.693147  \n",
       "25%         0.00000     2.000000     0.000000          4.430817  \n",
       "50%         0.00000     3.000000     0.000000          5.153292  \n",
       "75%         1.00000     3.000000     1.000000          6.695792  \n",
       "max         1.00000     6.000000     1.000000         10.145374  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 크기 X_train: (1551, 20)\n",
      "원본 데이터 크기 y_train: (1551,) \n",
      "\n",
      "원본 데이터 '1' 개수: 43\n",
      "원본 데이터 '0' 개수: 318 \n",
      "\n",
      "샘플링 데이터 크기 X_train: (3710, 20)\n",
      "샘플링 데이터 크기 y_train: (3710,) \n",
      "\n",
      "샘플링 데이터 '1' 개수: 530\n",
      "샘플링 데이터 '0' 개수: 530\n"
     ]
    }
   ],
   "source": [
    "# 오버샘플링(학습데이터만)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 오버샘플링 전 클래스 분포 확인\n",
    "print('원본 데이터 크기 X_train: {}'.format(X_train.shape))\n",
    "print('원본 데이터 크기 y_train: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"원본 데이터 '1' 개수: {}\".format(sum(y_train==1)))\n",
    "print(\"원본 데이터 '0' 개수: {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "# SMOTE 적용\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "# 오버샘플링 후 클래스 분포 확인\n",
    "print('샘플링 데이터 크기 X_train: {}'.format(X_train_res.shape))\n",
    "print('샘플링 데이터 크기 y_train: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"샘플링 데이터 '1' 개수: {}\".format(sum(y_train_res==1)))\n",
    "print(\"샘플링 데이터 '0' 개수: {}\".format(sum(y_train_res==0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일링할 피처 선택\n",
    "scaling_features = X_train.columns\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = X_train.copy()  # 원본 데이터 복사\n",
    "X_test_scaled = X_test.copy()    # 원본 데이터 복사\n",
    "X_train_scaled[scaling_features] = scaler.fit_transform(X_train[scaling_features])\n",
    "X_test_scaled[scaling_features] = scaler.transform(X_test[scaling_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 01:55:14.289778: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스킵 연결 모델(Skip Connection)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def Classifier_Model_SC(units, l2):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # 입력층을 정의하며, 입력의 형태는 훈련 데이터의 특성 수에 따라 결정\n",
    "    inputs = Input(shape=(len(X_train.keys()),))\n",
    "    \n",
    "    # 첫 번째 Dense 층을 만들고 ReLU 활성화 함수를 사용, L2 정규화 적용\n",
    "    x = Dense(units=units[0], activation='relu', kernel_regularizer=regularizers.l2(l2[0]))(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # 이후 7개의 Dense 층을 스킵 연결을 가지도록 생성\n",
    "    for i in range(1, 8):   \n",
    "        dense = Dense(units=units[i], activation='relu', kernel_regularizer=regularizers.l2(l2[i]))\n",
    "        y = dense(x)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        # 현재 층의 출력(y)과 이전 층의 출력(x)을 더하여 스킵 연결 구현\n",
    "        x = Add()([x, y])\n",
    "\n",
    "    # 출력층을 정의, 유닛의 수는 클래스의 수와 동일하며, softmax 활성화 함수를 사용\n",
    "    outputs = Dense(units=7, activation='softmax')(x)\n",
    "\n",
    "    # 모델을 생성, 입력과 출력을 지정\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',  # 손실함수를 다중 클래스 분류에 적합한 형태로 변경\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "units = [256 for _ in range(8)] # 노드 개수 설정\n",
    "L2 = [0.001 + i * 0.0025 for i in range(8)] # L2 값 설정\n",
    "\n",
    "model = Classifier_Model_SC(units, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='accuracy', patience=256, mode='auto')\n",
    "rlrp = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=256, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 정확도가 높은 모델의 가중치 저장\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Callback 클래스를 상속받아 사용자 정의 콜백 클래스 생성\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, max_models_to_save=5):\n",
    "        super().__init__()\n",
    "        self.max_models_to_save = max_models_to_save # 최대로 저장할 모델의 수를 설정\n",
    "        self.saved_models = [] # 저장된 모델들을 관리할 리스트를 생성\n",
    "        \n",
    "# 에포크 종료 시점에 호출되는 메서드를 정의\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get('val_accuracy', 0.0) # 현재 에포크의 검증 정확도\n",
    "        model_weights = self.model.get_weights() # 현재 에포크의 모델 가중치\n",
    "\n",
    "        # 첫 번째 에포크이거나 새로운 val_accuracy가 이전보다 높을 때만 모델 저장\n",
    "        if not self.saved_models or val_accuracy > min(self.saved_models, key=lambda x: x[0])[0]:\n",
    "            self.saved_models.append((val_accuracy, model_weights)) # (val_accuracy, model_weights) 형식의 튜플을 리스트에 추가\n",
    "            # 리스트를 val_accuracy 기준으로 내림차순 정렬하고, 최대로 저장할 모델의 수를 넘지 않도록 리스트를 자름\n",
    "            self.saved_models = sorted(self.saved_models, key=lambda x: -x[0])[:self.max_models_to_save] \n",
    "\n",
    "# 사용자 정의 콜백을 생성\n",
    "custom_checkpoint = CustomModelCheckpoint(max_models_to_save=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 세팅\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1024\n",
    "MB_SIZE = 256\n",
    "REPORT = 1\n",
    "TRAIN_RATIO = 0.8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "history = model.fit(\n",
    "  X_train_scaled, y_train,\n",
    "  batch_size=MB_SIZE,\n",
    "  validation_split = 0.2,\n",
    "  verbose=1,\n",
    "  epochs=EPOCHS,\n",
    "  callbacks=[es, rlrp, custom_checkpoint]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 정확도가 가장 높은 모델 찾기\n",
    "# enumerate 함수를 사용하여 저장된 모델들의 인덱스와 검증 정확도, 가중치를 함께 호출\n",
    "for i, (val_accuracy, weights) in enumerate(custom_checkpoint.saved_models):\n",
    "    model.set_weights(weights) # 현재 순환에서의 모델 가중치를 로드\n",
    "    test_metrics = model.evaluate(X_test_scaled, y_test, verbose=0) # 현재 가중치로 설정된 모델에 대해 테스트 데이터를 이용해 평가를 진행\n",
    "    print(f'Model {i+1} - val_acc: {val_accuracy:.4f}, test_acc: {test_metrics[1]:.4f}') # test_metrics[1]은 evaluate 함수의 반환값 중 두 번째 값으로, 정확도를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 정확도가 가장 높은 모델의 가중치를 로드(여기서는 Model 8이 제일 높았음)\n",
    "model.set_weights(custom_checkpoint.saved_models[7][1])  # 0-based index이므로 8번째 모델은 7번 index\n",
    "\n",
    "# 모델 가중치를 저장(git에 있는 'best_model_weights_classify.h5'는 가장 높은 성능 모델의 가중치이므로 중복 저장하지 않도록 주의)\n",
    "# model.save_weights('best_model_weights_classify.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9645 - accuracy: 0.8067\n",
      "Test Loss: 0.964\n",
      "Test Accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 평가\n",
    "model.load_weights(\"best_model_weights_classify.h5\")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
