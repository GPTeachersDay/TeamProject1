{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552, 27) (389, 27) (1552,) (389,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def load_dataset(csv_path, TRAIN_RATIO=0.8):\n",
    "    \n",
    "    global X, y, X_train, X_test, y_train, y_test, df\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 인코딩 방식 변경\n",
    "    # idxmax 함수는 각 행의 최대값을 가진 열의 인덱스를 반환한다. 따라서 원핫인코딩된 피쳐를 하나의 카테고리 변수로 복원할 수 있음\n",
    "    df['Fault'] = df[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].idxmax(axis=1)\n",
    "    \n",
    "    # 라벨 인코딩(원핫인코딩보다 차원수가 줄어드는 효과)\n",
    "    encoder = LabelEncoder()\n",
    "    df['Fault'] = encoder.fit_transform(df['Fault'])\n",
    "    \n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop(['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults', 'Fault'], axis=1)\n",
    "    y = df['Fault']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "csv_path = '/mnt/c/Users/k10dh/AppData/Local/Packages/CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc/k10dh/TeamProject/TeamProject1/KDH/Dataset/mulit_classification_data.csv'\n",
    "X_train, X_test, y_train, y_test = load_dataset(csv_path)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 20) (388, 20) (1551,) (388,)\n"
     ]
    }
   ],
   "source": [
    "# 특성공학\n",
    "# 이상치 제거\n",
    "df = df[~((df['Pixels_Areas'] > 35000) |\n",
    "          (df['X_Perimeter'] > 2000) |\n",
    "          (df['Y_Perimeter'] > 2500) |\n",
    "          (df['Sum_of_Luminosity'] > 0.5e7))]\n",
    "\n",
    "# 'TypeOfSteel_A300' + 'TypeOfSteel_400' = 'TypeOfSteel' (A300이면 1)\n",
    "df['TypeOfSteel'] = df['TypeOfSteel_A300']\n",
    "df.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400'], axis=1, inplace=True)\n",
    "\n",
    "# 'Minimum_of_Luminosity' + 'Maximum_of_Luminosity' = 'Mean_of_Luminosity'\n",
    "# df['Mean_of_Luminosity'] = (df['Minimum_of_Luminosity'] + df['Maximum_of_Luminosity']) / 2\n",
    "# df.drop(['Minimum_of_Luminosity', 'Maximum_of_Luminosity'], axis=1, inplace=True)\n",
    "\n",
    "# 'X_Minimum' + 'X_Maximum' = 'X_Mean'\n",
    "# df['X_Mean'] = (df['X_Minimum'] + df['X_Maximum']) / 2\n",
    "# df.drop(['X_Minimum', 'X_Maximum'], axis=1, inplace=True)\n",
    "\n",
    "# 'Y_Minimum' + 'Y_Maximum' = 'Y_Mean'\n",
    "# df['Y_Mean'] = (df['Y_Minimum'] + df['Y_Maximum']) / 2\n",
    "# df.drop(['Y_Minimum', 'Y_Maximum'], axis=1, inplace=True)\n",
    "\n",
    "# 상관관계가 높은 feature 확인 (절대값 0.9이상)\n",
    "# 'X_Perimeter' + 'Pixels_Areas'\n",
    "# 'Y_Perimeter' + 'X_Perimeter'\n",
    "# 'Sum_of_Luminosity' + 'Pixels_Areas' + 'X_Perimeter'\n",
    "df.drop(['X_Perimeter', 'Y_Perimeter'], axis=1, inplace=True)\n",
    "\n",
    "# 로그 스케일링\n",
    "df['Log_Pixels_Areas'] = np.log(df['Pixels_Areas'])\n",
    "# df['Log_Sum_of_Luminosity'] = np.log(df['Sum_of_Luminosity'])\n",
    "# df['Log_Y_Mean'] = np.log(df['Y_Mean'])\n",
    "df.drop(['Pixels_Areas', 'Sum_of_Luminosity'], axis=1, inplace=True)\n",
    "\n",
    "# 중요도 낮은 특성 제거(머신러닝 분류모델에서 사용하는 기법인데 딥러닝에도 적용이 가능한가?)\n",
    "df.drop(['Outside_Global_Index', 'SigmoidOfAreas', 'Log_Y_Index'], axis=1, inplace=True)\n",
    "\n",
    "# 학습 데이터 분리\n",
    "X = df.drop(['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults', 'Fault'], axis=1)\n",
    "y = df['Fault']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 83)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum',\n",
       "       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
       "       'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index',\n",
       "       'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'LogOfAreas',\n",
       "       'Log_X_Index', 'Orientation_Index', 'Luminosity_Index', 'Pastry',\n",
       "       'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults',\n",
       "       'Fault', 'TypeOfSteel', 'Log_Pixels_Areas'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>...</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "      <th>Fault</th>\n",
       "      <th>TypeOfSteel</th>\n",
       "      <th>Log_Pixels_Areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1.939000e+03</td>\n",
       "      <td>1.939000e+03</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.00000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>571.707581</td>\n",
       "      <td>618.437855</td>\n",
       "      <td>1.649048e+06</td>\n",
       "      <td>1.649092e+06</td>\n",
       "      <td>84.626096</td>\n",
       "      <td>130.178442</td>\n",
       "      <td>1459.260959</td>\n",
       "      <td>78.777720</td>\n",
       "      <td>0.332032</td>\n",
       "      <td>0.413977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081485</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>0.201135</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.028365</td>\n",
       "      <td>0.207323</td>\n",
       "      <td>0.34657</td>\n",
       "      <td>2.569881</td>\n",
       "      <td>0.400722</td>\n",
       "      <td>5.733272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>520.654729</td>\n",
       "      <td>497.665430</td>\n",
       "      <td>1.774493e+06</td>\n",
       "      <td>1.774491e+06</td>\n",
       "      <td>32.058785</td>\n",
       "      <td>18.691238</td>\n",
       "      <td>144.616025</td>\n",
       "      <td>55.100383</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273650</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>0.400952</td>\n",
       "      <td>0.189135</td>\n",
       "      <td>0.166057</td>\n",
       "      <td>0.405494</td>\n",
       "      <td>0.47600</td>\n",
       "      <td>1.763241</td>\n",
       "      <td>0.490171</td>\n",
       "      <td>1.808779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.712000e+03</td>\n",
       "      <td>6.724000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>4.701220e+05</td>\n",
       "      <td>4.701520e+05</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1358.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.315750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.430817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>1.199744e+06</td>\n",
       "      <td>1.199753e+06</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.153292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1053.000000</td>\n",
       "      <td>1072.500000</td>\n",
       "      <td>2.182309e+06</td>\n",
       "      <td>2.182322e+06</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.695792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1705.000000</td>\n",
       "      <td>1713.000000</td>\n",
       "      <td>1.298766e+07</td>\n",
       "      <td>1.298769e+07</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>1794.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.145374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_Minimum    X_Maximum     Y_Minimum     Y_Maximum   \n",
       "count  1939.000000  1939.000000  1.939000e+03  1.939000e+03  \\\n",
       "mean    571.707581   618.437855  1.649048e+06  1.649092e+06   \n",
       "std     520.654729   497.665430  1.774493e+06  1.774491e+06   \n",
       "min       0.000000     4.000000  6.712000e+03  6.724000e+03   \n",
       "25%      52.000000   192.500000  4.701220e+05  4.701520e+05   \n",
       "50%     436.000000   470.000000  1.199744e+06  1.199753e+06   \n",
       "75%    1053.000000  1072.500000  2.182309e+06  2.182322e+06   \n",
       "max    1705.000000  1713.000000  1.298766e+07  1.298769e+07   \n",
       "\n",
       "       Minimum_of_Luminosity  Maximum_of_Luminosity  Length_of_Conveyer   \n",
       "count            1939.000000            1939.000000         1939.000000  \\\n",
       "mean               84.626096             130.178442         1459.260959   \n",
       "std                32.058785              18.691238          144.616025   \n",
       "min                 0.000000              37.000000         1227.000000   \n",
       "25%                63.000000             124.000000         1358.000000   \n",
       "50%                90.000000             127.000000         1364.000000   \n",
       "75%               106.000000             140.000000         1650.000000   \n",
       "max               203.000000             253.000000         1794.000000   \n",
       "\n",
       "       Steel_Plate_Thickness  Edges_Index  Empty_Index  ...       Pastry   \n",
       "count            1939.000000  1939.000000  1939.000000  ...  1939.000000  \\\n",
       "mean               78.777720     0.332032     0.413977  ...     0.081485   \n",
       "std                55.100383     0.299704     0.136789  ...     0.273650   \n",
       "min                40.000000     0.000000     0.000000  ...     0.000000   \n",
       "25%                40.000000     0.060400     0.315750  ...     0.000000   \n",
       "50%                70.000000     0.227800     0.412100  ...     0.000000   \n",
       "75%                80.000000     0.575500     0.501400  ...     0.000000   \n",
       "max               300.000000     0.995200     0.927500  ...     1.000000   \n",
       "\n",
       "         Z_Scratch     K_Scatch       Stains    Dirtiness        Bumps   \n",
       "count  1939.000000  1939.000000  1939.000000  1939.000000  1939.000000  \\\n",
       "mean      0.097989     0.201135     0.037133     0.028365     0.207323   \n",
       "std       0.297376     0.400952     0.189135     0.166057     0.405494   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Other_Faults        Fault  TypeOfSteel  Log_Pixels_Areas  \n",
       "count    1939.00000  1939.000000  1939.000000       1939.000000  \n",
       "mean        0.34657     2.569881     0.400722          5.733272  \n",
       "std         0.47600     1.763241     0.490171          1.808779  \n",
       "min         0.00000     0.000000     0.000000          0.693147  \n",
       "25%         0.00000     2.000000     0.000000          4.430817  \n",
       "50%         0.00000     3.000000     0.000000          5.153292  \n",
       "75%         1.00000     3.000000     1.000000          6.695792  \n",
       "max         1.00000     6.000000     1.000000         10.145374  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 크기 X_train: (1551, 20)\n",
      "원본 데이터 크기 y_train: (1551,) \n",
      "\n",
      "원본 데이터 '1' 개수: 43\n",
      "원본 데이터 '0' 개수: 318 \n",
      "\n",
      "샘플링 데이터 크기 X_train: (3710, 20)\n",
      "샘플링 데이터 크기 y_train: (3710,) \n",
      "\n",
      "샘플링 데이터 '1' 개수: 530\n",
      "샘플링 데이터 '0' 개수: 530\n"
     ]
    }
   ],
   "source": [
    "# 오버샘플링(학습데이터만)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 오버샘플링 전 클래스 분포 확인\n",
    "print('원본 데이터 크기 X_train: {}'.format(X_train.shape))\n",
    "print('원본 데이터 크기 y_train: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"원본 데이터 '1' 개수: {}\".format(sum(y_train==1)))\n",
    "print(\"원본 데이터 '0' 개수: {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "# SMOTE 적용\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "# 오버샘플링 후 클래스 분포 확인\n",
    "print('샘플링 데이터 크기 X_train: {}'.format(X_train_res.shape))\n",
    "print('샘플링 데이터 크기 y_train: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"샘플링 데이터 '1' 개수: {}\".format(sum(y_train_res==1)))\n",
    "print(\"샘플링 데이터 '0' 개수: {}\".format(sum(y_train_res==0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orientation_Index        0.136810\n",
      "Empty_Index              0.129313\n",
      "Minimum_of_Luminosity    0.093402\n",
      "Edges_Y_Index            0.076571\n",
      "Steel_Plate_Thickness    0.058778\n",
      "TypeOfSteel              0.040343\n",
      "Luminosity_Index        -0.033933\n",
      "Outside_X_Index         -0.096823\n",
      "Maximum_of_Luminosity   -0.097424\n",
      "Log_Pixels_Areas        -0.107178\n",
      "LogOfAreas              -0.107178\n",
      "Edges_X_Index           -0.110439\n",
      "Log_X_Index             -0.133517\n",
      "Edges_Index             -0.136113\n",
      "Y_Maximum               -0.144896\n",
      "Y_Minimum               -0.144897\n",
      "X_Minimum               -0.156552\n",
      "Square_Index            -0.180232\n",
      "X_Maximum               -0.180858\n",
      "Length_of_Conveyer      -0.206868\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟값과 각 변수들 간의 상관관계\n",
    "co = X_train.corrwith(y_train)\n",
    "\n",
    "# 상관계수를 내림차순으로 정리\n",
    "print(co.sort_values(ascending=False))\n",
    "\n",
    "# 절대값\n",
    "co_abs = abs(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일링할 피처 선택\n",
    "scaling_features = X_train.columns\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = X_train.copy()  # 원본 데이터 복사\n",
    "X_test_scaled = X_test.copy()    # 원본 데이터 복사\n",
    "X_train_scaled[scaling_features] = scaler.fit_transform(X_train[scaling_features])\n",
    "X_test_scaled[scaling_features] = scaler.transform(X_test[scaling_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 01:15:57.239484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 하이퍼파라미터 랜덤\n",
    "import random\n",
    "\n",
    "# 유닛 랜덤\n",
    "def units_random():\n",
    "    # 2의 7제곱 (128)부터 2의 10제곱 (1024)까지\n",
    "    possible_values = [2**i for i in range(7, 11)]\n",
    "\n",
    "    # 랜덤하게 8개 선택, 중복 허용\n",
    "    units = [random.choice(possible_values) for _ in range(8)]\n",
    "\n",
    "    print(f\"units : {units}\")\n",
    "    \n",
    "    return units\n",
    "\n",
    "# L2 랜덤\n",
    "def L2_random():\n",
    "    # 0.001부터 0.015까지 0.001의 간격으로\n",
    "    possible_values = np.arange(0.001, 0.016, 0.001)\n",
    "\n",
    "    # 랜덤하게 8개 선택, 중복 허용\n",
    "    L2 = [random.choice(possible_values) for _ in range(8)]\n",
    "    L2 = [round(num, 3) for num in L2]\n",
    "\n",
    "    print(f\"L2 : {L2}\")\n",
    "    \n",
    "    return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이스모델\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def Classifier_Model(units, l2):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=units[0], activation='relu', input_shape=(len(X_train.keys()),), kernel_regularizer=regularizers.l2(l2[0])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[1], activation='relu', kernel_regularizer=regularizers.l2(l2[1])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[2], activation='relu', kernel_regularizer=regularizers.l2(l2[2])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[3], activation='relu', kernel_regularizer=regularizers.l2(l2[3])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[4], activation='relu', kernel_regularizer=regularizers.l2(l2[4])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[5], activation='relu', kernel_regularizer=regularizers.l2(l2[5])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[6], activation='relu', kernel_regularizer=regularizers.l2(l2[6])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=units[7], activation='relu', kernel_regularizer=regularizers.l2(l2[7])),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(units=7, activation='softmax') # 출력 유닛의 수를 클래스 수에 맞추고, softmax 활성화 함수를 사용\n",
    "    ])\n",
    "    \n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',  # 손실함수를 다중 클래스 분류에 적합한 형태로 변경\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스킵 연결 모델(Skip Connection)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def Classifier_Model_SC(units, l2):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    inputs = Input(shape=(len(X_train.keys()),))\n",
    "    x = Dense(units=units[0], activation='relu', kernel_regularizer=regularizers.l2(l2[0]))(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    for i in range(1, 8):   \n",
    "        dense = Dense(units=units[i], activation='relu', kernel_regularizer=regularizers.l2(l2[i]))\n",
    "        y = dense(x)\n",
    "        y = Dropout(0.2)(y)\n",
    "        x = Add()([x, y])\n",
    "\n",
    "    outputs = Dense(units=7, activation='softmax')(x) # 출력 유닛의 수를 클래스 수에 맞추고, softmax 활성화 함수를 사용\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',  # 손실함수를 다중 클래스 분류에 적합한 형태로 변경\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 랜덤 서치\\n# 하이퍼파라미터 세팅\\nnp.random.seed(42)\\ntf.random.set_seed(42)\\n\\nLEARNING_RATE = 0.001\\nEPOCHS = 1024\\nMB_SIZE = 1024\\nREPORT = 1\\nTRAIN_RATIO = 0.8\\n\\n# 학습 자동 중단 설정\\nes = EarlyStopping(monitor=\\'loss\\', patience=128, mode=\\'min\\')\\nrlrp = ReduceLROnPlateau(monitor=\\'loss\\', factor=0.2, patience=128, mode=\\'min\\')\\n\\naccuracy_list = []\\n\\nwhile True:  \\n    model = Classifier_Model(units_random(), L2_random())\\n    \\n    # 모델 학습\\n    history = model.fit(\\n    X_train_scaled, y_train,\\n    batch_size=MB_SIZE,\\n    validation_split = 0.2,\\n    verbose=1,\\n    epochs=EPOCHS,\\n    callbacks=[es, rlrp]\\n    )\\n    \\n    # 테스트 세트 평가\\n    loss, accuracy = model.evaluate(X_test_scaled, y_test)\\n    print(\"Test Loss:\", round(loss, 3))\\n    print(\"Test Accuracy:\", round(accuracy, 3))\\n    \\n    accuracy_list.append(accuracy)\\n    \\n    if len(accuracy_list) >= 10:\\n        max_accuracy = max(accuracy_list)\\n        units, L2 = units_random(), L2_random()\\n        print(\"Maximum Accuracy:\", max_accuracy)\\n        print(\"units:\", units)\\n        print(\"L2\", L2)\\n        \\n        break\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 랜덤 서치\n",
    "# 하이퍼파라미터 세팅\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1024\n",
    "MB_SIZE = 1024\n",
    "REPORT = 1\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=128, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=128, mode='min')\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "while True:  \n",
    "    model = Classifier_Model(units_random(), L2_random())\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    batch_size=MB_SIZE,\n",
    "    validation_split = 0.2,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[es, rlrp]\n",
    "    )\n",
    "    \n",
    "    # 테스트 세트 평가\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "    print(\"Test Loss:\", round(loss, 3))\n",
    "    print(\"Test Accuracy:\", round(accuracy, 3))\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    if len(accuracy_list) >= 10:\n",
    "        max_accuracy = max(accuracy_list)\n",
    "        units, L2 = units_random(), L2_random()\n",
    "        print(\"Maximum Accuracy:\", max_accuracy)\n",
    "        print(\"units:\", units)\n",
    "        print(\"L2\", L2)\n",
    "        \n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 앙상블 모델\\n# 앙상블 모델\\ndef Ensemble(num_models = 5):\\n    np.random.seed(42)\\n    tf.random.set_seed(42)\\n    \\n    models = []\\n    \\n    # 하이퍼파라미터 세팅\\n    LEARNING_RATE = 0.001\\n    EPOCHS = 1024\\n    MB_SIZE = 2000\\n    REPORT = 1\\n    TRAIN_RATIO = 0.8\\n    \\n    # 학습 자동 중단 설정\\n    es = EarlyStopping(monitor=\\'loss\\', patience=64, mode=\\'min\\')\\n    rlrp = ReduceLROnPlateau(monitor=\\'loss\\', factor=0.15, patience=64, mode=\\'min\\')\\n    \\n    optimizer = tf.keras.optimizers.Adam(\\n                                        learning_rate=0.001,\\n                                        beta_1=0.9,\\n                                        beta_2=0.999,\\n                                        epsilon=1e-08\\n                                        )\\n\\n    for _ in range(num_models):\\n        model = Classifier_Model()\\n        models.append(model)\\n\\n    histories = []\\n    for i in range(num_models):\\n        history = models[i].fit(\\n                                X_train_scaled, y_train,\\n                                batch_size=MB_SIZE,\\n                                validation_split = 0.2,\\n                                verbose=1,\\n                                epochs=EPOCHS,\\n                                callbacks=[es, rlrp]\\n                                )\\n        \\n        histories.append(history)\\n\\n    # 각 모델의 예측값을 얻고 평균을 냅니다\\n    predictions = []\\n    for model in models:\\n        loss, accuracy = model.evaluate(X_test_scaled, y_test)\\n        predictions.append(loss, accuracy)\\n        print(\"Test Loss:\", round(loss, 3))\\n        print(\"Test Accuracy:\", round(accuracy, 3))\\n\\n    # 최종 예측값은 여러 모델의 예측값을 평균낸 것입니다\\n    final_predictions = np.mean(predictions, axis=0)\\n    \\n    return final_predictions\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 앙상블 모델\n",
    "# 앙상블 모델\n",
    "def Ensemble(num_models = 5):\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    # 하이퍼파라미터 세팅\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 1024\n",
    "    MB_SIZE = 2000\n",
    "    REPORT = 1\n",
    "    TRAIN_RATIO = 0.8\n",
    "    \n",
    "    # 학습 자동 중단 설정\n",
    "    es = EarlyStopping(monitor='loss', patience=64, mode='min')\n",
    "    rlrp = ReduceLROnPlateau(monitor='loss', factor=0.15, patience=64, mode='min')\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08\n",
    "                                        )\n",
    "\n",
    "    for _ in range(num_models):\n",
    "        model = Classifier_Model()\n",
    "        models.append(model)\n",
    "\n",
    "    histories = []\n",
    "    for i in range(num_models):\n",
    "        history = models[i].fit(\n",
    "                                X_train_scaled, y_train,\n",
    "                                batch_size=MB_SIZE,\n",
    "                                validation_split = 0.2,\n",
    "                                verbose=1,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[es, rlrp]\n",
    "                                )\n",
    "        \n",
    "        histories.append(history)\n",
    "\n",
    "    # 각 모델의 예측값을 얻고 평균을 냅니다\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "        predictions.append(loss, accuracy)\n",
    "        print(\"Test Loss:\", round(loss, 3))\n",
    "        print(\"Test Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "    # 최종 예측값은 여러 모델의 예측값을 평균낸 것입니다\n",
    "    final_predictions = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return final_predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "\"\"\"\n",
    "units = [33, 64, 128, 256, 256, 128, 64, 33]\n",
    "L2 = [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000]\n",
    "model = Classifier_Model(units, L2)\n",
    "\"\"\"\n",
    "units = [256 for _ in range(8)]\n",
    "L2 = [0.001 + i * 0.0025 for i in range(8)]\n",
    "model = Classifier_Model_SC(units, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='accuracy', patience=256, mode='auto')\n",
    "rlrp = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=256, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.callbacks import ModelCheckpoint\\n\\n# 모델 체크포인트를 설정합니다.\\ncheckpoint = ModelCheckpoint('best_val_acc_weights.h5',  # 저장될 파일 이름\\n                             monitor='val_accuracy',  # 모니터링 할 지표\\n                             verbose=1,  \\n                             save_best_only=True,  # 가장 좋은 모델만 저장할지 결정\\n                             mode='max',  # 'val_accuracy'를 최대로 유지하는 모델을 저장\\n                             save_weights_only=True)  # 가중치만 저장할지 결정\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델 체크포인트를 설정합니다.\n",
    "checkpoint = ModelCheckpoint('best_val_acc_weights.h5',  # 저장될 파일 이름\n",
    "                             monitor='val_accuracy',  # 모니터링 할 지표\n",
    "                             verbose=1,  \n",
    "                             save_best_only=True,  # 가장 좋은 모델만 저장할지 결정\n",
    "                             mode='max',  # 'val_accuracy'를 최대로 유지하는 모델을 저장\n",
    "                             save_weights_only=True)  # 가중치만 저장할지 결정\n",
    "\"\"\"                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, max_models_to_save=5):\n",
    "        super().__init__()\n",
    "        self.max_models_to_save = max_models_to_save\n",
    "        self.saved_models = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get('val_accuracy', 0.0)\n",
    "        model_weights = self.model.get_weights()\n",
    "\n",
    "        # 첫 번째 에포크이거나 새로운 val_accuracy가 이전보다 높을 때만 모델 저장\n",
    "        if not self.saved_models or val_accuracy > min(self.saved_models, key=lambda x: x[0])[0]:\n",
    "            self.saved_models.append((val_accuracy, model_weights))\n",
    "            self.saved_models = sorted(self.saved_models, key=lambda x: -x[0])[:self.max_models_to_save]\n",
    "\n",
    "# 사용자 정의 콜백을 생성\n",
    "custom_checkpoint = CustomModelCheckpoint(max_models_to_save=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 01:16:11.002438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-24 01:16:11.008961: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x34694d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-24 01:16:11.009006: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-24 01:16:11.015816: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-24 01:16:13.152239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-05-24 01:16:13.306818: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 8s 96ms/step - loss: 22.4935 - accuracy: 0.2395 - val_loss: 20.4487 - val_accuracy: 0.4695 - lr: 0.0010\n",
      "Epoch 2/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.0645 - accuracy: 0.3532 - val_loss: 19.1404 - val_accuracy: 0.4502 - lr: 0.0010\n",
      "Epoch 3/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.7325 - accuracy: 0.4694 - val_loss: 17.9142 - val_accuracy: 0.5145 - lr: 0.0010\n",
      "Epoch 4/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.4952 - accuracy: 0.5339 - val_loss: 16.6838 - val_accuracy: 0.6077 - lr: 0.0010\n",
      "Epoch 5/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.3153 - accuracy: 0.5605 - val_loss: 15.5751 - val_accuracy: 0.5820 - lr: 0.0010\n",
      "Epoch 6/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2328 - accuracy: 0.5726 - val_loss: 14.5068 - val_accuracy: 0.6302 - lr: 0.0010\n",
      "Epoch 7/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.2018 - accuracy: 0.6024 - val_loss: 13.5132 - val_accuracy: 0.6141 - lr: 0.0010\n",
      "Epoch 8/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.2282 - accuracy: 0.6145 - val_loss: 12.5927 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 9/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3136 - accuracy: 0.6298 - val_loss: 11.7147 - val_accuracy: 0.6495 - lr: 0.0010\n",
      "Epoch 10/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.4836 - accuracy: 0.6419 - val_loss: 10.9354 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 11/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.7317 - accuracy: 0.6444 - val_loss: 10.2024 - val_accuracy: 0.6785 - lr: 0.0010\n",
      "Epoch 12/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0102 - accuracy: 0.6613 - val_loss: 9.5393 - val_accuracy: 0.6720 - lr: 0.0010\n",
      "Epoch 13/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3862 - accuracy: 0.6581 - val_loss: 8.9369 - val_accuracy: 0.6977 - lr: 0.0010\n",
      "Epoch 14/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7731 - accuracy: 0.6637 - val_loss: 8.3804 - val_accuracy: 0.6913 - lr: 0.0010\n",
      "Epoch 15/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2307 - accuracy: 0.6766 - val_loss: 7.8505 - val_accuracy: 0.6849 - lr: 0.0010\n",
      "Epoch 16/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7253 - accuracy: 0.6653 - val_loss: 7.4029 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 17/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2495 - accuracy: 0.6782 - val_loss: 6.9387 - val_accuracy: 0.6817 - lr: 0.0010\n",
      "Epoch 18/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8226 - accuracy: 0.6927 - val_loss: 6.5656 - val_accuracy: 0.7042 - lr: 0.0010\n",
      "Epoch 19/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4070 - accuracy: 0.7089 - val_loss: 6.1858 - val_accuracy: 0.6720 - lr: 0.0010\n",
      "Epoch 20/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0855 - accuracy: 0.6831 - val_loss: 5.8387 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 21/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.7039 - accuracy: 0.7048 - val_loss: 5.5051 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 22/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.4095 - accuracy: 0.7016 - val_loss: 5.2297 - val_accuracy: 0.6817 - lr: 0.0010\n",
      "Epoch 23/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1268 - accuracy: 0.7097 - val_loss: 4.9464 - val_accuracy: 0.7074 - lr: 0.0010\n",
      "Epoch 24/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8592 - accuracy: 0.7048 - val_loss: 4.7066 - val_accuracy: 0.6977 - lr: 0.0010\n",
      "Epoch 25/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6160 - accuracy: 0.7048 - val_loss: 4.4798 - val_accuracy: 0.6945 - lr: 0.0010\n",
      "Epoch 26/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.3819 - accuracy: 0.7169 - val_loss: 4.2353 - val_accuracy: 0.7138 - lr: 0.0010\n",
      "Epoch 27/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.1377 - accuracy: 0.7194 - val_loss: 4.0486 - val_accuracy: 0.7138 - lr: 0.0010\n",
      "Epoch 28/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.9470 - accuracy: 0.7210 - val_loss: 3.8644 - val_accuracy: 0.7042 - lr: 0.0010\n",
      "Epoch 29/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7680 - accuracy: 0.7274 - val_loss: 3.6709 - val_accuracy: 0.7074 - lr: 0.0010\n",
      "Epoch 30/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5871 - accuracy: 0.7403 - val_loss: 3.4956 - val_accuracy: 0.6945 - lr: 0.0010\n",
      "Epoch 31/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4141 - accuracy: 0.7258 - val_loss: 3.3557 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 32/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.2659 - accuracy: 0.7355 - val_loss: 3.1949 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 33/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1187 - accuracy: 0.7339 - val_loss: 3.0574 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 34/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9936 - accuracy: 0.7290 - val_loss: 2.9491 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 35/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.8757 - accuracy: 0.7371 - val_loss: 2.8361 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 36/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.7514 - accuracy: 0.7452 - val_loss: 2.7193 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 37/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6576 - accuracy: 0.7234 - val_loss: 2.6329 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 38/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5586 - accuracy: 0.7194 - val_loss: 2.5002 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 39/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4474 - accuracy: 0.7444 - val_loss: 2.4319 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 40/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.3555 - accuracy: 0.7500 - val_loss: 2.3371 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 41/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.2469 - accuracy: 0.7484 - val_loss: 2.2452 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 42/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2.1688 - accuracy: 0.7573 - val_loss: 2.1673 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 43/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.0888 - accuracy: 0.7548 - val_loss: 2.0919 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 44/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0176 - accuracy: 0.7508 - val_loss: 2.0446 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 45/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9537 - accuracy: 0.7540 - val_loss: 1.9726 - val_accuracy: 0.7138 - lr: 0.0010\n",
      "Epoch 46/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.9105 - accuracy: 0.7516 - val_loss: 1.9361 - val_accuracy: 0.7074 - lr: 0.0010\n",
      "Epoch 47/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.8526 - accuracy: 0.7387 - val_loss: 1.8352 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 48/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.7720 - accuracy: 0.7629 - val_loss: 1.8004 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 49/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7265 - accuracy: 0.7500 - val_loss: 1.7457 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 50/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6604 - accuracy: 0.7629 - val_loss: 1.7007 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 51/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.6134 - accuracy: 0.7710 - val_loss: 1.6481 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 52/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5741 - accuracy: 0.7653 - val_loss: 1.6314 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 53/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5439 - accuracy: 0.7573 - val_loss: 1.5702 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 54/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4847 - accuracy: 0.7613 - val_loss: 1.5376 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 55/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4526 - accuracy: 0.7750 - val_loss: 1.4829 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 56/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4080 - accuracy: 0.7669 - val_loss: 1.4686 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 57/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3827 - accuracy: 0.7605 - val_loss: 1.4266 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 58/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3644 - accuracy: 0.7581 - val_loss: 1.4211 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 59/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3195 - accuracy: 0.7782 - val_loss: 1.4083 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 60/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3155 - accuracy: 0.7444 - val_loss: 1.3823 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 61/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2816 - accuracy: 0.7573 - val_loss: 1.3473 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 62/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2401 - accuracy: 0.7661 - val_loss: 1.2953 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 63/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2209 - accuracy: 0.7524 - val_loss: 1.2855 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 64/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1896 - accuracy: 0.7774 - val_loss: 1.2404 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 65/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1705 - accuracy: 0.7661 - val_loss: 1.2396 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 66/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1421 - accuracy: 0.7710 - val_loss: 1.2171 - val_accuracy: 0.7138 - lr: 0.0010\n",
      "Epoch 67/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1206 - accuracy: 0.7694 - val_loss: 1.1955 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 68/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0913 - accuracy: 0.7798 - val_loss: 1.1555 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 69/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0616 - accuracy: 0.7839 - val_loss: 1.1539 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 70/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0460 - accuracy: 0.7855 - val_loss: 1.1222 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 71/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0342 - accuracy: 0.7766 - val_loss: 1.1247 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 72/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0325 - accuracy: 0.7637 - val_loss: 1.0930 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 73/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.0158 - accuracy: 0.7790 - val_loss: 1.0909 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 74/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9881 - accuracy: 0.7903 - val_loss: 1.0925 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 75/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9994 - accuracy: 0.7782 - val_loss: 1.0413 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 76/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.9554 - accuracy: 0.7952 - val_loss: 1.0651 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 77/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.9614 - accuracy: 0.7758 - val_loss: 1.0531 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 78/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.9636 - accuracy: 0.7758 - val_loss: 1.0443 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 79/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9403 - accuracy: 0.7702 - val_loss: 1.0144 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 80/1024\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.9345 - accuracy: 0.7774 - val_loss: 1.0146 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 81/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9411 - accuracy: 0.7742 - val_loss: 1.0212 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 82/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9078 - accuracy: 0.7790 - val_loss: 0.9700 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 83/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8757 - accuracy: 0.7903 - val_loss: 0.9812 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 84/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.8879 - accuracy: 0.7774 - val_loss: 0.9558 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 85/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8545 - accuracy: 0.7935 - val_loss: 0.9622 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 86/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8639 - accuracy: 0.7887 - val_loss: 0.9572 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 87/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8553 - accuracy: 0.7855 - val_loss: 0.9555 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 88/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.8602 - accuracy: 0.7815 - val_loss: 0.9398 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 89/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8218 - accuracy: 0.7911 - val_loss: 0.9647 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 90/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8339 - accuracy: 0.7847 - val_loss: 0.9455 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 91/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8284 - accuracy: 0.7903 - val_loss: 0.9294 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 92/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.8228 - accuracy: 0.7944 - val_loss: 0.9161 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 93/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.8026 - accuracy: 0.7863 - val_loss: 0.9552 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 94/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.8184 - accuracy: 0.7847 - val_loss: 0.9078 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 95/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.8343 - accuracy: 0.7613 - val_loss: 0.9544 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 96/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8241 - accuracy: 0.7734 - val_loss: 0.9046 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 97/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8147 - accuracy: 0.7815 - val_loss: 0.9028 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 98/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7873 - accuracy: 0.7944 - val_loss: 0.8838 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 99/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7933 - accuracy: 0.7847 - val_loss: 0.8779 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 100/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7755 - accuracy: 0.7927 - val_loss: 0.8755 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 101/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7632 - accuracy: 0.7976 - val_loss: 0.8997 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 102/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7747 - accuracy: 0.7806 - val_loss: 0.9114 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 103/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7625 - accuracy: 0.8073 - val_loss: 0.8550 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 104/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7561 - accuracy: 0.8081 - val_loss: 0.9049 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 105/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.7631 - accuracy: 0.7919 - val_loss: 0.8695 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 106/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7381 - accuracy: 0.7944 - val_loss: 0.8958 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 107/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7587 - accuracy: 0.7871 - val_loss: 0.8922 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 108/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.7423 - accuracy: 0.7984 - val_loss: 0.8469 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 109/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7260 - accuracy: 0.8121 - val_loss: 0.8521 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 110/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7290 - accuracy: 0.7927 - val_loss: 0.8677 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 111/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7210 - accuracy: 0.8129 - val_loss: 0.8320 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 112/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.7207 - accuracy: 0.8040 - val_loss: 0.8474 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 113/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.7161 - accuracy: 0.7984 - val_loss: 0.8406 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 114/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.7128 - accuracy: 0.8000 - val_loss: 0.8511 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 115/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.7269 - accuracy: 0.7952 - val_loss: 0.8274 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 116/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7149 - accuracy: 0.8065 - val_loss: 0.8536 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 117/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6960 - accuracy: 0.8008 - val_loss: 0.8319 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 118/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7176 - accuracy: 0.8065 - val_loss: 0.8548 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 119/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7107 - accuracy: 0.8065 - val_loss: 0.8404 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 120/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6901 - accuracy: 0.8048 - val_loss: 0.8208 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 121/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6984 - accuracy: 0.8065 - val_loss: 0.8535 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 122/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7256 - accuracy: 0.7935 - val_loss: 0.8387 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 123/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.7037 - accuracy: 0.8048 - val_loss: 0.8496 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 124/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7084 - accuracy: 0.7935 - val_loss: 0.8113 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 125/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6901 - accuracy: 0.8024 - val_loss: 0.8492 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 126/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6893 - accuracy: 0.8081 - val_loss: 0.8138 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 127/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6747 - accuracy: 0.7960 - val_loss: 0.8124 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 128/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6778 - accuracy: 0.8097 - val_loss: 0.8184 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 129/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6853 - accuracy: 0.7927 - val_loss: 0.8152 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 130/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7004 - accuracy: 0.7935 - val_loss: 0.8056 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 131/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.7012 - accuracy: 0.8008 - val_loss: 0.8363 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 132/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6703 - accuracy: 0.8081 - val_loss: 0.7987 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 133/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6757 - accuracy: 0.8161 - val_loss: 0.8492 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 134/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6686 - accuracy: 0.8065 - val_loss: 0.7999 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 135/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6600 - accuracy: 0.8129 - val_loss: 0.8081 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 136/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6596 - accuracy: 0.8145 - val_loss: 0.7985 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 137/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6540 - accuracy: 0.8202 - val_loss: 0.8223 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 138/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6737 - accuracy: 0.8040 - val_loss: 0.8019 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 139/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6537 - accuracy: 0.8161 - val_loss: 0.8847 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 140/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6772 - accuracy: 0.8008 - val_loss: 0.8003 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 141/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6721 - accuracy: 0.8081 - val_loss: 0.8568 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 142/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6903 - accuracy: 0.8000 - val_loss: 0.8098 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 143/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6698 - accuracy: 0.8105 - val_loss: 0.8433 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 144/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6707 - accuracy: 0.8065 - val_loss: 0.8059 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 145/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6711 - accuracy: 0.8073 - val_loss: 0.8291 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 146/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6823 - accuracy: 0.7968 - val_loss: 0.8028 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 147/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6653 - accuracy: 0.8137 - val_loss: 0.7944 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 148/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6411 - accuracy: 0.8194 - val_loss: 0.8241 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 149/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6609 - accuracy: 0.8129 - val_loss: 0.8182 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 150/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6568 - accuracy: 0.8161 - val_loss: 0.7708 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 151/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6453 - accuracy: 0.8210 - val_loss: 0.8145 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 152/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6458 - accuracy: 0.8274 - val_loss: 0.7850 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 153/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6459 - accuracy: 0.8177 - val_loss: 0.8500 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 154/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6561 - accuracy: 0.8065 - val_loss: 0.7796 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 155/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6336 - accuracy: 0.8210 - val_loss: 0.8036 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 156/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6441 - accuracy: 0.8234 - val_loss: 0.8340 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 157/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6537 - accuracy: 0.8129 - val_loss: 0.7931 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 158/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6364 - accuracy: 0.8121 - val_loss: 0.7877 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 159/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6330 - accuracy: 0.8242 - val_loss: 0.8362 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 160/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6464 - accuracy: 0.8113 - val_loss: 0.8019 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 161/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6274 - accuracy: 0.8194 - val_loss: 0.7941 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 162/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6342 - accuracy: 0.8161 - val_loss: 0.7835 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 163/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6423 - accuracy: 0.8145 - val_loss: 0.7969 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 164/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6483 - accuracy: 0.8153 - val_loss: 0.7855 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 165/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6356 - accuracy: 0.8226 - val_loss: 0.7869 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 166/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6236 - accuracy: 0.8355 - val_loss: 0.8257 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 167/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6413 - accuracy: 0.8266 - val_loss: 0.8038 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 168/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.6237 - accuracy: 0.8298 - val_loss: 0.8005 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 169/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6358 - accuracy: 0.8258 - val_loss: 0.8030 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 170/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6215 - accuracy: 0.8274 - val_loss: 0.7944 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 171/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6134 - accuracy: 0.8331 - val_loss: 0.8352 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 172/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6284 - accuracy: 0.8234 - val_loss: 0.8212 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 173/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6196 - accuracy: 0.8234 - val_loss: 0.7826 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 174/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6089 - accuracy: 0.8363 - val_loss: 0.8014 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 175/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6089 - accuracy: 0.8274 - val_loss: 0.7900 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 176/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6277 - accuracy: 0.8234 - val_loss: 0.8138 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 177/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6306 - accuracy: 0.8177 - val_loss: 0.7814 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 178/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6550 - accuracy: 0.8113 - val_loss: 0.7875 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 179/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6348 - accuracy: 0.8177 - val_loss: 0.8416 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 180/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6586 - accuracy: 0.8081 - val_loss: 0.7826 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 181/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6237 - accuracy: 0.8266 - val_loss: 0.8029 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 182/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6122 - accuracy: 0.8411 - val_loss: 0.8167 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 183/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6216 - accuracy: 0.8250 - val_loss: 0.8134 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 184/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6107 - accuracy: 0.8347 - val_loss: 0.8368 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 185/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6477 - accuracy: 0.8056 - val_loss: 0.7977 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 186/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.6455 - accuracy: 0.8024 - val_loss: 0.8318 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 187/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6356 - accuracy: 0.8218 - val_loss: 0.7866 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 188/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6196 - accuracy: 0.8234 - val_loss: 0.7901 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 189/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6086 - accuracy: 0.8339 - val_loss: 0.7910 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 190/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6119 - accuracy: 0.8411 - val_loss: 0.8128 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 191/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6045 - accuracy: 0.8323 - val_loss: 0.7853 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 192/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5886 - accuracy: 0.8306 - val_loss: 0.7783 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 193/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5931 - accuracy: 0.8363 - val_loss: 0.8398 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 194/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6166 - accuracy: 0.8323 - val_loss: 0.7871 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 195/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5988 - accuracy: 0.8339 - val_loss: 0.8131 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 196/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6037 - accuracy: 0.8250 - val_loss: 0.8141 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 197/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5993 - accuracy: 0.8452 - val_loss: 0.7865 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 198/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - accuracy: 0.8355 - val_loss: 0.8056 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 199/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5974 - accuracy: 0.8403 - val_loss: 0.7970 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 200/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5777 - accuracy: 0.8500 - val_loss: 0.7776 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 201/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5825 - accuracy: 0.8492 - val_loss: 0.7916 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 202/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6087 - accuracy: 0.8298 - val_loss: 0.7959 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 203/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6141 - accuracy: 0.8331 - val_loss: 0.8200 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 204/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6140 - accuracy: 0.8242 - val_loss: 0.8295 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 205/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6123 - accuracy: 0.8282 - val_loss: 0.8194 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 206/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5921 - accuracy: 0.8411 - val_loss: 0.7632 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 207/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.5931 - accuracy: 0.8460 - val_loss: 0.8036 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 208/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5916 - accuracy: 0.8516 - val_loss: 0.7892 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 209/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5877 - accuracy: 0.8435 - val_loss: 0.7950 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 210/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5805 - accuracy: 0.8476 - val_loss: 0.7923 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 211/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5857 - accuracy: 0.8403 - val_loss: 0.8137 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 212/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6137 - accuracy: 0.8250 - val_loss: 0.8450 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 213/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5961 - accuracy: 0.8427 - val_loss: 0.7757 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 214/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5667 - accuracy: 0.8492 - val_loss: 0.7929 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 215/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5773 - accuracy: 0.8565 - val_loss: 0.7823 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 216/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5732 - accuracy: 0.8508 - val_loss: 0.8004 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 217/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5920 - accuracy: 0.8403 - val_loss: 0.7827 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 218/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6237 - accuracy: 0.8202 - val_loss: 0.7842 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 219/1024\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6224 - accuracy: 0.8129 - val_loss: 0.8653 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 220/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6096 - accuracy: 0.8315 - val_loss: 0.7923 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 221/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6233 - accuracy: 0.8282 - val_loss: 0.8406 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 222/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6026 - accuracy: 0.8444 - val_loss: 0.8342 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 223/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6061 - accuracy: 0.8355 - val_loss: 0.8323 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 224/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5759 - accuracy: 0.8532 - val_loss: 0.8086 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 225/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - accuracy: 0.8435 - val_loss: 0.8567 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 226/1024\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5838 - accuracy: 0.8460 - val_loss: 0.8304 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 227/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5986 - accuracy: 0.8315 - val_loss: 0.8447 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 228/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5844 - accuracy: 0.8395 - val_loss: 0.7810 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 229/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5737 - accuracy: 0.8484 - val_loss: 0.8021 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 230/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5767 - accuracy: 0.8427 - val_loss: 0.8018 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 231/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5762 - accuracy: 0.8468 - val_loss: 0.7929 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 232/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5877 - accuracy: 0.8298 - val_loss: 0.8232 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 233/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5898 - accuracy: 0.8468 - val_loss: 0.8132 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 234/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5674 - accuracy: 0.8524 - val_loss: 0.7880 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 235/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5573 - accuracy: 0.8597 - val_loss: 0.7889 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 236/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5619 - accuracy: 0.8565 - val_loss: 0.8018 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 237/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5673 - accuracy: 0.8484 - val_loss: 0.8014 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 238/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6078 - accuracy: 0.8290 - val_loss: 0.8223 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 239/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5919 - accuracy: 0.8387 - val_loss: 0.8182 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 240/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5757 - accuracy: 0.8452 - val_loss: 0.8290 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 241/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5740 - accuracy: 0.8468 - val_loss: 0.7893 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 242/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6019 - accuracy: 0.8323 - val_loss: 0.8785 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 243/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6077 - accuracy: 0.8347 - val_loss: 0.7936 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 244/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5933 - accuracy: 0.8444 - val_loss: 0.8013 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 245/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5767 - accuracy: 0.8508 - val_loss: 0.7869 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 246/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5703 - accuracy: 0.8597 - val_loss: 0.7981 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 247/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5773 - accuracy: 0.8395 - val_loss: 0.7942 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 248/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5605 - accuracy: 0.8548 - val_loss: 0.7995 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 249/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5665 - accuracy: 0.8476 - val_loss: 0.8335 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 250/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5723 - accuracy: 0.8581 - val_loss: 0.7864 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 251/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5718 - accuracy: 0.8444 - val_loss: 0.8035 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 252/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5746 - accuracy: 0.8484 - val_loss: 0.7983 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 253/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5826 - accuracy: 0.8508 - val_loss: 0.7714 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 254/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5796 - accuracy: 0.8444 - val_loss: 0.8338 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 255/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5626 - accuracy: 0.8581 - val_loss: 0.7912 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 256/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5512 - accuracy: 0.8613 - val_loss: 0.8144 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 257/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5570 - accuracy: 0.8532 - val_loss: 0.8141 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 258/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5526 - accuracy: 0.8629 - val_loss: 0.8192 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 259/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5622 - accuracy: 0.8427 - val_loss: 0.8168 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 260/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5772 - accuracy: 0.8395 - val_loss: 0.8732 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 261/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.5817 - accuracy: 0.8516 - val_loss: 0.8520 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 262/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5840 - accuracy: 0.8500 - val_loss: 0.7941 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 263/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5693 - accuracy: 0.8516 - val_loss: 0.8156 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 264/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5601 - accuracy: 0.8573 - val_loss: 0.7747 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 265/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5270 - accuracy: 0.8823 - val_loss: 0.8000 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 266/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5437 - accuracy: 0.8645 - val_loss: 0.8056 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 267/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5451 - accuracy: 0.8605 - val_loss: 0.8828 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 268/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5909 - accuracy: 0.8460 - val_loss: 0.8666 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 269/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5958 - accuracy: 0.8444 - val_loss: 0.7895 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 270/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5616 - accuracy: 0.8556 - val_loss: 0.7681 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 271/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5506 - accuracy: 0.8702 - val_loss: 0.8011 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 272/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5345 - accuracy: 0.8685 - val_loss: 0.8215 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 273/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5296 - accuracy: 0.8613 - val_loss: 0.8063 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 274/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5292 - accuracy: 0.8710 - val_loss: 0.7974 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 275/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5210 - accuracy: 0.8718 - val_loss: 0.8117 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 276/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5400 - accuracy: 0.8621 - val_loss: 0.7989 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 277/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5451 - accuracy: 0.8637 - val_loss: 0.8060 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 278/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5693 - accuracy: 0.8435 - val_loss: 0.7909 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 279/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5762 - accuracy: 0.8435 - val_loss: 0.7987 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 280/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5574 - accuracy: 0.8605 - val_loss: 0.8338 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 281/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5618 - accuracy: 0.8532 - val_loss: 0.7922 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 282/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5459 - accuracy: 0.8597 - val_loss: 0.8071 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 283/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5213 - accuracy: 0.8839 - val_loss: 0.8076 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 284/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5502 - accuracy: 0.8524 - val_loss: 0.8512 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 285/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5524 - accuracy: 0.8565 - val_loss: 0.8604 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 286/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5633 - accuracy: 0.8589 - val_loss: 0.8003 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 287/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5453 - accuracy: 0.8685 - val_loss: 0.7980 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 288/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5527 - accuracy: 0.8710 - val_loss: 0.8237 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 289/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5497 - accuracy: 0.8621 - val_loss: 0.8214 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 290/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5442 - accuracy: 0.8556 - val_loss: 0.8232 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 291/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5408 - accuracy: 0.8645 - val_loss: 0.8454 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 292/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5480 - accuracy: 0.8605 - val_loss: 0.8274 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 293/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5278 - accuracy: 0.8718 - val_loss: 0.7987 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 294/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5423 - accuracy: 0.8637 - val_loss: 0.8004 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 295/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5229 - accuracy: 0.8766 - val_loss: 0.8282 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 296/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5530 - accuracy: 0.8661 - val_loss: 0.8364 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 297/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5578 - accuracy: 0.8629 - val_loss: 0.8138 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 298/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5349 - accuracy: 0.8710 - val_loss: 0.8032 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 299/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5371 - accuracy: 0.8516 - val_loss: 0.7946 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 300/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5402 - accuracy: 0.8694 - val_loss: 0.8191 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 301/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5708 - accuracy: 0.8540 - val_loss: 0.8358 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 302/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5478 - accuracy: 0.8524 - val_loss: 0.7719 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 303/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5475 - accuracy: 0.8677 - val_loss: 0.7727 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 304/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5469 - accuracy: 0.8645 - val_loss: 0.7943 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 305/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5203 - accuracy: 0.8750 - val_loss: 0.7882 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 306/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5433 - accuracy: 0.8629 - val_loss: 0.8664 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 307/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5492 - accuracy: 0.8694 - val_loss: 0.8237 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 308/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5241 - accuracy: 0.8710 - val_loss: 0.8345 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 309/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5261 - accuracy: 0.8726 - val_loss: 0.8106 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 310/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5212 - accuracy: 0.8831 - val_loss: 0.8225 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 311/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5421 - accuracy: 0.8629 - val_loss: 0.8095 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 312/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5214 - accuracy: 0.8645 - val_loss: 0.8187 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 313/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5016 - accuracy: 0.8839 - val_loss: 0.8229 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 314/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5643 - accuracy: 0.8500 - val_loss: 0.8433 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 315/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5261 - accuracy: 0.8750 - val_loss: 0.7870 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 316/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5234 - accuracy: 0.8685 - val_loss: 0.7877 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 317/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5400 - accuracy: 0.8597 - val_loss: 0.7747 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 318/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5232 - accuracy: 0.8726 - val_loss: 0.8080 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 319/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5044 - accuracy: 0.8782 - val_loss: 0.8389 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 320/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5073 - accuracy: 0.8750 - val_loss: 0.8172 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 321/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5074 - accuracy: 0.8774 - val_loss: 0.8747 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 322/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5463 - accuracy: 0.8629 - val_loss: 0.7950 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 323/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5246 - accuracy: 0.8750 - val_loss: 0.8124 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 324/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5327 - accuracy: 0.8669 - val_loss: 0.8075 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 325/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5325 - accuracy: 0.8758 - val_loss: 0.8462 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 326/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5418 - accuracy: 0.8677 - val_loss: 0.7934 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 327/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4926 - accuracy: 0.8927 - val_loss: 0.8088 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 328/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5174 - accuracy: 0.8782 - val_loss: 0.8005 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 329/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5476 - accuracy: 0.8597 - val_loss: 0.8062 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 330/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5220 - accuracy: 0.8734 - val_loss: 0.7935 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 331/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5182 - accuracy: 0.8750 - val_loss: 0.8077 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 332/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5086 - accuracy: 0.8798 - val_loss: 0.8387 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 333/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5236 - accuracy: 0.8726 - val_loss: 0.8252 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 334/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5384 - accuracy: 0.8589 - val_loss: 0.8115 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 335/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5359 - accuracy: 0.8710 - val_loss: 0.7856 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 336/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5250 - accuracy: 0.8815 - val_loss: 0.8289 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 337/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5133 - accuracy: 0.8750 - val_loss: 0.8025 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 338/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5053 - accuracy: 0.8911 - val_loss: 0.8353 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 339/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5086 - accuracy: 0.8815 - val_loss: 0.8051 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 340/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5039 - accuracy: 0.8815 - val_loss: 0.8301 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 341/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5328 - accuracy: 0.8742 - val_loss: 0.8133 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 342/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5187 - accuracy: 0.8871 - val_loss: 0.8112 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 343/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5144 - accuracy: 0.8798 - val_loss: 0.8102 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 344/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5240 - accuracy: 0.8831 - val_loss: 0.8365 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 345/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5086 - accuracy: 0.8887 - val_loss: 0.8496 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 346/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.5095 - accuracy: 0.8855 - val_loss: 0.7954 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 347/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5153 - accuracy: 0.8694 - val_loss: 0.8126 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 348/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5122 - accuracy: 0.8790 - val_loss: 0.8409 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 349/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5231 - accuracy: 0.8718 - val_loss: 0.8350 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 350/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.5185 - accuracy: 0.8823 - val_loss: 0.7982 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 351/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5226 - accuracy: 0.8790 - val_loss: 0.8042 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 352/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4998 - accuracy: 0.8871 - val_loss: 0.8162 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 353/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5083 - accuracy: 0.8790 - val_loss: 0.8411 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 354/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5178 - accuracy: 0.8839 - val_loss: 0.7876 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 355/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5164 - accuracy: 0.8831 - val_loss: 0.7957 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 356/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5000 - accuracy: 0.8823 - val_loss: 0.8195 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 357/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5318 - accuracy: 0.8782 - val_loss: 0.8558 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 358/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5238 - accuracy: 0.8782 - val_loss: 0.8536 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 359/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5334 - accuracy: 0.8677 - val_loss: 0.8338 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 360/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5152 - accuracy: 0.8855 - val_loss: 0.8233 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 361/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5224 - accuracy: 0.8742 - val_loss: 0.8457 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 362/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5098 - accuracy: 0.8839 - val_loss: 0.8554 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 363/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5118 - accuracy: 0.8855 - val_loss: 0.8549 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 364/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5286 - accuracy: 0.8645 - val_loss: 0.8798 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Epoch 365/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5098 - accuracy: 0.8839 - val_loss: 0.8396 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 366/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5200 - accuracy: 0.8669 - val_loss: 0.8443 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 367/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5296 - accuracy: 0.8710 - val_loss: 0.8309 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 368/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4902 - accuracy: 0.8903 - val_loss: 0.8103 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 369/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5092 - accuracy: 0.8806 - val_loss: 0.8182 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 370/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5267 - accuracy: 0.8710 - val_loss: 0.8227 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 371/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4930 - accuracy: 0.8863 - val_loss: 0.8506 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 372/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5071 - accuracy: 0.8847 - val_loss: 0.8273 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 373/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4996 - accuracy: 0.8847 - val_loss: 0.9181 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 374/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5063 - accuracy: 0.8831 - val_loss: 0.8310 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 375/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5057 - accuracy: 0.8855 - val_loss: 0.8809 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 376/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.5245 - accuracy: 0.8718 - val_loss: 0.8433 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 377/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5255 - accuracy: 0.8798 - val_loss: 0.8573 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 378/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5238 - accuracy: 0.8702 - val_loss: 0.8077 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 379/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5342 - accuracy: 0.8750 - val_loss: 0.8950 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 380/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5388 - accuracy: 0.8685 - val_loss: 0.8294 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 381/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5198 - accuracy: 0.8742 - val_loss: 0.8339 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 382/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5200 - accuracy: 0.8661 - val_loss: 0.8233 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 383/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5047 - accuracy: 0.8855 - val_loss: 0.8249 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 384/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4978 - accuracy: 0.8847 - val_loss: 0.8109 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 385/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4930 - accuracy: 0.8903 - val_loss: 0.8261 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 386/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4853 - accuracy: 0.8984 - val_loss: 0.8645 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 387/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5141 - accuracy: 0.8927 - val_loss: 0.8140 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 388/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4903 - accuracy: 0.8927 - val_loss: 0.8505 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 389/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5091 - accuracy: 0.8871 - val_loss: 0.8194 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 390/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4887 - accuracy: 0.8919 - val_loss: 0.8157 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 391/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4936 - accuracy: 0.8863 - val_loss: 0.8169 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 392/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4807 - accuracy: 0.9016 - val_loss: 0.8427 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 393/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5261 - accuracy: 0.8653 - val_loss: 0.8337 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 394/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5390 - accuracy: 0.8669 - val_loss: 0.8921 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 395/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5408 - accuracy: 0.8597 - val_loss: 0.8275 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 396/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4842 - accuracy: 0.8960 - val_loss: 0.8182 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 397/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4893 - accuracy: 0.8919 - val_loss: 0.8186 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 398/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5055 - accuracy: 0.8766 - val_loss: 0.8006 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 399/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4797 - accuracy: 0.8992 - val_loss: 0.7914 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 400/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4748 - accuracy: 0.8984 - val_loss: 0.8122 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 401/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4677 - accuracy: 0.9008 - val_loss: 0.8222 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 402/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4748 - accuracy: 0.8976 - val_loss: 0.8220 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 403/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4844 - accuracy: 0.8919 - val_loss: 0.8373 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 404/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4988 - accuracy: 0.8839 - val_loss: 0.8250 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 405/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4796 - accuracy: 0.8968 - val_loss: 0.8033 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 406/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4868 - accuracy: 0.8911 - val_loss: 0.8225 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 407/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4675 - accuracy: 0.8976 - val_loss: 0.8216 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 408/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4768 - accuracy: 0.8984 - val_loss: 0.8252 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 409/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4641 - accuracy: 0.9032 - val_loss: 0.8143 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 410/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4593 - accuracy: 0.9097 - val_loss: 0.8174 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 411/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4833 - accuracy: 0.8847 - val_loss: 0.8520 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 412/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4868 - accuracy: 0.8935 - val_loss: 0.8436 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 413/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.5067 - accuracy: 0.8831 - val_loss: 0.8529 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 414/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5120 - accuracy: 0.8823 - val_loss: 0.8625 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 415/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5140 - accuracy: 0.8831 - val_loss: 0.8209 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 416/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4991 - accuracy: 0.8871 - val_loss: 0.8365 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 417/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5307 - accuracy: 0.8823 - val_loss: 0.8157 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 418/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5069 - accuracy: 0.8863 - val_loss: 0.8115 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 419/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4961 - accuracy: 0.8984 - val_loss: 0.8334 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 420/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5012 - accuracy: 0.8847 - val_loss: 0.8910 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 421/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5129 - accuracy: 0.8823 - val_loss: 0.8386 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 422/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4916 - accuracy: 0.8903 - val_loss: 0.8381 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 423/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5007 - accuracy: 0.8887 - val_loss: 0.8341 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 424/1024\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4891 - accuracy: 0.8895 - val_loss: 0.8164 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 425/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4777 - accuracy: 0.8903 - val_loss: 0.8228 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 426/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4784 - accuracy: 0.9008 - val_loss: 0.8450 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 427/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4881 - accuracy: 0.8968 - val_loss: 0.8105 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 428/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4824 - accuracy: 0.8944 - val_loss: 0.8069 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 429/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4910 - accuracy: 0.8815 - val_loss: 0.8421 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 430/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4971 - accuracy: 0.8911 - val_loss: 0.8811 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 431/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4922 - accuracy: 0.8935 - val_loss: 0.8677 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 432/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5019 - accuracy: 0.8855 - val_loss: 0.8147 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 433/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4748 - accuracy: 0.8976 - val_loss: 0.7976 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 434/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4902 - accuracy: 0.8903 - val_loss: 0.8010 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 435/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4750 - accuracy: 0.8911 - val_loss: 0.8690 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 436/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4760 - accuracy: 0.9048 - val_loss: 0.8107 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 437/1024\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4900 - accuracy: 0.8895 - val_loss: 0.8266 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 438/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4859 - accuracy: 0.8919 - val_loss: 0.8304 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 439/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4712 - accuracy: 0.9040 - val_loss: 0.8159 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 440/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4605 - accuracy: 0.9056 - val_loss: 0.8196 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 441/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4468 - accuracy: 0.9185 - val_loss: 0.8707 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 442/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4790 - accuracy: 0.8903 - val_loss: 0.8721 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 443/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4754 - accuracy: 0.8903 - val_loss: 0.8383 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 444/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4853 - accuracy: 0.8847 - val_loss: 0.8089 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 445/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4638 - accuracy: 0.9089 - val_loss: 0.8176 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 446/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4960 - accuracy: 0.8806 - val_loss: 0.8799 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 447/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4966 - accuracy: 0.8839 - val_loss: 0.8474 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 448/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4730 - accuracy: 0.8976 - val_loss: 0.8320 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 449/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4870 - accuracy: 0.9000 - val_loss: 0.8371 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 450/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4758 - accuracy: 0.8935 - val_loss: 0.8106 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 451/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4848 - accuracy: 0.8887 - val_loss: 0.8452 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 452/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4674 - accuracy: 0.9000 - val_loss: 0.8211 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 453/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4635 - accuracy: 0.8952 - val_loss: 0.8674 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 454/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4828 - accuracy: 0.8903 - val_loss: 0.8774 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 455/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4670 - accuracy: 0.9024 - val_loss: 0.8423 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 456/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4587 - accuracy: 0.9169 - val_loss: 0.8658 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 457/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4676 - accuracy: 0.9056 - val_loss: 0.8319 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 458/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4733 - accuracy: 0.8976 - val_loss: 0.8413 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 459/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4887 - accuracy: 0.8839 - val_loss: 0.8064 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 460/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4713 - accuracy: 0.9040 - val_loss: 0.8667 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 461/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4682 - accuracy: 0.9000 - val_loss: 0.8540 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 462/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4678 - accuracy: 0.9065 - val_loss: 0.8479 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 463/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4656 - accuracy: 0.9056 - val_loss: 0.8617 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 464/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4777 - accuracy: 0.8887 - val_loss: 0.8254 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 465/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4630 - accuracy: 0.9024 - val_loss: 0.8351 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 466/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4710 - accuracy: 0.8992 - val_loss: 0.8677 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 467/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4810 - accuracy: 0.8992 - val_loss: 0.8329 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 468/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4929 - accuracy: 0.8887 - val_loss: 0.8442 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 469/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4833 - accuracy: 0.8911 - val_loss: 0.8581 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 470/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4973 - accuracy: 0.8911 - val_loss: 0.8437 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 471/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4621 - accuracy: 0.8984 - val_loss: 0.8410 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 472/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4733 - accuracy: 0.9065 - val_loss: 0.8236 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 473/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4774 - accuracy: 0.9040 - val_loss: 0.8789 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 474/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4840 - accuracy: 0.8927 - val_loss: 0.8409 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 475/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5011 - accuracy: 0.8847 - val_loss: 0.8493 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 476/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4494 - accuracy: 0.9105 - val_loss: 0.8655 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 477/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4723 - accuracy: 0.9032 - val_loss: 0.8439 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 478/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4696 - accuracy: 0.8984 - val_loss: 0.8250 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 479/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4831 - accuracy: 0.8911 - val_loss: 0.8476 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 480/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4665 - accuracy: 0.8952 - val_loss: 0.8497 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 481/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4514 - accuracy: 0.9089 - val_loss: 0.8200 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 482/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4420 - accuracy: 0.9177 - val_loss: 0.8469 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 483/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4671 - accuracy: 0.9065 - val_loss: 0.8196 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 484/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4460 - accuracy: 0.9169 - val_loss: 0.8398 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 485/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4540 - accuracy: 0.9105 - val_loss: 0.9289 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 486/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4814 - accuracy: 0.8863 - val_loss: 0.8409 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 487/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4702 - accuracy: 0.8952 - val_loss: 0.8455 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 488/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4653 - accuracy: 0.9081 - val_loss: 0.8333 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 489/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4558 - accuracy: 0.9065 - val_loss: 0.8693 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 490/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4572 - accuracy: 0.9056 - val_loss: 0.8373 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 491/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4485 - accuracy: 0.9153 - val_loss: 0.8910 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 492/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4609 - accuracy: 0.9016 - val_loss: 0.8696 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 493/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4578 - accuracy: 0.9105 - val_loss: 0.8522 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 494/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4652 - accuracy: 0.9016 - val_loss: 0.8351 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 495/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4745 - accuracy: 0.8935 - val_loss: 0.8462 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 496/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4636 - accuracy: 0.9000 - val_loss: 0.8463 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 497/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4507 - accuracy: 0.9048 - val_loss: 0.8379 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 498/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4685 - accuracy: 0.8968 - val_loss: 0.8689 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 499/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4591 - accuracy: 0.8992 - val_loss: 0.9277 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 500/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4599 - accuracy: 0.9016 - val_loss: 0.9070 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 501/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4566 - accuracy: 0.9048 - val_loss: 0.8493 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 502/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4556 - accuracy: 0.9161 - val_loss: 0.8495 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Epoch 503/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4394 - accuracy: 0.9210 - val_loss: 0.8580 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 504/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4636 - accuracy: 0.8984 - val_loss: 0.8694 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 505/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4642 - accuracy: 0.9032 - val_loss: 0.8565 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 506/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4649 - accuracy: 0.9048 - val_loss: 0.8411 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 507/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4677 - accuracy: 0.9040 - val_loss: 0.8624 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 508/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4772 - accuracy: 0.8968 - val_loss: 0.8626 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 509/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4639 - accuracy: 0.9008 - val_loss: 0.9063 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 510/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4476 - accuracy: 0.9105 - val_loss: 0.8727 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 511/1024\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4575 - accuracy: 0.9169 - val_loss: 0.8190 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 512/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4492 - accuracy: 0.9113 - val_loss: 0.8416 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 513/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4420 - accuracy: 0.9089 - val_loss: 0.8480 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 514/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4393 - accuracy: 0.9161 - val_loss: 0.8453 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 515/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4498 - accuracy: 0.9137 - val_loss: 0.8627 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 516/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4344 - accuracy: 0.9177 - val_loss: 0.8367 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 517/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4425 - accuracy: 0.9137 - val_loss: 0.8459 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 518/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4321 - accuracy: 0.9185 - val_loss: 0.8446 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 519/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4433 - accuracy: 0.9137 - val_loss: 0.8806 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 520/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4447 - accuracy: 0.9097 - val_loss: 0.8806 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 521/1024\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4486 - accuracy: 0.9097 - val_loss: 0.8245 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 522/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4623 - accuracy: 0.9048 - val_loss: 0.8603 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 523/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4566 - accuracy: 0.9145 - val_loss: 0.9362 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 524/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4855 - accuracy: 0.8960 - val_loss: 0.8228 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 525/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4658 - accuracy: 0.8976 - val_loss: 0.8389 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 526/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4537 - accuracy: 0.9073 - val_loss: 0.8604 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 527/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4587 - accuracy: 0.9137 - val_loss: 0.8805 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 528/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4611 - accuracy: 0.9097 - val_loss: 0.9573 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 529/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4918 - accuracy: 0.8960 - val_loss: 0.8664 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 530/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4887 - accuracy: 0.8895 - val_loss: 0.8437 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 531/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4502 - accuracy: 0.9145 - val_loss: 0.8477 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 532/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4631 - accuracy: 0.9105 - val_loss: 0.8649 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 533/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4570 - accuracy: 0.9040 - val_loss: 0.8344 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 534/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4280 - accuracy: 0.9274 - val_loss: 0.8880 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 535/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4546 - accuracy: 0.9024 - val_loss: 0.8413 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 536/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4556 - accuracy: 0.9129 - val_loss: 0.8464 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 537/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4357 - accuracy: 0.9105 - val_loss: 0.8726 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 538/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4526 - accuracy: 0.9097 - val_loss: 0.8618 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 539/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4569 - accuracy: 0.9008 - val_loss: 0.9182 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 540/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4874 - accuracy: 0.8968 - val_loss: 0.8517 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 541/1024\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4450 - accuracy: 0.9097 - val_loss: 0.9130 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 542/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4527 - accuracy: 0.9105 - val_loss: 0.8494 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 543/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4451 - accuracy: 0.9113 - val_loss: 0.8618 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 544/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4446 - accuracy: 0.9113 - val_loss: 0.8596 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 545/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4538 - accuracy: 0.9089 - val_loss: 0.9279 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 546/1024\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4918 - accuracy: 0.8839 - val_loss: 0.8499 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 547/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4708 - accuracy: 0.9008 - val_loss: 0.8820 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 548/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4916 - accuracy: 0.8903 - val_loss: 0.8741 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 549/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4647 - accuracy: 0.9032 - val_loss: 0.8569 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 550/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4426 - accuracy: 0.9153 - val_loss: 0.8375 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 551/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4377 - accuracy: 0.9250 - val_loss: 0.8695 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 552/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4492 - accuracy: 0.9081 - val_loss: 0.8560 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 553/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4322 - accuracy: 0.9177 - val_loss: 0.8494 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 554/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4495 - accuracy: 0.9065 - val_loss: 0.8756 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 555/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4332 - accuracy: 0.9153 - val_loss: 0.8720 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 556/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4439 - accuracy: 0.9153 - val_loss: 0.8404 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 557/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4446 - accuracy: 0.9129 - val_loss: 0.8321 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 558/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4299 - accuracy: 0.9202 - val_loss: 0.8373 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 559/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4316 - accuracy: 0.9234 - val_loss: 0.8364 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 560/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4375 - accuracy: 0.9073 - val_loss: 0.8520 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 561/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4284 - accuracy: 0.9185 - val_loss: 0.8332 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 562/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4299 - accuracy: 0.9210 - val_loss: 0.8692 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 563/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4247 - accuracy: 0.9226 - val_loss: 0.8792 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 564/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4553 - accuracy: 0.9105 - val_loss: 0.9324 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 565/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4678 - accuracy: 0.8992 - val_loss: 0.8982 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 566/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4765 - accuracy: 0.8944 - val_loss: 0.8666 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 567/1024\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4685 - accuracy: 0.9081 - val_loss: 0.8598 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 568/1024\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4413 - accuracy: 0.9105 - val_loss: 0.8405 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 569/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4453 - accuracy: 0.9161 - val_loss: 0.8557 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 570/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4386 - accuracy: 0.9202 - val_loss: 0.8478 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 571/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4395 - accuracy: 0.9169 - val_loss: 0.8688 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 572/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4363 - accuracy: 0.9153 - val_loss: 0.8859 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 573/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4488 - accuracy: 0.9113 - val_loss: 0.9060 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 574/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4456 - accuracy: 0.9202 - val_loss: 0.8846 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 575/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4519 - accuracy: 0.9040 - val_loss: 0.8811 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 576/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4623 - accuracy: 0.9024 - val_loss: 0.8343 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 577/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4409 - accuracy: 0.9129 - val_loss: 0.8665 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 578/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4303 - accuracy: 0.9145 - val_loss: 0.8714 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 579/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4418 - accuracy: 0.9242 - val_loss: 0.8560 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 580/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4261 - accuracy: 0.9145 - val_loss: 0.9227 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 581/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4561 - accuracy: 0.9032 - val_loss: 0.9080 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 582/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4887 - accuracy: 0.8903 - val_loss: 0.9419 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 583/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4701 - accuracy: 0.8968 - val_loss: 0.8525 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 584/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4557 - accuracy: 0.9056 - val_loss: 0.8785 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 585/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4393 - accuracy: 0.9202 - val_loss: 0.8473 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 586/1024\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4618 - accuracy: 0.9032 - val_loss: 0.9203 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 587/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4797 - accuracy: 0.8960 - val_loss: 0.8766 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 588/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4670 - accuracy: 0.8976 - val_loss: 0.8680 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 589/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4472 - accuracy: 0.9081 - val_loss: 0.8203 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 590/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4485 - accuracy: 0.9113 - val_loss: 0.8968 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 591/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4470 - accuracy: 0.9137 - val_loss: 0.8606 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 592/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4459 - accuracy: 0.9169 - val_loss: 0.9179 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 593/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4661 - accuracy: 0.9040 - val_loss: 0.9407 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 594/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4428 - accuracy: 0.9210 - val_loss: 0.8869 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 595/1024\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4608 - accuracy: 0.9024 - val_loss: 0.8509 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 596/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4335 - accuracy: 0.9129 - val_loss: 0.8305 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 597/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4096 - accuracy: 0.9315 - val_loss: 0.8612 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 598/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4204 - accuracy: 0.9258 - val_loss: 0.9103 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 599/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4401 - accuracy: 0.9161 - val_loss: 1.0411 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 600/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4754 - accuracy: 0.8944 - val_loss: 0.9589 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 601/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4621 - accuracy: 0.9048 - val_loss: 0.8489 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 602/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4389 - accuracy: 0.9089 - val_loss: 0.8840 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 603/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4481 - accuracy: 0.9113 - val_loss: 0.8430 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 604/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4426 - accuracy: 0.9024 - val_loss: 0.8440 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 605/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4492 - accuracy: 0.9113 - val_loss: 0.8640 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 606/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4311 - accuracy: 0.9218 - val_loss: 0.8430 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 607/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.9169 - val_loss: 0.8483 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 608/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4139 - accuracy: 0.9282 - val_loss: 0.8611 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 609/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3915 - accuracy: 0.9315 - val_loss: 0.8582 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 610/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3969 - accuracy: 0.9355 - val_loss: 0.8631 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 611/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4433 - accuracy: 0.9145 - val_loss: 0.9151 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 612/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4340 - accuracy: 0.9153 - val_loss: 0.8610 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 613/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4210 - accuracy: 0.9129 - val_loss: 0.8890 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 614/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4175 - accuracy: 0.9274 - val_loss: 0.8468 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 615/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4026 - accuracy: 0.9339 - val_loss: 0.8516 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 616/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4137 - accuracy: 0.9226 - val_loss: 0.8671 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 617/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4175 - accuracy: 0.9234 - val_loss: 0.8651 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 618/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4255 - accuracy: 0.9169 - val_loss: 0.8768 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 619/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4247 - accuracy: 0.9202 - val_loss: 0.8774 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 620/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4156 - accuracy: 0.9194 - val_loss: 0.8519 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 621/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4266 - accuracy: 0.9185 - val_loss: 0.8646 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 622/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4319 - accuracy: 0.9113 - val_loss: 0.8661 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 623/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4119 - accuracy: 0.9315 - val_loss: 0.8596 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 624/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4195 - accuracy: 0.9274 - val_loss: 0.8695 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 625/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4277 - accuracy: 0.9177 - val_loss: 0.8620 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 626/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4162 - accuracy: 0.9185 - val_loss: 0.8718 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 627/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3989 - accuracy: 0.9339 - val_loss: 0.8458 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 628/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4097 - accuracy: 0.9355 - val_loss: 0.8831 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 629/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4068 - accuracy: 0.9298 - val_loss: 0.8708 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 630/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4284 - accuracy: 0.9153 - val_loss: 0.8989 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 631/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4136 - accuracy: 0.9218 - val_loss: 0.8929 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 632/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4484 - accuracy: 0.9113 - val_loss: 0.9025 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 633/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4211 - accuracy: 0.9202 - val_loss: 0.8693 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 634/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4184 - accuracy: 0.9234 - val_loss: 0.8814 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 635/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4236 - accuracy: 0.9282 - val_loss: 0.9019 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 636/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4024 - accuracy: 0.9355 - val_loss: 0.8760 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 637/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4254 - accuracy: 0.9194 - val_loss: 0.9080 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 638/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4429 - accuracy: 0.9032 - val_loss: 0.8886 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 639/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4155 - accuracy: 0.9250 - val_loss: 0.8554 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 640/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4291 - accuracy: 0.9194 - val_loss: 0.8692 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 641/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4325 - accuracy: 0.9177 - val_loss: 0.9108 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 642/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4439 - accuracy: 0.9185 - val_loss: 0.9022 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 643/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4486 - accuracy: 0.9040 - val_loss: 0.8654 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 644/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4524 - accuracy: 0.9105 - val_loss: 0.8986 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 645/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4471 - accuracy: 0.9105 - val_loss: 0.8702 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 646/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4271 - accuracy: 0.9274 - val_loss: 0.8779 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 647/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4466 - accuracy: 0.9161 - val_loss: 0.8720 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 648/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4715 - accuracy: 0.8871 - val_loss: 0.8524 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 649/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4207 - accuracy: 0.9274 - val_loss: 0.8541 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 650/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4531 - accuracy: 0.9129 - val_loss: 0.8375 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 651/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4140 - accuracy: 0.9242 - val_loss: 0.8663 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 652/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3991 - accuracy: 0.9355 - val_loss: 0.8546 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 653/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4055 - accuracy: 0.9242 - val_loss: 0.8635 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 654/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4040 - accuracy: 0.9306 - val_loss: 0.8685 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 655/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4111 - accuracy: 0.9266 - val_loss: 0.8789 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 656/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4203 - accuracy: 0.9169 - val_loss: 0.8685 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 657/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4034 - accuracy: 0.9315 - val_loss: 0.8938 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 658/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4395 - accuracy: 0.9081 - val_loss: 1.0377 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 659/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4668 - accuracy: 0.9008 - val_loss: 0.8891 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 660/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4523 - accuracy: 0.9040 - val_loss: 0.8628 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 661/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4271 - accuracy: 0.9129 - val_loss: 0.8577 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 662/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4486 - accuracy: 0.9153 - val_loss: 0.8905 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 663/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4293 - accuracy: 0.9169 - val_loss: 0.8659 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 664/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4194 - accuracy: 0.9234 - val_loss: 0.8639 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 665/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.9250 - val_loss: 0.8872 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 666/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4277 - accuracy: 0.9242 - val_loss: 0.8897 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 667/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4164 - accuracy: 0.9202 - val_loss: 0.9034 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 668/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3983 - accuracy: 0.9339 - val_loss: 0.8674 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 669/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4153 - accuracy: 0.9298 - val_loss: 0.8797 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 670/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4380 - accuracy: 0.9105 - val_loss: 0.8937 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 671/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4068 - accuracy: 0.9258 - val_loss: 0.8836 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 672/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4314 - accuracy: 0.9153 - val_loss: 0.9097 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 673/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4296 - accuracy: 0.9226 - val_loss: 0.8761 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 674/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4174 - accuracy: 0.9298 - val_loss: 0.8570 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 675/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4322 - accuracy: 0.9137 - val_loss: 0.8900 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 676/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4110 - accuracy: 0.9234 - val_loss: 0.8548 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 677/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4180 - accuracy: 0.9315 - val_loss: 0.8820 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 678/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4272 - accuracy: 0.9185 - val_loss: 0.8814 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 679/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4150 - accuracy: 0.9234 - val_loss: 0.9472 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 680/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4591 - accuracy: 0.9048 - val_loss: 0.8609 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 681/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4250 - accuracy: 0.9169 - val_loss: 0.8418 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 682/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4185 - accuracy: 0.9210 - val_loss: 0.9111 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 683/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4305 - accuracy: 0.9145 - val_loss: 0.9268 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 684/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4201 - accuracy: 0.9258 - val_loss: 0.8521 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 685/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4041 - accuracy: 0.9323 - val_loss: 0.8671 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 686/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4042 - accuracy: 0.9371 - val_loss: 0.8644 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 687/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4003 - accuracy: 0.9242 - val_loss: 0.8947 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 688/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4157 - accuracy: 0.9194 - val_loss: 0.8805 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 689/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4145 - accuracy: 0.9210 - val_loss: 0.8834 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 690/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4038 - accuracy: 0.9339 - val_loss: 0.8588 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 691/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3809 - accuracy: 0.9387 - val_loss: 0.8677 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 692/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4106 - accuracy: 0.9210 - val_loss: 0.8919 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 693/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4115 - accuracy: 0.9242 - val_loss: 0.9479 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 694/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3988 - accuracy: 0.9315 - val_loss: 0.8952 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 695/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4232 - accuracy: 0.9258 - val_loss: 0.9180 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 696/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4105 - accuracy: 0.9185 - val_loss: 0.8876 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 697/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3849 - accuracy: 0.9452 - val_loss: 0.8560 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 698/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4084 - accuracy: 0.9258 - val_loss: 0.9056 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 699/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4266 - accuracy: 0.9202 - val_loss: 0.8872 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 700/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4037 - accuracy: 0.9339 - val_loss: 0.9378 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 701/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4031 - accuracy: 0.9274 - val_loss: 0.8945 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 702/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4194 - accuracy: 0.9169 - val_loss: 0.9155 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 703/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4324 - accuracy: 0.9145 - val_loss: 0.9109 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 704/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4205 - accuracy: 0.9194 - val_loss: 0.8914 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 705/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4378 - accuracy: 0.9145 - val_loss: 0.8614 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 706/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4282 - accuracy: 0.9177 - val_loss: 0.8732 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 707/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4235 - accuracy: 0.9234 - val_loss: 0.8978 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 708/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4109 - accuracy: 0.9266 - val_loss: 0.9244 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 709/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4031 - accuracy: 0.9347 - val_loss: 0.8702 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 710/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4004 - accuracy: 0.9290 - val_loss: 0.8566 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 711/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3984 - accuracy: 0.9323 - val_loss: 0.8880 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 712/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3999 - accuracy: 0.9306 - val_loss: 0.8871 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 713/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3946 - accuracy: 0.9290 - val_loss: 0.8794 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 714/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3995 - accuracy: 0.9379 - val_loss: 0.8778 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 715/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4008 - accuracy: 0.9331 - val_loss: 0.9322 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 716/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4346 - accuracy: 0.9137 - val_loss: 0.8691 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 717/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4015 - accuracy: 0.9274 - val_loss: 0.8838 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 718/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4032 - accuracy: 0.9282 - val_loss: 0.8684 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 719/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4073 - accuracy: 0.9315 - val_loss: 0.8500 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 720/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4175 - accuracy: 0.9306 - val_loss: 0.8776 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 721/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3935 - accuracy: 0.9371 - val_loss: 0.8569 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 722/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4106 - accuracy: 0.9266 - val_loss: 0.8892 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 723/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3919 - accuracy: 0.9355 - val_loss: 0.8813 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 724/1024\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3968 - accuracy: 0.9274 - val_loss: 0.9096 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 725/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3786 - accuracy: 0.9468 - val_loss: 0.9266 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 726/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3896 - accuracy: 0.9379 - val_loss: 0.8996 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 727/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3893 - accuracy: 0.9371 - val_loss: 0.8993 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 728/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3839 - accuracy: 0.9435 - val_loss: 0.9494 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 729/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4201 - accuracy: 0.9161 - val_loss: 0.8764 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 730/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4094 - accuracy: 0.9210 - val_loss: 0.8492 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 731/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4102 - accuracy: 0.9266 - val_loss: 0.8880 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 732/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4165 - accuracy: 0.9242 - val_loss: 0.8721 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 733/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3989 - accuracy: 0.9315 - val_loss: 0.8827 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 734/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3871 - accuracy: 0.9387 - val_loss: 0.9019 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 735/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4014 - accuracy: 0.9250 - val_loss: 0.9036 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 736/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3988 - accuracy: 0.9315 - val_loss: 0.8812 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 737/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3788 - accuracy: 0.9347 - val_loss: 0.9473 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 738/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4026 - accuracy: 0.9323 - val_loss: 0.9343 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 739/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3939 - accuracy: 0.9306 - val_loss: 0.9003 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 740/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4080 - accuracy: 0.9210 - val_loss: 0.8751 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 741/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4062 - accuracy: 0.9242 - val_loss: 0.8858 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 742/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4074 - accuracy: 0.9226 - val_loss: 0.8831 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 743/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4036 - accuracy: 0.9274 - val_loss: 0.8955 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 744/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4123 - accuracy: 0.9274 - val_loss: 0.9033 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 745/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4185 - accuracy: 0.9258 - val_loss: 0.8896 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 746/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4003 - accuracy: 0.9306 - val_loss: 0.8635 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 747/1024\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3986 - accuracy: 0.9282 - val_loss: 0.8735 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 748/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3810 - accuracy: 0.9379 - val_loss: 0.9109 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 749/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3897 - accuracy: 0.9403 - val_loss: 0.8902 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 750/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4169 - accuracy: 0.9218 - val_loss: 0.9184 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 751/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4001 - accuracy: 0.9258 - val_loss: 0.8875 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 752/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3943 - accuracy: 0.9379 - val_loss: 0.9074 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 753/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3925 - accuracy: 0.9331 - val_loss: 0.9072 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 754/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3997 - accuracy: 0.9363 - val_loss: 0.9214 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 755/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3945 - accuracy: 0.9347 - val_loss: 0.8917 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 756/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3706 - accuracy: 0.9508 - val_loss: 0.8869 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 757/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3883 - accuracy: 0.9363 - val_loss: 0.8901 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 758/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3928 - accuracy: 0.9339 - val_loss: 0.8976 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 759/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3747 - accuracy: 0.9387 - val_loss: 0.9277 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 760/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4038 - accuracy: 0.9242 - val_loss: 0.9012 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 761/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3918 - accuracy: 0.9339 - val_loss: 0.9363 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 762/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3997 - accuracy: 0.9266 - val_loss: 0.8855 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 763/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3991 - accuracy: 0.9323 - val_loss: 0.8798 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 764/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3819 - accuracy: 0.9363 - val_loss: 0.8805 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 765/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3916 - accuracy: 0.9331 - val_loss: 0.8619 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 766/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3908 - accuracy: 0.9371 - val_loss: 0.8939 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 767/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4099 - accuracy: 0.9258 - val_loss: 0.8653 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 768/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4112 - accuracy: 0.9242 - val_loss: 0.9153 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 769/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3879 - accuracy: 0.9355 - val_loss: 0.8700 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 770/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4019 - accuracy: 0.9306 - val_loss: 0.8689 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 771/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3856 - accuracy: 0.9306 - val_loss: 0.9395 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 772/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4015 - accuracy: 0.9226 - val_loss: 0.9087 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 773/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3979 - accuracy: 0.9298 - val_loss: 0.9175 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 774/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4092 - accuracy: 0.9210 - val_loss: 0.8922 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 775/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3815 - accuracy: 0.9371 - val_loss: 0.9307 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 776/1024\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3881 - accuracy: 0.9339 - val_loss: 0.8879 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 777/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3727 - accuracy: 0.9452 - val_loss: 0.8599 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 778/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3827 - accuracy: 0.9290 - val_loss: 0.8950 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 779/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3849 - accuracy: 0.9347 - val_loss: 0.8902 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 780/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3883 - accuracy: 0.9379 - val_loss: 0.8943 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 781/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4073 - accuracy: 0.9315 - val_loss: 0.9335 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 782/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3839 - accuracy: 0.9363 - val_loss: 0.9107 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 783/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3981 - accuracy: 0.9185 - val_loss: 0.8803 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 784/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4082 - accuracy: 0.9306 - val_loss: 0.8823 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 785/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3970 - accuracy: 0.9234 - val_loss: 0.8617 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 786/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4056 - accuracy: 0.9298 - val_loss: 0.8922 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 787/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4000 - accuracy: 0.9315 - val_loss: 0.8821 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 788/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3821 - accuracy: 0.9427 - val_loss: 0.8946 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 789/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3840 - accuracy: 0.9347 - val_loss: 0.9046 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 790/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4088 - accuracy: 0.9274 - val_loss: 0.9201 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 791/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3892 - accuracy: 0.9282 - val_loss: 0.9195 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 792/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3859 - accuracy: 0.9427 - val_loss: 0.8713 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 793/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4046 - accuracy: 0.9323 - val_loss: 0.8881 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 794/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3961 - accuracy: 0.9266 - val_loss: 0.9139 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 795/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3903 - accuracy: 0.9371 - val_loss: 0.9073 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 796/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4060 - accuracy: 0.9282 - val_loss: 0.9083 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 797/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4172 - accuracy: 0.9153 - val_loss: 0.8867 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 798/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4065 - accuracy: 0.9250 - val_loss: 0.8821 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 799/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3868 - accuracy: 0.9331 - val_loss: 0.8596 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 800/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3750 - accuracy: 0.9435 - val_loss: 0.8826 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 801/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3737 - accuracy: 0.9419 - val_loss: 0.8869 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 802/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3747 - accuracy: 0.9460 - val_loss: 0.9083 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 803/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3868 - accuracy: 0.9379 - val_loss: 0.9081 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 804/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3881 - accuracy: 0.9444 - val_loss: 0.8970 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 805/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3680 - accuracy: 0.9427 - val_loss: 0.8468 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 806/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3779 - accuracy: 0.9395 - val_loss: 0.8891 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 807/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3883 - accuracy: 0.9379 - val_loss: 0.9125 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 808/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3881 - accuracy: 0.9298 - val_loss: 0.8912 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 809/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3918 - accuracy: 0.9306 - val_loss: 0.9118 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 810/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4045 - accuracy: 0.9242 - val_loss: 0.8706 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 811/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3987 - accuracy: 0.9298 - val_loss: 0.8722 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 812/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3768 - accuracy: 0.9395 - val_loss: 0.8985 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 813/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3904 - accuracy: 0.9298 - val_loss: 0.9279 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 814/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3848 - accuracy: 0.9355 - val_loss: 0.9113 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 815/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3869 - accuracy: 0.9363 - val_loss: 0.9024 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 816/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3863 - accuracy: 0.9347 - val_loss: 0.9261 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 817/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3857 - accuracy: 0.9315 - val_loss: 0.8763 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 818/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3854 - accuracy: 0.9444 - val_loss: 0.8760 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 819/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3850 - accuracy: 0.9282 - val_loss: 0.8901 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 820/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4079 - accuracy: 0.9274 - val_loss: 0.8818 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 821/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4062 - accuracy: 0.9274 - val_loss: 0.9479 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 822/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3992 - accuracy: 0.9298 - val_loss: 0.9392 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 823/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4397 - accuracy: 0.9040 - val_loss: 0.8915 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 824/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4251 - accuracy: 0.9161 - val_loss: 0.8647 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 825/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4363 - accuracy: 0.9169 - val_loss: 0.9465 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 826/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4297 - accuracy: 0.9105 - val_loss: 0.8973 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 827/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4229 - accuracy: 0.9258 - val_loss: 0.9368 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 828/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4253 - accuracy: 0.9202 - val_loss: 0.9086 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 829/1024\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4067 - accuracy: 0.9306 - val_loss: 0.9326 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 830/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4061 - accuracy: 0.9323 - val_loss: 0.8513 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 831/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3810 - accuracy: 0.9403 - val_loss: 0.8863 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 832/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3794 - accuracy: 0.9363 - val_loss: 0.8599 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 833/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3869 - accuracy: 0.9323 - val_loss: 0.9162 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 834/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3979 - accuracy: 0.9282 - val_loss: 0.8714 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 835/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3602 - accuracy: 0.9532 - val_loss: 0.8812 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 836/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3989 - accuracy: 0.9323 - val_loss: 0.9050 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 837/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3899 - accuracy: 0.9339 - val_loss: 0.9110 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 838/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3824 - accuracy: 0.9387 - val_loss: 0.8835 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 839/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4011 - accuracy: 0.9242 - val_loss: 0.8894 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 840/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3949 - accuracy: 0.9306 - val_loss: 0.9217 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 841/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3972 - accuracy: 0.9306 - val_loss: 0.8717 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 842/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3839 - accuracy: 0.9379 - val_loss: 0.9057 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 843/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3731 - accuracy: 0.9500 - val_loss: 0.9204 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 844/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3713 - accuracy: 0.9395 - val_loss: 0.9338 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 845/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3666 - accuracy: 0.9484 - val_loss: 0.9242 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 846/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3596 - accuracy: 0.9540 - val_loss: 0.9181 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 847/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3673 - accuracy: 0.9435 - val_loss: 0.9042 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 848/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3736 - accuracy: 0.9411 - val_loss: 0.9203 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 849/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3721 - accuracy: 0.9371 - val_loss: 0.9341 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 850/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3879 - accuracy: 0.9355 - val_loss: 0.9523 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 851/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3805 - accuracy: 0.9371 - val_loss: 0.8708 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 852/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3862 - accuracy: 0.9435 - val_loss: 0.9095 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 853/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3851 - accuracy: 0.9347 - val_loss: 0.9655 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 854/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3936 - accuracy: 0.9298 - val_loss: 0.9387 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 855/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3948 - accuracy: 0.9282 - val_loss: 0.9596 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 856/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3937 - accuracy: 0.9331 - val_loss: 0.9069 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 857/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3961 - accuracy: 0.9323 - val_loss: 0.9089 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 858/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4153 - accuracy: 0.9210 - val_loss: 0.8687 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 859/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4130 - accuracy: 0.9218 - val_loss: 0.9191 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 860/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3942 - accuracy: 0.9363 - val_loss: 0.8888 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 861/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3838 - accuracy: 0.9331 - val_loss: 0.9011 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 862/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3776 - accuracy: 0.9419 - val_loss: 0.8672 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 863/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3665 - accuracy: 0.9484 - val_loss: 0.9269 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 864/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3707 - accuracy: 0.9387 - val_loss: 0.9504 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 865/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3666 - accuracy: 0.9476 - val_loss: 0.8716 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 866/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3725 - accuracy: 0.9460 - val_loss: 0.9448 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 867/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3878 - accuracy: 0.9331 - val_loss: 0.9855 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 868/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3944 - accuracy: 0.9194 - val_loss: 0.9206 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 869/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4050 - accuracy: 0.9347 - val_loss: 0.8881 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 870/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3919 - accuracy: 0.9315 - val_loss: 0.8973 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 871/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3974 - accuracy: 0.9258 - val_loss: 0.8950 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 872/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3814 - accuracy: 0.9379 - val_loss: 0.8784 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 873/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3781 - accuracy: 0.9435 - val_loss: 0.8904 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 874/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3703 - accuracy: 0.9427 - val_loss: 0.8830 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 875/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3766 - accuracy: 0.9452 - val_loss: 0.8941 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 876/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3613 - accuracy: 0.9500 - val_loss: 0.9225 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 877/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4253 - accuracy: 0.9145 - val_loss: 0.9288 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 878/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4107 - accuracy: 0.9242 - val_loss: 0.9331 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 879/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3933 - accuracy: 0.9290 - val_loss: 0.9150 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 880/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4027 - accuracy: 0.9250 - val_loss: 0.8858 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 881/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3767 - accuracy: 0.9379 - val_loss: 0.8784 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 882/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3579 - accuracy: 0.9476 - val_loss: 0.9122 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 883/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3845 - accuracy: 0.9331 - val_loss: 0.9650 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 884/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3939 - accuracy: 0.9290 - val_loss: 0.9351 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 885/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3761 - accuracy: 0.9411 - val_loss: 0.9153 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 886/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3867 - accuracy: 0.9355 - val_loss: 0.9119 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 887/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4047 - accuracy: 0.9226 - val_loss: 0.9427 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 888/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4097 - accuracy: 0.9274 - val_loss: 0.8619 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 889/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4167 - accuracy: 0.9234 - val_loss: 0.9600 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 890/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4431 - accuracy: 0.9089 - val_loss: 0.8742 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 891/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4220 - accuracy: 0.9234 - val_loss: 0.8502 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 892/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4080 - accuracy: 0.9266 - val_loss: 0.9882 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 893/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3904 - accuracy: 0.9298 - val_loss: 0.8730 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 894/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3942 - accuracy: 0.9290 - val_loss: 0.9414 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 895/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4046 - accuracy: 0.9274 - val_loss: 0.8794 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 896/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3845 - accuracy: 0.9306 - val_loss: 0.9189 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 897/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3852 - accuracy: 0.9355 - val_loss: 0.9120 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 898/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3876 - accuracy: 0.9419 - val_loss: 0.8856 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 899/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3828 - accuracy: 0.9395 - val_loss: 0.9273 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 900/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3683 - accuracy: 0.9500 - val_loss: 0.8967 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 901/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3771 - accuracy: 0.9355 - val_loss: 0.9503 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 902/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3714 - accuracy: 0.9347 - val_loss: 0.9399 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 903/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3794 - accuracy: 0.9379 - val_loss: 0.8950 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 904/1024\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3716 - accuracy: 0.9508 - val_loss: 0.9192 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 905/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3594 - accuracy: 0.9516 - val_loss: 0.8842 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 906/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3747 - accuracy: 0.9371 - val_loss: 0.9358 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 907/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3881 - accuracy: 0.9419 - val_loss: 0.8689 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 908/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3585 - accuracy: 0.9468 - val_loss: 0.9338 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 909/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3745 - accuracy: 0.9452 - val_loss: 0.9056 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 910/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3635 - accuracy: 0.9484 - val_loss: 0.9150 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 911/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3596 - accuracy: 0.9435 - val_loss: 0.8790 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 912/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3588 - accuracy: 0.9532 - val_loss: 0.8717 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 913/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3600 - accuracy: 0.9492 - val_loss: 0.8942 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 914/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3603 - accuracy: 0.9468 - val_loss: 0.9291 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 915/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3868 - accuracy: 0.9323 - val_loss: 0.9578 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 916/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3940 - accuracy: 0.9250 - val_loss: 0.9173 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 917/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3915 - accuracy: 0.9282 - val_loss: 0.8663 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 918/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3770 - accuracy: 0.9371 - val_loss: 0.8660 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 919/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3692 - accuracy: 0.9460 - val_loss: 0.8640 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 920/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3796 - accuracy: 0.9371 - val_loss: 0.8908 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 921/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3654 - accuracy: 0.9500 - val_loss: 0.9094 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 922/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3706 - accuracy: 0.9435 - val_loss: 0.9332 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 923/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3791 - accuracy: 0.9347 - val_loss: 0.9123 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 924/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3644 - accuracy: 0.9444 - val_loss: 0.9002 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 925/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3626 - accuracy: 0.9468 - val_loss: 0.9532 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 926/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3539 - accuracy: 0.9411 - val_loss: 0.8902 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 927/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3879 - accuracy: 0.9331 - val_loss: 0.9302 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 928/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3853 - accuracy: 0.9298 - val_loss: 0.9065 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 929/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3816 - accuracy: 0.9331 - val_loss: 0.8735 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 930/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3960 - accuracy: 0.9363 - val_loss: 0.9121 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 931/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4107 - accuracy: 0.9202 - val_loss: 0.8732 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 932/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3842 - accuracy: 0.9306 - val_loss: 0.8448 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 933/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3854 - accuracy: 0.9387 - val_loss: 0.8636 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 934/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3843 - accuracy: 0.9427 - val_loss: 0.9580 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 935/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4167 - accuracy: 0.9105 - val_loss: 0.8962 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 936/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3764 - accuracy: 0.9363 - val_loss: 0.9117 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 937/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3613 - accuracy: 0.9476 - val_loss: 0.8914 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 938/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3659 - accuracy: 0.9444 - val_loss: 0.8924 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 939/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3546 - accuracy: 0.9444 - val_loss: 0.8837 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 940/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3491 - accuracy: 0.9492 - val_loss: 0.9030 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 941/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3588 - accuracy: 0.9403 - val_loss: 0.8977 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 942/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3439 - accuracy: 0.9508 - val_loss: 0.9010 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 943/1024\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3425 - accuracy: 0.9516 - val_loss: 0.9093 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 944/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3572 - accuracy: 0.9468 - val_loss: 0.9317 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 945/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3831 - accuracy: 0.9282 - val_loss: 0.9087 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 946/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3738 - accuracy: 0.9371 - val_loss: 0.8770 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 947/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3782 - accuracy: 0.9315 - val_loss: 0.9375 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 948/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3555 - accuracy: 0.9540 - val_loss: 0.8900 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 949/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3668 - accuracy: 0.9411 - val_loss: 0.9586 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 950/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3639 - accuracy: 0.9419 - val_loss: 0.9331 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 951/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3793 - accuracy: 0.9363 - val_loss: 0.9194 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 952/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3615 - accuracy: 0.9411 - val_loss: 0.9113 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 953/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3804 - accuracy: 0.9411 - val_loss: 0.9601 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 954/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3699 - accuracy: 0.9427 - val_loss: 0.9096 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 955/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3594 - accuracy: 0.9444 - val_loss: 0.8755 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 956/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3666 - accuracy: 0.9444 - val_loss: 0.9018 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 957/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3609 - accuracy: 0.9460 - val_loss: 0.8706 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 958/1024\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3711 - accuracy: 0.9444 - val_loss: 0.9003 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 959/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3626 - accuracy: 0.9395 - val_loss: 0.9119 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 960/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3675 - accuracy: 0.9363 - val_loss: 0.9226 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 961/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3574 - accuracy: 0.9524 - val_loss: 0.8973 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 962/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3771 - accuracy: 0.9379 - val_loss: 0.9047 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 963/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3713 - accuracy: 0.9444 - val_loss: 0.9192 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 964/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3674 - accuracy: 0.9468 - val_loss: 0.8687 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 965/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3466 - accuracy: 0.9500 - val_loss: 0.8931 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 966/1024\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3615 - accuracy: 0.9427 - val_loss: 0.9023 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 967/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3735 - accuracy: 0.9371 - val_loss: 0.8810 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 968/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3763 - accuracy: 0.9379 - val_loss: 0.9434 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 969/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3823 - accuracy: 0.9274 - val_loss: 0.8984 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 970/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3731 - accuracy: 0.9331 - val_loss: 0.8832 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 971/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3826 - accuracy: 0.9347 - val_loss: 0.9236 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 972/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3776 - accuracy: 0.9347 - val_loss: 0.9628 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 973/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3759 - accuracy: 0.9347 - val_loss: 0.9206 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 974/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3828 - accuracy: 0.9355 - val_loss: 0.9025 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 975/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3857 - accuracy: 0.9355 - val_loss: 0.8786 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 976/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3534 - accuracy: 0.9452 - val_loss: 0.9118 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 977/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3751 - accuracy: 0.9371 - val_loss: 0.8971 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 978/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3836 - accuracy: 0.9339 - val_loss: 0.9243 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 979/1024\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3846 - accuracy: 0.9363 - val_loss: 0.9176 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 980/1024\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3738 - accuracy: 0.9363 - val_loss: 0.9008 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 981/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3986 - accuracy: 0.9210 - val_loss: 0.9965 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 982/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4493 - accuracy: 0.8960 - val_loss: 0.9028 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 983/1024\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4284 - accuracy: 0.9185 - val_loss: 0.9239 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 984/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3982 - accuracy: 0.9290 - val_loss: 0.8589 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 985/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3838 - accuracy: 0.9387 - val_loss: 0.8707 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 986/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3729 - accuracy: 0.9435 - val_loss: 0.8942 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 987/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3719 - accuracy: 0.9435 - val_loss: 0.8905 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 988/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3461 - accuracy: 0.9589 - val_loss: 0.8762 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 989/1024\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3421 - accuracy: 0.9573 - val_loss: 0.9068 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 990/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3411 - accuracy: 0.9565 - val_loss: 1.0050 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 991/1024\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3581 - accuracy: 0.9460 - val_loss: 0.9322 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 992/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3740 - accuracy: 0.9331 - val_loss: 0.9009 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 993/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3758 - accuracy: 0.9419 - val_loss: 0.9299 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 994/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3676 - accuracy: 0.9419 - val_loss: 0.8992 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 995/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3523 - accuracy: 0.9452 - val_loss: 0.8825 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 996/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3638 - accuracy: 0.9476 - val_loss: 0.8882 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 997/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3700 - accuracy: 0.9379 - val_loss: 0.9381 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 998/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3706 - accuracy: 0.9379 - val_loss: 0.9377 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 999/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3708 - accuracy: 0.9379 - val_loss: 1.0172 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 1000/1024\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3988 - accuracy: 0.9250 - val_loss: 0.9188 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 1001/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3782 - accuracy: 0.9371 - val_loss: 0.8671 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 1002/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3730 - accuracy: 0.9371 - val_loss: 0.9000 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 1003/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3503 - accuracy: 0.9516 - val_loss: 0.9091 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 1004/1024\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3616 - accuracy: 0.9452 - val_loss: 0.9455 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 1005/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3713 - accuracy: 0.9476 - val_loss: 0.9822 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 1006/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3886 - accuracy: 0.9355 - val_loss: 0.9004 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 1007/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3551 - accuracy: 0.9532 - val_loss: 0.8869 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 1008/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3472 - accuracy: 0.9508 - val_loss: 0.9071 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 1009/1024\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3517 - accuracy: 0.9492 - val_loss: 0.8925 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 1010/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3754 - accuracy: 0.9355 - val_loss: 0.9225 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 1011/1024\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3608 - accuracy: 0.9516 - val_loss: 0.9598 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 1012/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3727 - accuracy: 0.9411 - val_loss: 0.9192 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 1013/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3771 - accuracy: 0.9282 - val_loss: 0.9307 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Epoch 1014/1024\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3672 - accuracy: 0.9476 - val_loss: 0.9169 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 1015/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3531 - accuracy: 0.9516 - val_loss: 0.9302 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 1016/1024\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3440 - accuracy: 0.9516 - val_loss: 0.9273 - val_accuracy: 0.7556 - lr: 0.0010\n",
      "Epoch 1017/1024\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3418 - accuracy: 0.9605 - val_loss: 0.9340 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 1018/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3477 - accuracy: 0.9516 - val_loss: 0.9142 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 1019/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3425 - accuracy: 0.9540 - val_loss: 0.9041 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 1020/1024\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3319 - accuracy: 0.9581 - val_loss: 0.9337 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 1021/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3589 - accuracy: 0.9492 - val_loss: 0.9256 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 1022/1024\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3491 - accuracy: 0.9508 - val_loss: 0.9274 - val_accuracy: 0.7846 - lr: 0.0010\n",
      "Epoch 1023/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3769 - accuracy: 0.9298 - val_loss: 0.9929 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 1024/1024\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3936 - accuracy: 0.9331 - val_loss: 0.9061 - val_accuracy: 0.7749 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 세팅\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1024\n",
    "MB_SIZE = 256\n",
    "REPORT = 1\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "  X_train_scaled, y_train,\n",
    "  batch_size=MB_SIZE,\n",
    "  validation_split = 0.2,\n",
    "  verbose=1,\n",
    "  epochs=EPOCHS,\n",
    "  callbacks=[es, rlrp, custom_checkpoint]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - val_acc: 0.8103, test_acc: 0.7655\n",
      "Model 2 - val_acc: 0.8071, test_acc: 0.7809\n",
      "Model 3 - val_acc: 0.8071, test_acc: 0.7809\n",
      "Model 4 - val_acc: 0.8071, test_acc: 0.7809\n",
      "Model 5 - val_acc: 0.8071, test_acc: 0.7861\n",
      "Model 6 - val_acc: 0.8071, test_acc: 0.7887\n",
      "Model 7 - val_acc: 0.8071, test_acc: 0.7861\n",
      "Model 8 - val_acc: 0.8071, test_acc: 0.8067\n",
      "Model 9 - val_acc: 0.8071, test_acc: 0.8015\n",
      "Model 10 - val_acc: 0.8039, test_acc: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# test 정확도가 가장 높은 모델 찾기\n",
    "for i, (val_accuracy, weights) in enumerate(custom_checkpoint.saved_models):\n",
    "    model.set_weights(weights)\n",
    "    test_metrics = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(f'Model {i+1} - val_acc: {val_accuracy:.4f}, test_acc: {test_metrics[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 정확도가 가장 높은 모델의 가중치를 로드\n",
    "model.set_weights(custom_checkpoint.saved_models[7][1])  # 0-based index이므로 8번째 모델은 인덱스 7에 해당합니다.\n",
    "\n",
    "# 모델 가중치를 저장\n",
    "model.save_weights('best_model_weights_classify.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9645 - accuracy: 0.8067\n",
      "Test Loss: 0.964\n",
      "Test Accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 평가\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", round(loss, 3))\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Figure 설정\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, index 1\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 훈련 및 검증 평가 지표 추출\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# 평가 지표 그래프 그리기\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, index 2\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()  # 그래프 간 간격 조정\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
