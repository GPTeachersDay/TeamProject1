{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 추출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메서드 정의\n",
    "def main(URL = 'Dataset\\Regression_data.csv'):\n",
    "    \n",
    "    # 랜덤 시드 고정\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    global df, LEARNING_RATE, EPOCH_COUNT, MB_SIZE, REPORT, TRAIN_RATIO, X, y, X_train, X_test, y_train, y_test, y_pred\n",
    "    \n",
    "    df = load_dataset(URL) # 데이터 로드\n",
    "    Regression_Model() # 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메서드 정의\n",
    "def load_dataset(URL = 'Dataset\\Regression_data.csv'):\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(URL)\n",
    "\n",
    "    # 성별 인코딩\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    df['Sex'] = encoder.fit_transform(df['Sex'])\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매서드 정의 \n",
    "def eval_accuracy():\n",
    "    \n",
    "\t# 오차율 구하는 과정    \n",
    "\t# np.mean() 메서드의 이유는 미니배치 처리를 고려하여 하나의 지표로 묶어주기 위함 입니다. \n",
    "    mdiff = np.mean(np.abs((y_pred - y_test) / y_test))\n",
    "    # 1 에서 오차율을 빼 정확도를 구합니다. \n",
    "    return 1 - mdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_Model():\n",
    "    # 학습 모델 구현\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # 상수 정의\n",
    "    LEARNING_RATE = 0.01\n",
    "    EPOCH_COUNT = 100\n",
    "    MB_SIZE = 10\n",
    "    REPORT = 1\n",
    "    TRAIN_RATIO = 0.8\n",
    "\n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop('Rings', axis=1)\n",
    "    y = df['Rings']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=128, activation='relu', input_shape=(8,)), # (8,)로 입력해야 튜플 형태로 입력되어 오류가 발생하지 않음\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # 옵티마이저와 손실 함수 설정\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE) # SGD : 경사하강법을 기본적으로 사용하는 옵티마이저\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer) # metrics=[eval_accuracy(y_pred, y_test)] 직접 작성한 eval_accuracy를 평가지표로 사용할 수 있음\n",
    "\n",
    "    # 학습 시작\n",
    "    model.fit(X_train, y_train, epochs=EPOCH_COUNT, batch_size=MB_SIZE, verbose=REPORT)\n",
    "\n",
    "    # 평가\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # R^2 Score 계산\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R^2 Score: {round(r2, 3)}')\n",
    "\n",
    "    # MSE 계산\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {round(mse, 3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
      "0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
      "1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
      "2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
      "3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
      "4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
      "\n",
      "   Viscera weight  Shell weight  Rings  \n",
      "0          0.1010         0.150     15  \n",
      "1          0.0485         0.070      7  \n",
      "2          0.1415         0.210      9  \n",
      "3          0.1140         0.155     10  \n",
      "4          0.0395         0.055      7  \n",
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 10.0795\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 7.3718\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 6.4557\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 6.0497\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 5.6386\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 5.6294\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.4774\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.4244\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 5.2977\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.3126\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.2336\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.1550\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 5.3105\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.0924\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.0373\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.9482\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.3059\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.0547\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.0520\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.0202\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.9201\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.9535\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8613\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8975\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8936\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8328\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8117\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.7915\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8144\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8409\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8584\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.8384\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8176\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.7153\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.7917\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 4.7804\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 4.7275\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.7951\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.8967\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6982\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 1s 3ms/step - loss: 4.6328\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.7343\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6173\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6788\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6365\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5950\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 1s 1ms/step - loss: 4.6636\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5484\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6394\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5854\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6787\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5563\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6314\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6286\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6004\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6133\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5086\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.6673\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4818\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5588\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5592\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5870\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5809\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4904\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5790\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5899\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5566\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5150\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5351\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4826\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5866\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4892\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5179\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5513\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.5052\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5570\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5061\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5433\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5029\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.5091\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4295\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4370\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4967\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4819\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.3976\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4923\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4397\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4962\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4973\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.6561\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4365\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4051\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4300\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4107\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4156\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4334\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4239\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4107\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.4642\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4.4400\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.544\n",
      "Mean Squared Error: 4.937\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TeamProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
