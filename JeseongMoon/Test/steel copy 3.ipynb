{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1941, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>...</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>270900</td>\n",
       "      <td>270944</td>\n",
       "      <td>267</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>24220</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853</td>\n",
       "      <td>860</td>\n",
       "      <td>369370</td>\n",
       "      <td>369415</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>18996</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>498078</td>\n",
       "      <td>498335</td>\n",
       "      <td>2409</td>\n",
       "      <td>60</td>\n",
       "      <td>260</td>\n",
       "      <td>246930</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0         42         50     270900     270944           267           17   \n",
       "1        645        651    2538079    2538108           108           10   \n",
       "2        829        835    1553913    1553931            71            8   \n",
       "3        853        860     369370     369415           176           13   \n",
       "4       1289       1306     498078     498335          2409           60   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           44              24220                     76   \n",
       "1           30              11397                     84   \n",
       "2           19               7972                     99   \n",
       "3           45              18996                     99   \n",
       "4          260             246930                     37   \n",
       "\n",
       "   Maximum_of_Luminosity  ...  Orientation_Index  Luminosity_Index  \\\n",
       "0                    108  ...             0.8182           -0.2913   \n",
       "1                    123  ...             0.7931           -0.1756   \n",
       "2                    125  ...             0.6667           -0.1228   \n",
       "3                    126  ...             0.8444           -0.1568   \n",
       "4                    126  ...             0.9338           -0.1992   \n",
       "\n",
       "   SigmoidOfAreas  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  \\\n",
       "0          0.5822       1          0         0       0          0      0   \n",
       "1          0.2984       1          0         0       0          0      0   \n",
       "2          0.2150       1          0         0       0          0      0   \n",
       "3          0.5212       1          0         0       0          0      0   \n",
       "4          1.0000       1          0         0       0          0      0   \n",
       "\n",
       "   Other_Faults  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_path = 'D:\\project\\TeamProject1\\JeseongMoon\\Dataset\\mulit_classification_data.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f'{df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = df[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']]\n",
    "X = df.iloc[:,:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>270900</td>\n",
       "      <td>270944</td>\n",
       "      <td>267</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>24220</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4265</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6435</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.5822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0334</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4624</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>1623</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8513</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.2553</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853</td>\n",
       "      <td>860</td>\n",
       "      <td>369370</td>\n",
       "      <td>369415</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>18996</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2455</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.6532</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>498078</td>\n",
       "      <td>498335</td>\n",
       "      <td>2409</td>\n",
       "      <td>60</td>\n",
       "      <td>260</td>\n",
       "      <td>246930</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3818</td>\n",
       "      <td>1.2305</td>\n",
       "      <td>2.4099</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0         42         50     270900     270944           267           17   \n",
       "1        645        651    2538079    2538108           108           10   \n",
       "2        829        835    1553913    1553931            71            8   \n",
       "3        853        860     369370     369415           176           13   \n",
       "4       1289       1306     498078     498335          2409           60   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           44              24220                     76   \n",
       "1           30              11397                     84   \n",
       "2           19               7972                     99   \n",
       "3           45              18996                     99   \n",
       "4          260             246930                     37   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel  \\\n",
       "0                    108                1687            1   \n",
       "1                    123                1687            1   \n",
       "2                    125                1623            1   \n",
       "3                    126                1353            0   \n",
       "4                    126                1353            0   \n",
       "\n",
       "   Steel_Plate_Thickness  Edges_Index  Empty_Index  Square_Index  \\\n",
       "0                     80       0.0498       0.2415        0.1818   \n",
       "1                     80       0.7647       0.3793        0.2069   \n",
       "2                    100       0.9710       0.3426        0.3333   \n",
       "3                    290       0.7287       0.4413        0.1556   \n",
       "4                    185       0.0695       0.4486        0.0662   \n",
       "\n",
       "   Outside_X_Index  Edges_X_Index  Edges_Y_Index  Outside_Global_Index  \\\n",
       "0           0.0047         0.4706         1.0000                   1.0   \n",
       "1           0.0036         0.6000         0.9667                   1.0   \n",
       "2           0.0037         0.7500         0.9474                   1.0   \n",
       "3           0.0052         0.5385         1.0000                   1.0   \n",
       "4           0.0126         0.2833         0.9885                   1.0   \n",
       "\n",
       "   LogOfAreas  Log_X_Index  Log_Y_Index  Orientation_Index  Luminosity_Index  \\\n",
       "0      2.4265       0.9031       1.6435             0.8182           -0.2913   \n",
       "1      2.0334       0.7782       1.4624             0.7931           -0.1756   \n",
       "2      1.8513       0.7782       1.2553             0.6667           -0.1228   \n",
       "3      2.2455       0.8451       1.6532             0.8444           -0.1568   \n",
       "4      3.3818       1.2305       2.4099             0.9338           -0.1992   \n",
       "\n",
       "   SigmoidOfAreas  \n",
       "0          0.5822  \n",
       "1          0.2984  \n",
       "2          0.2150  \n",
       "3          0.5212  \n",
       "4          1.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.rename(columns={'TypeOfSteel_A300': 'TypeOfSteel'})\n",
    "X = X.drop(columns=['TypeOfSteel_A400'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1164\n",
       "1     777\n",
       "Name: TypeOfSteel, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.TypeOfSteel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel  Steel_Plate_Thickness  Edges_Index  Empty_Index  Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  Orientation_Index  Luminosity_Index  SigmoidOfAreas\n",
      "0         42         50     270900     270944           267           17           44              24220                     76                    108                1687            1                     80       0.0498       0.2415        0.1818           0.0047         0.4706         1.0000                   1.0      2.4265       0.9031       1.6435             0.8182           -0.2913          0.5822\n",
      "1        645        651    2538079    2538108           108           10           30              11397                     84                    123                1687            1                     80       0.7647       0.3793        0.2069           0.0036         0.6000         0.9667                   1.0      2.0334       0.7782       1.4624             0.7931           -0.1756          0.2984\n",
      "2        829        835    1553913    1553931            71            8           19               7972                     99                    125                1623            1                    100       0.9710       0.3426        0.3333           0.0037         0.7500         0.9474                   1.0      1.8513       0.7782       1.2553             0.6667           -0.1228          0.2150\n",
      "3        853        860     369370     369415           176           13           45              18996                     99                    126                1353            0                    290       0.7287       0.4413        0.1556           0.0052         0.5385         1.0000                   1.0      2.2455       0.8451       1.6532             0.8444           -0.1568          0.5212\n",
      "4       1289       1306     498078     498335          2409           60          260             246930                     37                    126                1353            0                    185       0.0695       0.4486        0.0662           0.0126         0.2833         0.9885                   1.0      3.3818       1.2305       2.4099             0.9338           -0.1992          1.0000\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.expand_frame_repr', False) \n",
    "print(X.head())  # 데이터프레임 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82105\\anaconda3\\envs\\project1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type\n",
       "0  Pastry\n",
       "1  Pastry\n",
       "2  Pastry\n",
       "3  Pastry\n",
       "4  Pastry"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"Type\"] = y[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].idxmax(axis=1)\n",
    "y = y.drop(columns=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other_Faults    673\n",
       "Bumps           402\n",
       "K_Scatch        391\n",
       "Z_Scratch       190\n",
       "Pastry          158\n",
       "Stains           72\n",
       "Dirtiness        55\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1941, 26) (1941, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataframe = df.iloc[:,-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = []\n",
    "for i in range(y_dataframe.shape[0]):\n",
    "    if y_dataframe[\"Pastry\"].values[i] == 1:\n",
    "        y_list.append(\"Pastry\")\n",
    "    elif y_dataframe[\"Z_Scratch\"].values[i] == 1:\n",
    "        y_list.append(\"Z_Scratch\")\n",
    "    elif y_dataframe[\"K_Scatch\"].values[i] == 1:\n",
    "        y_list.append(\"K_Scatch\")\n",
    "    elif y_dataframe[\"Stains\"].values[i] == 1:\n",
    "        y_list.append(\"Stains\")\n",
    "    elif y_dataframe[\"Dirtiness\"].values[i] == 1:\n",
    "        y_list.append(\"Dirtiness\")\n",
    "    elif y_dataframe[\"Bumps\"].values[i] == 1:\n",
    "        y_list.append(\"Bumps\")\n",
    "    else:\n",
    "        y_list.append(\"Other_Faults\")\n",
    "\n",
    "y_list = np.array(y_list)\n",
    "y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pastry' 'Z_Scratch' 'K_Scatch' 'Stains' 'Dirtiness' 'Bumps'\n",
      " 'Other_Faults']\n"
     ]
    }
   ],
   "source": [
    "label = y['Type']\n",
    "print(label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "3        673\n",
      "0        402\n",
      "2        391\n",
      "6        190\n",
      "4        158\n",
      "5         72\n",
      "1         55\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(label)\n",
    "label_encoded = le.transform(label)\n",
    "le_y = pd.DataFrame(label_encoded, columns=['label'])\n",
    "y = le_y\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552, 26) (389, 26) (1552, 1) (389, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 83)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred=model.predict(X)\n",
    "    \n",
    "    Precision    = metrics.precision_score (y, y_pred, average=\"weighted\")\n",
    "    Recall       = metrics.recall_score    (y, y_pred, average=\"weighted\")\n",
    "    Accuracy     = metrics.accuracy_score  (y, y_pred)\n",
    "    F1           = metrics.f1_score        (y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f'Precision Score  : {Precision}')\n",
    "    print(f'Recall Score     : {Recall}')\n",
    "    print(f'Accuracy Score   : {Accuracy}')\n",
    "    print(f'F1 Score         : {F1}')\n",
    "    return Precision, Recall, Accuracy, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred=model.predict(X)\n",
    "    \n",
    "    Precision    = metrics.precision_score (y, y_pred, average=\"weighted\")\n",
    "    Recall       = metrics.recall_score    (y, y_pred, average=\"weighted\")\n",
    "    Accuracy     = metrics.accuracy_score  (y, y_pred)\n",
    "    F1           = metrics.f1_score        (y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f'Precision Score  : {Precision}')\n",
    "    print(f'Recall Score     : {Recall}')\n",
    "    print(f'Accuracy Score   : {Accuracy}')\n",
    "    print(f'F1 Score         : {F1}')\n",
    "    return Precision, Recall, Accuracy, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82105\\anaconda3\\envs\\project1\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score  : 1.0\n",
      "Recall Score     : 1.0\n",
      "Accuracy Score   : 1.0\n",
      "F1 Score         : 1.0\n",
      "====================================================================================================\n",
      "Precision Score  : 0.7992110315751305\n",
      "Recall Score     : 0.7866323907455013\n",
      "Accuracy Score   : 0.7866323907455013\n",
      "F1 Score         : 0.7892523019803969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf_all = RandomForestClassifier(random_state=83)\n",
    "model_rf_all.fit(X_train, y_train)\n",
    "\n",
    "rf_precision_train, rf_recall_train, rf_accuracy_train, rf_f1_train = get_metrics(model_rf_all, X_train, y_train)\n",
    "print('='*100)\n",
    "rf_precision_test, rf_recall_test, rf_accuracy_test, rf_f1_test = get_metrics(model_rf_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "311/311 [==============================] - 3s 5ms/step - loss: 9.9968 - accuracy: 0.3628 - val_loss: 8.3368 - val_accuracy: 0.4679\n",
      "Epoch 2/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 7.1005 - accuracy: 0.4304 - val_loss: 5.9750 - val_accuracy: 0.4910\n",
      "Epoch 3/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 5.3293 - accuracy: 0.4356 - val_loss: 4.7623 - val_accuracy: 0.4550\n",
      "Epoch 4/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 4.2688 - accuracy: 0.4323 - val_loss: 3.9909 - val_accuracy: 0.4961\n",
      "Epoch 5/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 3.7544 - accuracy: 0.4452 - val_loss: 3.7265 - val_accuracy: 0.4473\n",
      "Epoch 6/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 3.5190 - accuracy: 0.4452 - val_loss: 3.3391 - val_accuracy: 0.4370\n",
      "Epoch 7/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 3.0840 - accuracy: 0.4394 - val_loss: 2.9203 - val_accuracy: 0.4679\n",
      "Epoch 8/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.7698 - accuracy: 0.4613 - val_loss: 2.6948 - val_accuracy: 0.4987\n",
      "Epoch 9/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.7114 - accuracy: 0.4427 - val_loss: 2.5880 - val_accuracy: 0.4807\n",
      "Epoch 10/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.5438 - accuracy: 0.4446 - val_loss: 2.4448 - val_accuracy: 0.4499\n",
      "Epoch 11/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.3715 - accuracy: 0.4472 - val_loss: 2.3278 - val_accuracy: 0.4859\n",
      "Epoch 12/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.3969 - accuracy: 0.4594 - val_loss: 2.4262 - val_accuracy: 0.4781\n",
      "Epoch 13/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.3215 - accuracy: 0.4439 - val_loss: 2.3278 - val_accuracy: 0.4524\n",
      "Epoch 14/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.1589 - accuracy: 0.4691 - val_loss: 2.2056 - val_accuracy: 0.4447\n",
      "Epoch 15/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.1479 - accuracy: 0.4439 - val_loss: 2.2857 - val_accuracy: 0.3625\n",
      "Epoch 16/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.1734 - accuracy: 0.4472 - val_loss: 2.0475 - val_accuracy: 0.4987\n",
      "Epoch 17/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.1329 - accuracy: 0.4381 - val_loss: 2.5557 - val_accuracy: 0.3702\n",
      "Epoch 18/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.2202 - accuracy: 0.4336 - val_loss: 2.2598 - val_accuracy: 0.4884\n",
      "Epoch 19/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.1288 - accuracy: 0.4330 - val_loss: 1.9563 - val_accuracy: 0.4961\n",
      "Epoch 20/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.0438 - accuracy: 0.4375 - val_loss: 2.2301 - val_accuracy: 0.3779\n",
      "Epoch 21/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.0534 - accuracy: 0.4439 - val_loss: 1.9841 - val_accuracy: 0.4627\n",
      "Epoch 22/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.0194 - accuracy: 0.4459 - val_loss: 1.9891 - val_accuracy: 0.4961\n",
      "Epoch 23/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.0738 - accuracy: 0.4543 - val_loss: 2.1138 - val_accuracy: 0.5039\n",
      "Epoch 24/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 2.0343 - accuracy: 0.4336 - val_loss: 1.9902 - val_accuracy: 0.4859\n",
      "Epoch 25/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.9269 - accuracy: 0.4446 - val_loss: 1.9956 - val_accuracy: 0.4987\n",
      "Epoch 26/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.0029 - accuracy: 0.4562 - val_loss: 2.0120 - val_accuracy: 0.4730\n",
      "Epoch 27/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.9615 - accuracy: 0.4452 - val_loss: 1.9209 - val_accuracy: 0.4807\n",
      "Epoch 28/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.8850 - accuracy: 0.4285 - val_loss: 1.9120 - val_accuracy: 0.4807\n",
      "Epoch 29/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 2.0244 - accuracy: 0.4530 - val_loss: 1.9263 - val_accuracy: 0.4704\n",
      "Epoch 30/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.9466 - accuracy: 0.4459 - val_loss: 2.3620 - val_accuracy: 0.3650\n",
      "Epoch 31/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.9604 - accuracy: 0.4472 - val_loss: 1.9032 - val_accuracy: 0.5064\n",
      "Epoch 32/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.8662 - accuracy: 0.4407 - val_loss: 1.8735 - val_accuracy: 0.4807\n",
      "Epoch 33/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.8636 - accuracy: 0.4478 - val_loss: 1.8816 - val_accuracy: 0.4704\n",
      "Epoch 34/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.8452 - accuracy: 0.4459 - val_loss: 1.8033 - val_accuracy: 0.4987\n",
      "Epoch 35/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7342 - accuracy: 0.4800 - val_loss: 1.9508 - val_accuracy: 0.4730\n",
      "Epoch 36/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.9092 - accuracy: 0.4588 - val_loss: 1.7756 - val_accuracy: 0.5013\n",
      "Epoch 37/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.8802 - accuracy: 0.4588 - val_loss: 1.8472 - val_accuracy: 0.5064\n",
      "Epoch 38/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.8116 - accuracy: 0.4594 - val_loss: 1.7158 - val_accuracy: 0.5064\n",
      "Epoch 39/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7253 - accuracy: 0.4736 - val_loss: 2.0569 - val_accuracy: 0.3779\n",
      "Epoch 40/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7451 - accuracy: 0.4691 - val_loss: 1.8567 - val_accuracy: 0.4447\n",
      "Epoch 41/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7170 - accuracy: 0.4652 - val_loss: 1.8052 - val_accuracy: 0.4859\n",
      "Epoch 42/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7111 - accuracy: 0.4710 - val_loss: 1.8165 - val_accuracy: 0.5013\n",
      "Epoch 43/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6508 - accuracy: 0.4845 - val_loss: 1.6087 - val_accuracy: 0.5064\n",
      "Epoch 44/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6243 - accuracy: 0.4755 - val_loss: 1.8129 - val_accuracy: 0.4807\n",
      "Epoch 45/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6220 - accuracy: 0.4794 - val_loss: 1.7222 - val_accuracy: 0.4602\n",
      "Epoch 46/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7019 - accuracy: 0.4807 - val_loss: 1.6514 - val_accuracy: 0.5013\n",
      "Epoch 47/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7205 - accuracy: 0.4768 - val_loss: 1.8090 - val_accuracy: 0.4987\n",
      "Epoch 48/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6598 - accuracy: 0.4755 - val_loss: 1.6891 - val_accuracy: 0.4833\n",
      "Epoch 49/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6479 - accuracy: 0.4781 - val_loss: 1.6339 - val_accuracy: 0.5064\n",
      "Epoch 50/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5966 - accuracy: 0.4742 - val_loss: 1.5845 - val_accuracy: 0.4987\n",
      "Epoch 51/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5966 - accuracy: 0.4697 - val_loss: 1.6986 - val_accuracy: 0.4704\n",
      "Epoch 52/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6172 - accuracy: 0.4723 - val_loss: 1.6138 - val_accuracy: 0.4987\n",
      "Epoch 53/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5830 - accuracy: 0.4781 - val_loss: 1.5865 - val_accuracy: 0.5064\n",
      "Epoch 54/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5433 - accuracy: 0.4858 - val_loss: 1.5473 - val_accuracy: 0.5064\n",
      "Epoch 55/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5643 - accuracy: 0.4845 - val_loss: 1.6999 - val_accuracy: 0.3779\n",
      "Epoch 56/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5739 - accuracy: 0.4787 - val_loss: 1.5515 - val_accuracy: 0.5064\n",
      "Epoch 57/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5960 - accuracy: 0.4787 - val_loss: 1.6173 - val_accuracy: 0.5090\n",
      "Epoch 58/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5665 - accuracy: 0.4820 - val_loss: 1.6332 - val_accuracy: 0.5013\n",
      "Epoch 59/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5451 - accuracy: 0.4755 - val_loss: 1.5289 - val_accuracy: 0.5039\n",
      "Epoch 60/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5043 - accuracy: 0.4762 - val_loss: 1.5187 - val_accuracy: 0.5039\n",
      "Epoch 61/100\n",
      "311/311 [==============================] - 1s 5ms/step - loss: 1.4911 - accuracy: 0.4871 - val_loss: 1.5694 - val_accuracy: 0.5090\n",
      "Epoch 62/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5488 - accuracy: 0.4691 - val_loss: 1.5406 - val_accuracy: 0.4987\n",
      "Epoch 63/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5244 - accuracy: 0.4916 - val_loss: 1.5805 - val_accuracy: 0.4987\n",
      "Epoch 64/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5621 - accuracy: 0.4845 - val_loss: 1.6025 - val_accuracy: 0.4293\n",
      "Epoch 65/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4982 - accuracy: 0.4897 - val_loss: 1.5328 - val_accuracy: 0.5039\n",
      "Epoch 66/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5296 - accuracy: 0.4981 - val_loss: 1.6509 - val_accuracy: 0.4550\n",
      "Epoch 67/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5582 - accuracy: 0.4839 - val_loss: 1.5655 - val_accuracy: 0.5039\n",
      "Epoch 68/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5223 - accuracy: 0.4871 - val_loss: 1.5794 - val_accuracy: 0.5064\n",
      "Epoch 69/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5216 - accuracy: 0.4948 - val_loss: 1.5185 - val_accuracy: 0.5039\n",
      "Epoch 70/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5133 - accuracy: 0.4800 - val_loss: 1.6387 - val_accuracy: 0.4781\n",
      "Epoch 71/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5417 - accuracy: 0.4671 - val_loss: 1.5431 - val_accuracy: 0.5013\n",
      "Epoch 72/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5021 - accuracy: 0.4897 - val_loss: 1.5341 - val_accuracy: 0.5013\n",
      "Epoch 73/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4895 - accuracy: 0.4800 - val_loss: 1.4856 - val_accuracy: 0.5064\n",
      "Epoch 74/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4797 - accuracy: 0.4839 - val_loss: 1.5123 - val_accuracy: 0.5064\n",
      "Epoch 75/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4844 - accuracy: 0.4865 - val_loss: 1.6067 - val_accuracy: 0.4807\n",
      "Epoch 76/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4826 - accuracy: 0.4832 - val_loss: 1.5671 - val_accuracy: 0.4987\n",
      "Epoch 77/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5645 - accuracy: 0.4755 - val_loss: 1.5752 - val_accuracy: 0.4987\n",
      "Epoch 78/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5198 - accuracy: 0.4865 - val_loss: 1.5913 - val_accuracy: 0.4987\n",
      "Epoch 79/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4720 - accuracy: 0.4929 - val_loss: 1.5836 - val_accuracy: 0.4884\n",
      "Epoch 80/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5195 - accuracy: 0.4710 - val_loss: 1.5592 - val_accuracy: 0.4859\n",
      "Epoch 81/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4632 - accuracy: 0.4897 - val_loss: 1.4701 - val_accuracy: 0.5193\n",
      "Epoch 82/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4856 - accuracy: 0.4968 - val_loss: 1.5808 - val_accuracy: 0.4987\n",
      "Epoch 83/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4741 - accuracy: 0.4800 - val_loss: 1.5150 - val_accuracy: 0.4987\n",
      "Epoch 84/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4395 - accuracy: 0.4948 - val_loss: 1.5191 - val_accuracy: 0.5039\n",
      "Epoch 85/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4473 - accuracy: 0.4787 - val_loss: 1.4903 - val_accuracy: 0.5064\n",
      "Epoch 86/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4684 - accuracy: 0.4832 - val_loss: 1.5061 - val_accuracy: 0.5039\n",
      "Epoch 87/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4777 - accuracy: 0.4839 - val_loss: 1.6072 - val_accuracy: 0.5039\n",
      "Epoch 88/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5168 - accuracy: 0.4781 - val_loss: 1.6299 - val_accuracy: 0.4062\n",
      "Epoch 89/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4571 - accuracy: 0.4749 - val_loss: 1.7010 - val_accuracy: 0.3625\n",
      "Epoch 90/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4678 - accuracy: 0.4807 - val_loss: 1.5342 - val_accuracy: 0.5039\n",
      "Epoch 91/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4521 - accuracy: 0.4929 - val_loss: 1.5989 - val_accuracy: 0.4010\n",
      "Epoch 92/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4579 - accuracy: 0.4716 - val_loss: 1.5428 - val_accuracy: 0.5013\n",
      "Epoch 93/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4659 - accuracy: 0.4845 - val_loss: 1.5464 - val_accuracy: 0.4987\n",
      "Epoch 94/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4365 - accuracy: 0.4884 - val_loss: 1.4997 - val_accuracy: 0.4987\n",
      "Epoch 95/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4257 - accuracy: 0.4807 - val_loss: 1.4917 - val_accuracy: 0.5013\n",
      "Epoch 96/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4500 - accuracy: 0.4845 - val_loss: 1.5738 - val_accuracy: 0.4936\n",
      "Epoch 97/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4791 - accuracy: 0.4800 - val_loss: 1.5868 - val_accuracy: 0.4961\n",
      "Epoch 98/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4739 - accuracy: 0.4794 - val_loss: 1.5674 - val_accuracy: 0.4910\n",
      "Epoch 99/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4240 - accuracy: 0.4852 - val_loss: 1.4954 - val_accuracy: 0.4987\n",
      "Epoch 100/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4494 - accuracy: 0.4923 - val_loss: 1.5497 - val_accuracy: 0.4910\n",
      "Accuracy: 0.4910025706940874\n",
      "Log Loss: 1.4910082862279102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='LeakyReLU', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(256, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(128, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(64, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(32, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(16, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=100, batch_size=5, verbose=1, \n",
    "          validation_data=(X_test, tf.keras.utils.to_categorical(y_test)), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 클래스 예측값으로 변환\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "311/311 [==============================] - 2s 3ms/step - loss: 1.9756 - accuracy: 0.2674 - val_loss: 1.9385 - val_accuracy: 0.2751\n",
      "Epoch 2/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7251 - accuracy: 0.3537 - val_loss: 1.7632 - val_accuracy: 0.3342\n",
      "Epoch 3/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6305 - accuracy: 0.4014 - val_loss: 1.7075 - val_accuracy: 0.4010\n",
      "Epoch 4/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5735 - accuracy: 0.4162 - val_loss: 1.6552 - val_accuracy: 0.4370\n",
      "Epoch 5/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.5369 - accuracy: 0.4356 - val_loss: 1.5140 - val_accuracy: 0.4730\n",
      "Epoch 6/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5464 - accuracy: 0.4265 - val_loss: 1.5417 - val_accuracy: 0.4679\n",
      "Epoch 7/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.5114 - accuracy: 0.4388 - val_loss: 1.4785 - val_accuracy: 0.4781\n",
      "Epoch 8/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.5086 - accuracy: 0.4517 - val_loss: 1.4620 - val_accuracy: 0.4859\n",
      "Epoch 9/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4879 - accuracy: 0.4407 - val_loss: 1.5169 - val_accuracy: 0.4499\n",
      "Epoch 10/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4976 - accuracy: 0.4407 - val_loss: 1.5103 - val_accuracy: 0.4704\n",
      "Epoch 11/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4873 - accuracy: 0.4555 - val_loss: 1.6265 - val_accuracy: 0.4422\n",
      "Epoch 12/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4825 - accuracy: 0.4523 - val_loss: 1.4909 - val_accuracy: 0.4524\n",
      "Epoch 13/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4706 - accuracy: 0.4439 - val_loss: 1.4776 - val_accuracy: 0.4730\n",
      "Epoch 14/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4606 - accuracy: 0.4568 - val_loss: 1.4910 - val_accuracy: 0.4936\n",
      "Epoch 15/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4667 - accuracy: 0.4568 - val_loss: 1.5490 - val_accuracy: 0.4730\n",
      "Epoch 16/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4626 - accuracy: 0.4562 - val_loss: 1.5591 - val_accuracy: 0.4833\n",
      "Epoch 17/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4698 - accuracy: 0.4716 - val_loss: 1.5881 - val_accuracy: 0.4936\n",
      "Epoch 18/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4441 - accuracy: 0.4749 - val_loss: 1.6033 - val_accuracy: 0.4602\n",
      "Epoch 19/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4608 - accuracy: 0.4626 - val_loss: 1.4787 - val_accuracy: 0.4730\n",
      "Epoch 20/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4493 - accuracy: 0.4749 - val_loss: 1.5158 - val_accuracy: 0.4807\n",
      "Epoch 21/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4258 - accuracy: 0.4774 - val_loss: 1.4439 - val_accuracy: 0.4961\n",
      "Epoch 22/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4517 - accuracy: 0.4659 - val_loss: 1.5599 - val_accuracy: 0.4653\n",
      "Epoch 23/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4296 - accuracy: 0.4716 - val_loss: 1.4427 - val_accuracy: 0.5064\n",
      "Epoch 24/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4139 - accuracy: 0.4742 - val_loss: 1.4588 - val_accuracy: 0.4961\n",
      "Epoch 25/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4200 - accuracy: 0.4601 - val_loss: 1.4363 - val_accuracy: 0.5090\n",
      "Epoch 26/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4284 - accuracy: 0.4813 - val_loss: 1.4503 - val_accuracy: 0.4936\n",
      "Epoch 27/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4183 - accuracy: 0.4813 - val_loss: 1.4633 - val_accuracy: 0.4833\n",
      "Epoch 28/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4390 - accuracy: 0.4678 - val_loss: 1.4121 - val_accuracy: 0.5013\n",
      "Epoch 29/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4190 - accuracy: 0.4729 - val_loss: 1.4168 - val_accuracy: 0.4961\n",
      "Epoch 30/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4153 - accuracy: 0.4826 - val_loss: 1.4396 - val_accuracy: 0.4961\n",
      "Epoch 31/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4411 - accuracy: 0.4742 - val_loss: 1.4431 - val_accuracy: 0.5116\n",
      "Epoch 32/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4135 - accuracy: 0.4729 - val_loss: 1.4494 - val_accuracy: 0.5064\n",
      "Epoch 33/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4325 - accuracy: 0.4807 - val_loss: 1.4295 - val_accuracy: 0.4884\n",
      "Epoch 34/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4230 - accuracy: 0.4807 - val_loss: 1.5094 - val_accuracy: 0.4936\n",
      "Epoch 35/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4200 - accuracy: 0.4826 - val_loss: 1.4756 - val_accuracy: 0.4987\n",
      "Epoch 36/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4168 - accuracy: 0.4807 - val_loss: 1.4306 - val_accuracy: 0.4987\n",
      "Epoch 37/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4252 - accuracy: 0.4755 - val_loss: 1.4379 - val_accuracy: 0.5064\n",
      "Epoch 38/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4192 - accuracy: 0.4794 - val_loss: 1.4648 - val_accuracy: 0.4936\n",
      "Epoch 39/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3918 - accuracy: 0.4762 - val_loss: 1.4775 - val_accuracy: 0.5090\n",
      "Epoch 40/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4046 - accuracy: 0.4762 - val_loss: 1.4462 - val_accuracy: 0.4859\n",
      "Epoch 41/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3971 - accuracy: 0.4865 - val_loss: 1.3946 - val_accuracy: 0.4910\n",
      "Epoch 42/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4181 - accuracy: 0.4678 - val_loss: 1.4452 - val_accuracy: 0.5064\n",
      "Epoch 43/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4060 - accuracy: 0.4871 - val_loss: 1.4526 - val_accuracy: 0.4910\n",
      "Epoch 44/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4097 - accuracy: 0.4678 - val_loss: 1.4268 - val_accuracy: 0.4987\n",
      "Epoch 45/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3966 - accuracy: 0.4884 - val_loss: 1.3906 - val_accuracy: 0.4936\n",
      "Epoch 46/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4009 - accuracy: 0.4762 - val_loss: 1.4891 - val_accuracy: 0.4859\n",
      "Epoch 47/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4088 - accuracy: 0.4807 - val_loss: 1.4613 - val_accuracy: 0.4679\n",
      "Epoch 48/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3896 - accuracy: 0.4832 - val_loss: 1.4652 - val_accuracy: 0.4961\n",
      "Epoch 49/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.3952 - accuracy: 0.4749 - val_loss: 1.4782 - val_accuracy: 0.4987\n",
      "Epoch 50/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3911 - accuracy: 0.4884 - val_loss: 1.4844 - val_accuracy: 0.5064\n",
      "Epoch 51/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4066 - accuracy: 0.4884 - val_loss: 1.4945 - val_accuracy: 0.5013\n",
      "Epoch 52/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3950 - accuracy: 0.4890 - val_loss: 1.4958 - val_accuracy: 0.4833\n",
      "Epoch 53/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.3901 - accuracy: 0.4878 - val_loss: 1.4825 - val_accuracy: 0.4987\n",
      "Epoch 54/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3807 - accuracy: 0.4865 - val_loss: 1.5870 - val_accuracy: 0.4807\n",
      "Epoch 55/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3995 - accuracy: 0.4787 - val_loss: 1.5271 - val_accuracy: 0.4833\n",
      "Epoch 56/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3892 - accuracy: 0.4774 - val_loss: 1.5312 - val_accuracy: 0.4833\n",
      "Epoch 57/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3744 - accuracy: 0.4884 - val_loss: 1.5236 - val_accuracy: 0.4859\n",
      "Epoch 58/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4110 - accuracy: 0.4762 - val_loss: 1.5485 - val_accuracy: 0.5013\n",
      "Epoch 59/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3872 - accuracy: 0.4787 - val_loss: 1.5181 - val_accuracy: 0.4653\n",
      "Epoch 60/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3972 - accuracy: 0.4845 - val_loss: 1.4977 - val_accuracy: 0.4884\n",
      "Epoch 61/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.3742 - accuracy: 0.4923 - val_loss: 1.5118 - val_accuracy: 0.4833\n",
      "Epoch 62/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3772 - accuracy: 0.4736 - val_loss: 1.5453 - val_accuracy: 0.4910\n",
      "Epoch 63/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3999 - accuracy: 0.4839 - val_loss: 1.6066 - val_accuracy: 0.4524\n",
      "Epoch 64/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3915 - accuracy: 0.4729 - val_loss: 1.5779 - val_accuracy: 0.4679\n",
      "Epoch 65/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3959 - accuracy: 0.4762 - val_loss: 1.5308 - val_accuracy: 0.4936\n",
      "Epoch 66/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3951 - accuracy: 0.4923 - val_loss: 1.4763 - val_accuracy: 0.4987\n",
      "Epoch 67/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3892 - accuracy: 0.4787 - val_loss: 1.5957 - val_accuracy: 0.4807\n",
      "Epoch 68/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3681 - accuracy: 0.4897 - val_loss: 1.6167 - val_accuracy: 0.4781\n",
      "Epoch 69/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3923 - accuracy: 0.4794 - val_loss: 1.5725 - val_accuracy: 0.4884\n",
      "Epoch 70/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3897 - accuracy: 0.4813 - val_loss: 1.6290 - val_accuracy: 0.4756\n",
      "Epoch 71/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3800 - accuracy: 0.4691 - val_loss: 1.5454 - val_accuracy: 0.4961\n",
      "Epoch 72/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3947 - accuracy: 0.4832 - val_loss: 1.6400 - val_accuracy: 0.4807\n",
      "Epoch 73/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4111 - accuracy: 0.4704 - val_loss: 1.5417 - val_accuracy: 0.4807\n",
      "Epoch 74/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3842 - accuracy: 0.4878 - val_loss: 1.5274 - val_accuracy: 0.4859\n",
      "Epoch 75/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3806 - accuracy: 0.4768 - val_loss: 1.5386 - val_accuracy: 0.4859\n",
      "Epoch 76/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3751 - accuracy: 0.4942 - val_loss: 1.5065 - val_accuracy: 0.4961\n",
      "Epoch 77/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3800 - accuracy: 0.4832 - val_loss: 1.5475 - val_accuracy: 0.4987\n",
      "Epoch 78/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3766 - accuracy: 0.4839 - val_loss: 1.5326 - val_accuracy: 0.4936\n",
      "Epoch 79/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3844 - accuracy: 0.4929 - val_loss: 1.5338 - val_accuracy: 0.4807\n",
      "Epoch 80/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3584 - accuracy: 0.4865 - val_loss: 1.4851 - val_accuracy: 0.4730\n",
      "Epoch 81/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3781 - accuracy: 0.4916 - val_loss: 1.4853 - val_accuracy: 0.4884\n",
      "Epoch 82/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.4178 - accuracy: 0.4749 - val_loss: 1.5713 - val_accuracy: 0.4679\n",
      "Epoch 83/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.4034 - accuracy: 0.4807 - val_loss: 1.4862 - val_accuracy: 0.4987\n",
      "Epoch 84/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3852 - accuracy: 0.4852 - val_loss: 1.5611 - val_accuracy: 0.4704\n",
      "Epoch 85/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3723 - accuracy: 0.4729 - val_loss: 1.5368 - val_accuracy: 0.4756\n",
      "Epoch 86/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3649 - accuracy: 0.4858 - val_loss: 1.5636 - val_accuracy: 0.4884\n",
      "Epoch 87/100\n",
      "311/311 [==============================] - ETA: 0s - loss: 1.3664 - accuracy: 0.48 - 1s 4ms/step - loss: 1.3663 - accuracy: 0.4884 - val_loss: 1.4870 - val_accuracy: 0.4859\n",
      "Epoch 88/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.3766 - accuracy: 0.4813 - val_loss: 1.4931 - val_accuracy: 0.4987\n",
      "Epoch 89/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3654 - accuracy: 0.4910 - val_loss: 1.4798 - val_accuracy: 0.4936\n",
      "Epoch 90/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3558 - accuracy: 0.4884 - val_loss: 1.5061 - val_accuracy: 0.4833\n",
      "Epoch 91/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3656 - accuracy: 0.4871 - val_loss: 1.5163 - val_accuracy: 0.4833\n",
      "Epoch 92/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3708 - accuracy: 0.4852 - val_loss: 1.5952 - val_accuracy: 0.4781\n",
      "Epoch 93/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.3623 - accuracy: 0.4884 - val_loss: 1.5222 - val_accuracy: 0.4833\n",
      "Epoch 94/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.3504 - accuracy: 0.4936 - val_loss: 1.5198 - val_accuracy: 0.4679\n",
      "Epoch 95/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3566 - accuracy: 0.4845 - val_loss: 1.5714 - val_accuracy: 0.4833\n",
      "Epoch 96/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3654 - accuracy: 0.4865 - val_loss: 1.5600 - val_accuracy: 0.4704\n",
      "Epoch 97/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3480 - accuracy: 0.4858 - val_loss: 1.5559 - val_accuracy: 0.4653\n",
      "Epoch 98/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3595 - accuracy: 0.4968 - val_loss: 1.5280 - val_accuracy: 0.4910\n",
      "Epoch 99/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3595 - accuracy: 0.4890 - val_loss: 1.5528 - val_accuracy: 0.4833\n",
      "Epoch 100/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.3689 - accuracy: 0.4968 - val_loss: 1.5213 - val_accuracy: 0.5013\n",
      "Accuracy: 0.5012853470437018\n",
      "Log Loss: 1.5212864563596893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='ReLU', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(16, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=100, batch_size=5, verbose=1, \n",
    "          validation_data=(X_test, tf.keras.utils.to_categorical(y_test)), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 클래스 예측값으로 변환\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "311/311 [==============================] - 2s 3ms/step - loss: 1.7620 - accuracy: 0.3351 - val_loss: 1.6034 - val_accuracy: 0.4242\n",
      "Epoch 2/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5468 - accuracy: 0.4555 - val_loss: 1.4867 - val_accuracy: 0.4704\n",
      "Epoch 3/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5303 - accuracy: 0.4388 - val_loss: 1.4969 - val_accuracy: 0.4679\n",
      "Epoch 4/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.5274 - accuracy: 0.4439 - val_loss: 1.5056 - val_accuracy: 0.4833\n",
      "Epoch 5/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4823 - accuracy: 0.4562 - val_loss: 1.5088 - val_accuracy: 0.4396\n",
      "Epoch 6/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4792 - accuracy: 0.4394 - val_loss: 1.4603 - val_accuracy: 0.4781\n",
      "Epoch 7/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4897 - accuracy: 0.4594 - val_loss: 1.5093 - val_accuracy: 0.4679\n",
      "Epoch 8/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4736 - accuracy: 0.4613 - val_loss: 1.5066 - val_accuracy: 0.4679\n",
      "Epoch 9/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4875 - accuracy: 0.4575 - val_loss: 1.4666 - val_accuracy: 0.4756\n",
      "Epoch 10/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4976 - accuracy: 0.4581 - val_loss: 1.4571 - val_accuracy: 0.4756\n",
      "Epoch 11/100\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 1.4660 - accuracy: 0.4723 - val_loss: 1.5061 - val_accuracy: 0.4499\n",
      "Epoch 12/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4640 - accuracy: 0.4613 - val_loss: 1.4584 - val_accuracy: 0.4936\n",
      "Epoch 13/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4397 - accuracy: 0.4639 - val_loss: 1.5026 - val_accuracy: 0.4807\n",
      "Epoch 14/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4599 - accuracy: 0.4601 - val_loss: 1.4635 - val_accuracy: 0.4936\n",
      "Epoch 15/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4808 - accuracy: 0.4517 - val_loss: 1.6647 - val_accuracy: 0.3985\n",
      "Epoch 16/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4707 - accuracy: 0.4485 - val_loss: 1.4402 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4626 - accuracy: 0.4646 - val_loss: 1.4141 - val_accuracy: 0.4627\n",
      "Epoch 18/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4374 - accuracy: 0.4601 - val_loss: 1.4532 - val_accuracy: 0.4807\n",
      "Epoch 19/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4692 - accuracy: 0.4439 - val_loss: 1.5144 - val_accuracy: 0.4859\n",
      "Epoch 20/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4825 - accuracy: 0.4427 - val_loss: 1.4376 - val_accuracy: 0.4679\n",
      "Epoch 21/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4631 - accuracy: 0.4530 - val_loss: 1.4103 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4586 - accuracy: 0.4633 - val_loss: 1.4295 - val_accuracy: 0.4936\n",
      "Epoch 23/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4710 - accuracy: 0.4665 - val_loss: 1.4471 - val_accuracy: 0.4987\n",
      "Epoch 24/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4408 - accuracy: 0.4691 - val_loss: 1.4092 - val_accuracy: 0.4961\n",
      "Epoch 25/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4801 - accuracy: 0.4504 - val_loss: 2.1436 - val_accuracy: 0.3625\n",
      "Epoch 26/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4423 - accuracy: 0.4723 - val_loss: 1.4195 - val_accuracy: 0.4936\n",
      "Epoch 27/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4487 - accuracy: 0.4659 - val_loss: 1.4573 - val_accuracy: 0.4987\n",
      "Epoch 28/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4507 - accuracy: 0.4684 - val_loss: 1.5253 - val_accuracy: 0.4370\n",
      "Epoch 29/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4339 - accuracy: 0.4781 - val_loss: 1.4739 - val_accuracy: 0.4781\n",
      "Epoch 30/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4608 - accuracy: 0.4620 - val_loss: 1.4185 - val_accuracy: 0.4884\n",
      "Epoch 31/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4562 - accuracy: 0.4581 - val_loss: 1.4394 - val_accuracy: 0.4730\n",
      "Epoch 32/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4500 - accuracy: 0.4697 - val_loss: 1.4544 - val_accuracy: 0.4884\n",
      "Epoch 33/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4195 - accuracy: 0.4749 - val_loss: 1.4470 - val_accuracy: 0.4679\n",
      "Epoch 34/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4395 - accuracy: 0.4639 - val_loss: 1.4392 - val_accuracy: 0.4730\n",
      "Epoch 35/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4376 - accuracy: 0.4633 - val_loss: 1.4649 - val_accuracy: 0.4756\n",
      "Epoch 36/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4495 - accuracy: 0.4485 - val_loss: 1.5729 - val_accuracy: 0.3882\n",
      "Epoch 37/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4471 - accuracy: 0.4594 - val_loss: 1.5185 - val_accuracy: 0.4704\n",
      "Epoch 38/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4438 - accuracy: 0.4665 - val_loss: 1.4085 - val_accuracy: 0.4653\n",
      "Epoch 39/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4357 - accuracy: 0.4504 - val_loss: 1.4410 - val_accuracy: 0.4524\n",
      "Epoch 40/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4385 - accuracy: 0.4549 - val_loss: 1.4566 - val_accuracy: 0.4936\n",
      "Epoch 41/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4228 - accuracy: 0.4691 - val_loss: 1.4815 - val_accuracy: 0.4756\n",
      "Epoch 42/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4403 - accuracy: 0.4646 - val_loss: 1.4408 - val_accuracy: 0.4910\n",
      "Epoch 43/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4430 - accuracy: 0.4678 - val_loss: 1.4469 - val_accuracy: 0.4781\n",
      "Epoch 44/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4443 - accuracy: 0.4626 - val_loss: 1.3992 - val_accuracy: 0.4884\n",
      "Epoch 45/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4521 - accuracy: 0.4620 - val_loss: 1.4336 - val_accuracy: 0.4961\n",
      "Epoch 46/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4355 - accuracy: 0.4601 - val_loss: 1.4135 - val_accuracy: 0.5141\n",
      "Epoch 47/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4410 - accuracy: 0.4639 - val_loss: 1.4473 - val_accuracy: 0.4884\n",
      "Epoch 48/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4394 - accuracy: 0.4697 - val_loss: 1.4983 - val_accuracy: 0.4242\n",
      "Epoch 49/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4425 - accuracy: 0.4659 - val_loss: 1.4054 - val_accuracy: 0.5013\n",
      "Epoch 50/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4343 - accuracy: 0.4878 - val_loss: 1.4098 - val_accuracy: 0.4987\n",
      "Epoch 51/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4139 - accuracy: 0.4774 - val_loss: 1.4529 - val_accuracy: 0.4987\n",
      "Epoch 52/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4395 - accuracy: 0.4620 - val_loss: 1.4216 - val_accuracy: 0.4756\n",
      "Epoch 53/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4455 - accuracy: 0.4813 - val_loss: 1.4548 - val_accuracy: 0.4473\n",
      "Epoch 54/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4405 - accuracy: 0.4659 - val_loss: 1.4116 - val_accuracy: 0.4679\n",
      "Epoch 55/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4424 - accuracy: 0.4684 - val_loss: 1.4809 - val_accuracy: 0.4627\n",
      "Epoch 56/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4398 - accuracy: 0.4684 - val_loss: 1.4155 - val_accuracy: 0.4859\n",
      "Epoch 57/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4163 - accuracy: 0.4794 - val_loss: 1.4605 - val_accuracy: 0.4756\n",
      "Epoch 58/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4282 - accuracy: 0.4794 - val_loss: 1.4286 - val_accuracy: 0.4936\n",
      "Epoch 59/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4400 - accuracy: 0.4691 - val_loss: 1.4525 - val_accuracy: 0.4781\n",
      "Epoch 60/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4232 - accuracy: 0.4678 - val_loss: 1.4251 - val_accuracy: 0.4833\n",
      "Epoch 61/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4349 - accuracy: 0.4710 - val_loss: 1.4635 - val_accuracy: 0.4756\n",
      "Epoch 62/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4307 - accuracy: 0.4639 - val_loss: 1.4839 - val_accuracy: 0.4730\n",
      "Epoch 63/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4069 - accuracy: 0.4858 - val_loss: 1.4592 - val_accuracy: 0.4704\n",
      "Epoch 64/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4361 - accuracy: 0.4588 - val_loss: 1.4433 - val_accuracy: 0.4730\n",
      "Epoch 65/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4133 - accuracy: 0.4626 - val_loss: 1.5992 - val_accuracy: 0.4319\n",
      "Epoch 66/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4269 - accuracy: 0.4691 - val_loss: 1.4632 - val_accuracy: 0.4807\n",
      "Epoch 67/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4406 - accuracy: 0.4581 - val_loss: 1.4999 - val_accuracy: 0.4704\n",
      "Epoch 68/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4498 - accuracy: 0.4736 - val_loss: 1.4546 - val_accuracy: 0.4781\n",
      "Epoch 69/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4179 - accuracy: 0.4716 - val_loss: 1.4724 - val_accuracy: 0.4859\n",
      "Epoch 70/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4107 - accuracy: 0.4742 - val_loss: 1.4541 - val_accuracy: 0.4859\n",
      "Epoch 71/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4312 - accuracy: 0.4729 - val_loss: 1.4562 - val_accuracy: 0.4730\n",
      "Epoch 72/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4058 - accuracy: 0.4716 - val_loss: 1.4421 - val_accuracy: 0.4936\n",
      "Epoch 73/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4351 - accuracy: 0.4652 - val_loss: 1.4379 - val_accuracy: 0.5013\n",
      "Epoch 74/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4378 - accuracy: 0.4762 - val_loss: 1.4623 - val_accuracy: 0.4961\n",
      "Epoch 75/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4288 - accuracy: 0.4762 - val_loss: 1.4576 - val_accuracy: 0.4833\n",
      "Epoch 76/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4319 - accuracy: 0.4652 - val_loss: 1.4725 - val_accuracy: 0.4833\n",
      "Epoch 77/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4092 - accuracy: 0.4755 - val_loss: 1.4381 - val_accuracy: 0.4936\n",
      "Epoch 78/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4079 - accuracy: 0.4865 - val_loss: 1.4792 - val_accuracy: 0.4884\n",
      "Epoch 79/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4216 - accuracy: 0.4736 - val_loss: 1.4552 - val_accuracy: 0.4499\n",
      "Epoch 80/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4151 - accuracy: 0.4613 - val_loss: 1.5568 - val_accuracy: 0.4602\n",
      "Epoch 81/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4104 - accuracy: 0.4794 - val_loss: 1.5348 - val_accuracy: 0.4730\n",
      "Epoch 82/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4157 - accuracy: 0.4820 - val_loss: 1.4955 - val_accuracy: 0.4576\n",
      "Epoch 83/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4307 - accuracy: 0.4839 - val_loss: 2.1351 - val_accuracy: 0.4344\n",
      "Epoch 84/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4136 - accuracy: 0.4665 - val_loss: 1.4660 - val_accuracy: 0.4730\n",
      "Epoch 85/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4134 - accuracy: 0.4646 - val_loss: 1.4684 - val_accuracy: 0.4756\n",
      "Epoch 86/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4192 - accuracy: 0.4826 - val_loss: 1.5217 - val_accuracy: 0.4756\n",
      "Epoch 87/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4191 - accuracy: 0.4716 - val_loss: 1.4560 - val_accuracy: 0.4781\n",
      "Epoch 88/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4017 - accuracy: 0.4878 - val_loss: 1.4431 - val_accuracy: 0.4679\n",
      "Epoch 89/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4294 - accuracy: 0.4768 - val_loss: 1.4567 - val_accuracy: 0.4884\n",
      "Epoch 90/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3982 - accuracy: 0.4910 - val_loss: 1.4894 - val_accuracy: 0.4910\n",
      "Epoch 91/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4134 - accuracy: 0.4832 - val_loss: 1.4856 - val_accuracy: 0.4859\n",
      "Epoch 92/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4091 - accuracy: 0.4897 - val_loss: 1.4867 - val_accuracy: 0.4936\n",
      "Epoch 93/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3862 - accuracy: 0.4800 - val_loss: 1.4549 - val_accuracy: 0.4961\n",
      "Epoch 94/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.4671 - val_loss: 1.4498 - val_accuracy: 0.4987\n",
      "Epoch 95/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3957 - accuracy: 0.4839 - val_loss: 1.4595 - val_accuracy: 0.4910\n",
      "Epoch 96/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4252 - accuracy: 0.4716 - val_loss: 1.4873 - val_accuracy: 0.4756\n",
      "Epoch 97/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4147 - accuracy: 0.4832 - val_loss: 1.4858 - val_accuracy: 0.4987\n",
      "Epoch 98/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3966 - accuracy: 0.4884 - val_loss: 1.4546 - val_accuracy: 0.4884\n",
      "Epoch 99/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.3932 - accuracy: 0.4839 - val_loss: 1.5087 - val_accuracy: 0.4936\n",
      "Epoch 100/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.4060 - accuracy: 0.4878 - val_loss: 1.4828 - val_accuracy: 0.4859\n",
      "Accuracy: 0.48586118251928023\n",
      "Log Loss: 1.4827737877430314\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='ReLU', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(16, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=100, batch_size=5, verbose=1, \n",
    "          validation_data=(X_test, tf.keras.utils.to_categorical(y_test)), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 클래스 예측값으로 변환\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "776/776 [==============================] - 2s 2ms/step - loss: 1.7387 - accuracy: 0.3595 - val_loss: 2.2191 - val_accuracy: 0.3470\n",
      "Epoch 2/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5990 - accuracy: 0.4343 - val_loss: 2.0305 - val_accuracy: 0.3933\n",
      "Epoch 3/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5679 - accuracy: 0.4336 - val_loss: 2.3401 - val_accuracy: 0.3599\n",
      "Epoch 4/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5424 - accuracy: 0.4265 - val_loss: 2.4081 - val_accuracy: 0.3805\n",
      "Epoch 5/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5362 - accuracy: 0.4381 - val_loss: 2.6595 - val_accuracy: 0.3882\n",
      "Epoch 6/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 0.44 - 1s 1ms/step - loss: 1.5301 - accuracy: 0.4465 - val_loss: 2.6912 - val_accuracy: 0.3933\n",
      "Epoch 7/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5713 - accuracy: 0.4195 - val_loss: 2.1897 - val_accuracy: 0.3650\n",
      "Epoch 8/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5447 - accuracy: 0.4381 - val_loss: 2.2385 - val_accuracy: 0.3522\n",
      "Epoch 9/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5651 - accuracy: 0.4311 - val_loss: 2.2494 - val_accuracy: 0.3856\n",
      "Epoch 10/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5589 - accuracy: 0.4317 - val_loss: 2.4162 - val_accuracy: 0.3599\n",
      "Epoch 11/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5535 - accuracy: 0.4298 - val_loss: 2.6998 - val_accuracy: 0.3753\n",
      "Epoch 12/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5466 - accuracy: 0.4594 - val_loss: 2.4122 - val_accuracy: 0.3522\n",
      "Epoch 13/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5299 - accuracy: 0.4427 - val_loss: 2.4893 - val_accuracy: 0.3933\n",
      "Epoch 14/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5812 - accuracy: 0.4259 - val_loss: 2.5470 - val_accuracy: 0.3573\n",
      "Epoch 15/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5264 - accuracy: 0.4523 - val_loss: 2.1336 - val_accuracy: 0.4370\n",
      "Epoch 16/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5641 - accuracy: 0.4317 - val_loss: 1.9198 - val_accuracy: 0.4627\n",
      "Epoch 17/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5765 - accuracy: 0.4195 - val_loss: 2.3530 - val_accuracy: 0.3599\n",
      "Epoch 18/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5640 - accuracy: 0.4259 - val_loss: 2.1485 - val_accuracy: 0.3830\n",
      "Epoch 19/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5707 - accuracy: 0.4323 - val_loss: 2.2369 - val_accuracy: 0.3830\n",
      "Epoch 20/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5428 - accuracy: 0.4323 - val_loss: 2.4790 - val_accuracy: 0.3599\n",
      "Epoch 21/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5446 - accuracy: 0.4401 - val_loss: 2.1327 - val_accuracy: 0.4447\n",
      "Epoch 22/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5528 - accuracy: 0.4407 - val_loss: 2.4552 - val_accuracy: 0.3753\n",
      "Epoch 23/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5386 - accuracy: 0.4478 - val_loss: 2.2212 - val_accuracy: 0.4447\n",
      "Epoch 24/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5645 - accuracy: 0.4278 - val_loss: 2.5916 - val_accuracy: 0.3830\n",
      "Epoch 25/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5334 - accuracy: 0.4472 - val_loss: 2.2475 - val_accuracy: 0.4396\n",
      "Epoch 26/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5576 - accuracy: 0.4265 - val_loss: 2.4012 - val_accuracy: 0.4216\n",
      "Epoch 27/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5333 - accuracy: 0.4317 - val_loss: 2.1146 - val_accuracy: 0.4602\n",
      "Epoch 28/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 1.5497 - accuracy: 0.42 - 1s 1ms/step - loss: 1.5507 - accuracy: 0.4298 - val_loss: 2.3999 - val_accuracy: 0.3830\n",
      "Epoch 29/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5494 - accuracy: 0.4278 - val_loss: 2.4279 - val_accuracy: 0.4190\n",
      "Epoch 30/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5436 - accuracy: 0.4336 - val_loss: 2.5996 - val_accuracy: 0.4242\n",
      "Epoch 31/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5373 - accuracy: 0.4375 - val_loss: 2.3021 - val_accuracy: 0.4447\n",
      "Epoch 32/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5484 - accuracy: 0.4343 - val_loss: 2.5452 - val_accuracy: 0.4704\n",
      "Epoch 33/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5338 - accuracy: 0.4375 - val_loss: 3.2208 - val_accuracy: 0.4473\n",
      "Epoch 34/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5291 - accuracy: 0.4388 - val_loss: 4.1927 - val_accuracy: 0.4447\n",
      "Epoch 35/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5690 - accuracy: 0.4214 - val_loss: 2.9448 - val_accuracy: 0.4730\n",
      "Epoch 36/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5362 - accuracy: 0.4169 - val_loss: 2.6640 - val_accuracy: 0.4627\n",
      "Epoch 37/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5455 - accuracy: 0.4401 - val_loss: 2.2170 - val_accuracy: 0.4473\n",
      "Epoch 38/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5095 - accuracy: 0.4401 - val_loss: 2.4470 - val_accuracy: 0.4370\n",
      "Epoch 39/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5313 - accuracy: 0.4304 - val_loss: 2.1417 - val_accuracy: 0.4473\n",
      "Epoch 40/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5250 - accuracy: 0.4491 - val_loss: 2.1385 - val_accuracy: 0.4781\n",
      "Epoch 41/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5468 - accuracy: 0.4478 - val_loss: 2.0824 - val_accuracy: 0.4730\n",
      "Epoch 42/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5334 - accuracy: 0.4452 - val_loss: 2.1577 - val_accuracy: 0.4781\n",
      "Epoch 43/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5375 - accuracy: 0.4452 - val_loss: 2.1033 - val_accuracy: 0.4833\n",
      "Epoch 44/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5254 - accuracy: 0.4562 - val_loss: 1.9635 - val_accuracy: 0.5013\n",
      "Epoch 45/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5540 - accuracy: 0.4356 - val_loss: 2.1699 - val_accuracy: 0.4653\n",
      "Epoch 46/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5529 - accuracy: 0.4330 - val_loss: 1.9000 - val_accuracy: 0.4730\n",
      "Epoch 47/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5164 - accuracy: 0.4575 - val_loss: 2.0794 - val_accuracy: 0.4730\n",
      "Epoch 48/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5346 - accuracy: 0.4381 - val_loss: 1.9738 - val_accuracy: 0.4602\n",
      "Epoch 49/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5305 - accuracy: 0.4291 - val_loss: 2.1243 - val_accuracy: 0.4550\n",
      "Epoch 50/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5362 - accuracy: 0.4439 - val_loss: 2.0333 - val_accuracy: 0.4833\n",
      "Epoch 51/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5254 - accuracy: 0.4427 - val_loss: 2.4146 - val_accuracy: 0.4344\n",
      "Epoch 52/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5449 - accuracy: 0.4356 - val_loss: 2.4400 - val_accuracy: 0.4679\n",
      "Epoch 53/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5401 - accuracy: 0.4504 - val_loss: 2.5459 - val_accuracy: 0.5090\n",
      "Epoch 54/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5410 - accuracy: 0.4407 - val_loss: 2.6694 - val_accuracy: 0.4730\n",
      "Epoch 55/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5625 - accuracy: 0.4246 - val_loss: 2.5370 - val_accuracy: 0.5039\n",
      "Epoch 56/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5387 - accuracy: 0.4304 - val_loss: 2.5212 - val_accuracy: 0.4807\n",
      "Epoch 57/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5427 - accuracy: 0.4349 - val_loss: 2.2608 - val_accuracy: 0.4267\n",
      "Epoch 58/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5405 - accuracy: 0.4446 - val_loss: 2.7568 - val_accuracy: 0.3728\n",
      "Epoch 59/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5523 - accuracy: 0.4285 - val_loss: 3.0141 - val_accuracy: 0.4473\n",
      "Epoch 60/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5748 - accuracy: 0.4220 - val_loss: 2.5940 - val_accuracy: 0.4036\n",
      "Epoch 61/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5401 - accuracy: 0.4343 - val_loss: 2.4231 - val_accuracy: 0.4473\n",
      "Epoch 62/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5301 - accuracy: 0.4414 - val_loss: 2.4269 - val_accuracy: 0.4756\n",
      "Epoch 63/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5659 - accuracy: 0.4407 - val_loss: 3.1284 - val_accuracy: 0.4756\n",
      "Epoch 64/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5307 - accuracy: 0.4317 - val_loss: 2.4931 - val_accuracy: 0.4910\n",
      "Epoch 65/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5632 - accuracy: 0.4169 - val_loss: 2.8763 - val_accuracy: 0.4910\n",
      "Epoch 66/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5444 - accuracy: 0.4336 - val_loss: 2.7797 - val_accuracy: 0.4987\n",
      "Epoch 67/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5589 - accuracy: 0.4362 - val_loss: 2.6182 - val_accuracy: 0.4987\n",
      "Epoch 68/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5624 - accuracy: 0.4265 - val_loss: 3.2923 - val_accuracy: 0.4653\n",
      "Epoch 69/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5850 - accuracy: 0.4149 - val_loss: 3.0530 - val_accuracy: 0.4653\n",
      "Epoch 70/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6067 - accuracy: 0.4079 - val_loss: 2.8568 - val_accuracy: 0.4576\n",
      "Epoch 71/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5982 - accuracy: 0.3988 - val_loss: 2.3847 - val_accuracy: 0.4422\n",
      "Epoch 72/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5930 - accuracy: 0.4040 - val_loss: 2.2474 - val_accuracy: 0.4679\n",
      "Epoch 73/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6092 - accuracy: 0.3963 - val_loss: 2.2987 - val_accuracy: 0.4859\n",
      "Epoch 74/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5729 - accuracy: 0.4227 - val_loss: 2.2917 - val_accuracy: 0.4653\n",
      "Epoch 75/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5651 - accuracy: 0.4246 - val_loss: 2.0634 - val_accuracy: 0.3933\n",
      "Epoch 76/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5682 - accuracy: 0.4195 - val_loss: 2.0522 - val_accuracy: 0.4087\n",
      "Epoch 77/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6016 - accuracy: 0.3750 - val_loss: 1.9861 - val_accuracy: 0.4756\n",
      "Epoch 78/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5874 - accuracy: 0.4040 - val_loss: 1.8583 - val_accuracy: 0.5064\n",
      "Epoch 79/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5744 - accuracy: 0.4111 - val_loss: 1.9829 - val_accuracy: 0.4576\n",
      "Epoch 80/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5838 - accuracy: 0.4053 - val_loss: 1.9806 - val_accuracy: 0.4627\n",
      "Epoch 81/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5734 - accuracy: 0.4388 - val_loss: 1.9370 - val_accuracy: 0.4756\n",
      "Epoch 82/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5709 - accuracy: 0.4439 - val_loss: 1.8058 - val_accuracy: 0.3548\n",
      "Epoch 83/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5497 - accuracy: 0.4401 - val_loss: 1.8470 - val_accuracy: 0.4807\n",
      "Epoch 84/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5377 - accuracy: 0.4414 - val_loss: 1.9661 - val_accuracy: 0.4267\n",
      "Epoch 85/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6047 - accuracy: 0.4014 - val_loss: 1.9615 - val_accuracy: 0.3599\n",
      "Epoch 86/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5979 - accuracy: 0.4104 - val_loss: 1.8983 - val_accuracy: 0.4062\n",
      "Epoch 87/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5988 - accuracy: 0.3956 - val_loss: 2.1424 - val_accuracy: 0.3676\n",
      "Epoch 88/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5993 - accuracy: 0.3930 - val_loss: 2.4443 - val_accuracy: 0.3650\n",
      "Epoch 89/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6010 - accuracy: 0.3776 - val_loss: 2.6348 - val_accuracy: 0.3470\n",
      "Epoch 90/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6130 - accuracy: 0.3840 - val_loss: 2.0740 - val_accuracy: 0.4859\n",
      "Epoch 91/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5802 - accuracy: 0.3988 - val_loss: 2.0052 - val_accuracy: 0.4961\n",
      "Epoch 92/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5879 - accuracy: 0.3950 - val_loss: 1.9065 - val_accuracy: 0.4704\n",
      "Epoch 93/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5817 - accuracy: 0.4008 - val_loss: 2.0282 - val_accuracy: 0.4730\n",
      "Epoch 94/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.6048 - accuracy: 0.3905 - val_loss: 1.9917 - val_accuracy: 0.4859\n",
      "Epoch 95/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5901 - accuracy: 0.3924 - val_loss: 2.1845 - val_accuracy: 0.4807\n",
      "Epoch 96/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5981 - accuracy: 0.3885 - val_loss: 2.8175 - val_accuracy: 0.4781\n",
      "Epoch 97/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5792 - accuracy: 0.4053 - val_loss: 6.8076 - val_accuracy: 0.4010\n",
      "Epoch 98/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5777 - accuracy: 0.4111 - val_loss: 4.4129 - val_accuracy: 0.4653\n",
      "Epoch 99/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5721 - accuracy: 0.4156 - val_loss: 3.8130 - val_accuracy: 0.4653\n",
      "Epoch 100/100\n",
      "776/776 [==============================] - 1s 1ms/step - loss: 1.5897 - accuracy: 0.4137 - val_loss: 4.6384 - val_accuracy: 0.4216\n",
      "Accuracy: 0.42159383033419023\n",
      "Log Loss: 2.7292443461216584\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='ReLU', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='ReLU'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=100, batch_size=2, verbose=1, \n",
    "          validation_data=(X_test, tf.keras.utils.to_categorical(y_test)), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 클래스 예측값으로 변환\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "311/311 [==============================] - 2s 3ms/step - loss: 2327.1394 - accuracy: 0.2726 - val_loss: 2.1857 - val_accuracy: 0.3805\n",
      "Epoch 2/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 5.0689 - accuracy: 0.3363 - val_loss: 4.0260 - val_accuracy: 0.3650\n",
      "Epoch 3/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 7.7031 - accuracy: 0.3415 - val_loss: 1.8649 - val_accuracy: 0.3650\n",
      "Epoch 4/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.8531 - accuracy: 0.3421 - val_loss: 1.8294 - val_accuracy: 0.3650\n",
      "Epoch 5/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.8209 - accuracy: 0.3421 - val_loss: 1.7988 - val_accuracy: 0.3650\n",
      "Epoch 6/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.7953 - accuracy: 0.3421 - val_loss: 1.7757 - val_accuracy: 0.3650\n",
      "Epoch 7/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7753 - accuracy: 0.3421 - val_loss: 1.7565 - val_accuracy: 0.3650\n",
      "Epoch 8/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.7586 - accuracy: 0.3421 - val_loss: 1.7396 - val_accuracy: 0.3650\n",
      "Epoch 9/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.7443 - accuracy: 0.3421 - val_loss: 1.7266 - val_accuracy: 0.3650\n",
      "Epoch 10/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7336 - accuracy: 0.3421 - val_loss: 1.7159 - val_accuracy: 0.3650\n",
      "Epoch 11/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7248 - accuracy: 0.3421 - val_loss: 1.7075 - val_accuracy: 0.3650\n",
      "Epoch 12/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7178 - accuracy: 0.3421 - val_loss: 1.7000 - val_accuracy: 0.3650\n",
      "Epoch 13/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.7114 - accuracy: 0.3421 - val_loss: 1.6935 - val_accuracy: 0.3650\n",
      "Epoch 14/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.7058 - accuracy: 0.3421 - val_loss: 1.6880 - val_accuracy: 0.3650\n",
      "Epoch 15/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.7017 - accuracy: 0.3421 - val_loss: 1.6843 - val_accuracy: 0.3650\n",
      "Epoch 16/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6986 - accuracy: 0.3421 - val_loss: 1.6809 - val_accuracy: 0.3650\n",
      "Epoch 17/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6956 - accuracy: 0.3421 - val_loss: 1.6777 - val_accuracy: 0.3650\n",
      "Epoch 18/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6930 - accuracy: 0.3421 - val_loss: 1.6750 - val_accuracy: 0.3650\n",
      "Epoch 19/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6908 - accuracy: 0.3421 - val_loss: 1.6729 - val_accuracy: 0.3650\n",
      "Epoch 20/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6889 - accuracy: 0.3421 - val_loss: 1.6710 - val_accuracy: 0.3650\n",
      "Epoch 21/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6873 - accuracy: 0.3421 - val_loss: 1.6692 - val_accuracy: 0.3650\n",
      "Epoch 22/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6858 - accuracy: 0.3421 - val_loss: 1.6677 - val_accuracy: 0.3650\n",
      "Epoch 23/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6846 - accuracy: 0.3421 - val_loss: 1.6665 - val_accuracy: 0.3650\n",
      "Epoch 24/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6836 - accuracy: 0.3421 - val_loss: 1.6654 - val_accuracy: 0.3650\n",
      "Epoch 25/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6827 - accuracy: 0.3421 - val_loss: 1.6645 - val_accuracy: 0.3650\n",
      "Epoch 26/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6820 - accuracy: 0.3421 - val_loss: 1.6639 - val_accuracy: 0.3650\n",
      "Epoch 27/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6812 - accuracy: 0.3421 - val_loss: 1.6631 - val_accuracy: 0.3650\n",
      "Epoch 28/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6806 - accuracy: 0.3421 - val_loss: 1.6624 - val_accuracy: 0.3650\n",
      "Epoch 29/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6800 - accuracy: 0.3421 - val_loss: 1.6619 - val_accuracy: 0.3650\n",
      "Epoch 30/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6795 - accuracy: 0.3421 - val_loss: 1.6615 - val_accuracy: 0.3650\n",
      "Epoch 31/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6790 - accuracy: 0.3421 - val_loss: 1.6610 - val_accuracy: 0.3650\n",
      "Epoch 32/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6786 - accuracy: 0.3421 - val_loss: 1.6606 - val_accuracy: 0.3650\n",
      "Epoch 33/100\n",
      "311/311 [==============================] - 1s 3ms/step - loss: 1.6782 - accuracy: 0.3421 - val_loss: 1.6602 - val_accuracy: 0.3650\n",
      "Epoch 34/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6779 - accuracy: 0.3421 - val_loss: 1.6599 - val_accuracy: 0.3650\n",
      "Epoch 35/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6776 - accuracy: 0.3421 - val_loss: 1.6597 - val_accuracy: 0.3650\n",
      "Epoch 36/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6773 - accuracy: 0.3421 - val_loss: 1.6595 - val_accuracy: 0.3650\n",
      "Epoch 37/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6771 - accuracy: 0.3421 - val_loss: 1.6593 - val_accuracy: 0.3650\n",
      "Epoch 38/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6769 - accuracy: 0.3421 - val_loss: 1.6591 - val_accuracy: 0.3650\n",
      "Epoch 39/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6766 - accuracy: 0.3421 - val_loss: 1.6590 - val_accuracy: 0.3650\n",
      "Epoch 40/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6765 - accuracy: 0.3421 - val_loss: 1.6588 - val_accuracy: 0.3650\n",
      "Epoch 41/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6763 - accuracy: 0.3421 - val_loss: 1.6587 - val_accuracy: 0.3650\n",
      "Epoch 42/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6761 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 43/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6760 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 44/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6758 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 45/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6757 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 46/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6756 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 47/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6755 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 48/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6754 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 49/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6753 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 50/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6753 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 51/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6752 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 52/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6751 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 53/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6750 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 54/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6750 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 55/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6749 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 56/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6749 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 57/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6748 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 58/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6748 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 59/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6748 - accuracy: 0.3421 - val_loss: 1.6581 - val_accuracy: 0.3650\n",
      "Epoch 60/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6747 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 61/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6747 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 62/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6747 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 63/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6747 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 64/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6746 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 65/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6746 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 66/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6746 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 67/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 68/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 69/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6582 - val_accuracy: 0.3650\n",
      "Epoch 70/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 71/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 72/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 73/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 74/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 75/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 76/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6583 - val_accuracy: 0.3650\n",
      "Epoch 77/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 78/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 79/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6584 - val_accuracy: 0.3650\n",
      "Epoch 80/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 81/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 82/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 83/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 84/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 85/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 86/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 87/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 88/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 89/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 90/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 91/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 92/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.3421 - val_loss: 1.6585 - val_accuracy: 0.3650\n",
      "Epoch 93/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6743 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 94/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 95/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 96/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 97/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 98/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 99/100\n",
      "311/311 [==============================] - 0s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Epoch 100/100\n",
      "311/311 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3421 - val_loss: 1.6586 - val_accuracy: 0.3650\n",
      "Accuracy: 0.36503856041131105\n",
      "Log Loss: 1.6585773793468133\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='ReLU', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='ReLU'),  \n",
    "    tf.keras.layers.Dense(128, activation='ReLU'),  \n",
    "    tf.keras.layers.Dense(64, activation='ReLU'),  \n",
    "    tf.keras.layers.Dense(32, activation='ReLU'),  \n",
    "    tf.keras.layers.Dense(16, activation='ReLU'),  \n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=100, batch_size=5, verbose=1, \n",
    "          validation_data=(X_test, tf.keras.utils.to_categorical(y_test)), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 클래스 예측값으로 변환\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
