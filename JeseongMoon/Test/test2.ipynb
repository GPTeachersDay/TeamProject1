{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 10) (836, 10) (3341,) (836,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_dataset(csv_path, TRAIN_RATIO=0.8):\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 성별 원핫 인코딩\n",
    "    df=pd.get_dummies(df,columns=['Sex'])\n",
    "    \n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop('Rings', axis=1)\n",
    "    y = df['Rings']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "csv_path = 'D:\\project\\Teamproject1\\colabo\\Data\\Regression_data.csv'\n",
    "X_train, X_test, y_train, y_test = load_dataset(csv_path)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M  \n",
       "461          0.265      1      0      0  \n",
       "2835         0.250      0      0      1  \n",
       "1378         0.354      1      0      0  \n",
       "2569         0.111      0      1      0  \n",
       "369          0.470      1      0      0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전복 전체 무게가 살 + 내장 + 껍질보다 적게 나가는 경우는 말이 안됨\n",
    "body = X_train['Whole weight'] - (X_train['Shucked weight'] + X_train['Viscera weight'] + X_train['Shell weight'])\n",
    "X_train['body'] = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = X_train[X_train['body'] < 0].index\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = X_test['Whole weight'] - (X_test['Shucked weight'] + X_test['Viscera weight'] + X_test['Shell weight'])\n",
    "X_test['body'] = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2 = X_test[X_test['body'] < 0].index\n",
    "index2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제해줌\n",
    "X_train.drop(index, axis=0, inplace=True)\n",
    "X_test.drop(index2, axis=0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenth가 Diameter보다 크다.\n",
    "<br>--> Length는 장축의 길이, Diameter는 단축의 지름으로 판단됨\n",
    "<br>타원(전복 껍데기)의 둘레 및 넓이 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length가 Diameter보다 큰게 딱 1개 있음 --> 그럴 수도 있으니 삭제는 안함\n",
    "index3 = X_train[X_train['Diameter'] > X_train['Length']].index\n",
    "index3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index4 = X_test[X_test['Diameter'] > X_test['Length']].index\n",
    "index4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 넓이 ( a * b * π)\n",
    "area = 0.5 * X_train['Length'] * 0.5 * X_train['Diameter'] * np.pi\n",
    "X_train['Area'] = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 넓이 \n",
    "area2 = 0.5 * X_test['Length'] * 0.5 * X_test['Diameter'] * np.pi\n",
    "X_test['Area'] = area2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter = np.pi * np.sqrt(0.5 * ((X_train['Length'] ** 2) + (X_train['Diameter'] ** 2)))\n",
    "X_train['Perimeter'] = perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter2 = np.pi * np.sqrt(0.5 * ((X_test['Length'] ** 2) + (X_test['Diameter'] ** 2)))\n",
    "X_test['Perimeter'] = perimeter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>1.660072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>1.572837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.769361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>1.277329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.974085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M    body      Area  Perimeter  \n",
       "461          0.265      1      0      0  0.1160  0.213648   1.660072  \n",
       "2835         0.250      0      0      1  0.0435  0.188024   1.572837  \n",
       "1378         0.354      1      0      0  0.0295  0.243473   1.769361  \n",
       "2569         0.111      0      1      0  0.0190  0.124643   1.277329  \n",
       "369          0.470      1      0      0  0.2700  0.303478   1.974085  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell weight      0.619796\n",
      "Diameter          0.559512\n",
      "Perimeter         0.548978\n",
      "Length            0.539317\n",
      "Height            0.534439\n",
      "body              0.533203\n",
      "Area              0.532949\n",
      "Whole weight      0.525487\n",
      "Viscera weight    0.489945\n",
      "Shucked weight    0.403014\n",
      "Sex_F             0.242466\n",
      "Sex_M             0.178722\n",
      "Sex_I            -0.431255\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟값과 각 변수들 간의 상관관계\n",
    "co = X_train.corrwith(y_train)\n",
    "\n",
    "# 상관계수를 내림차순으로 정리\n",
    "print(co.sort_values(ascending=False))\n",
    "\n",
    "# 절대값\n",
    "co_abs = abs(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Whole weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.572837</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.8745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.769361</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1.277329</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.974085</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.7190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height    body      Area  \\\n",
       "461          0.265     0.465   1.660072   0.585   0.170  0.1160  0.213648   \n",
       "2835         0.250     0.420   1.572837   0.570   0.140  0.0435  0.188024   \n",
       "1378         0.354     0.500   1.769361   0.620   0.150  0.0295  0.243473   \n",
       "2569         0.111     0.345   1.277329   0.460   0.115  0.0190  0.124643   \n",
       "369          0.470     0.560   1.974085   0.690   0.215  0.2700  0.303478   \n",
       "\n",
       "      Whole weight  \n",
       "461         0.9915  \n",
       "2835        0.8745  \n",
       "1378        1.2930  \n",
       "2569        0.4215  \n",
       "369         1.7190  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = X_train[['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'body', 'Area', 'Whole weight']]\n",
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Whole weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.126273</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>0.240</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.578631</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.194386</td>\n",
       "      <td>0.7530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.284024</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.126449</td>\n",
       "      <td>0.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.9080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.550</td>\n",
       "      <td>1.951489</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.295899</td>\n",
       "      <td>1.7725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height    body      Area  \\\n",
       "2197         0.125     0.305   1.126273   0.405   0.105  0.0105  0.097016   \n",
       "3662         0.240     0.450   1.578631   0.550   0.140  0.0360  0.194386   \n",
       "1266         0.114     0.350   1.284024   0.460   0.105  0.0220  0.126449   \n",
       "485          0.315     0.465   1.660072   0.585   0.140  0.0505  0.213648   \n",
       "2083         0.490     0.550   1.951489   0.685   0.200  0.0825  0.295899   \n",
       "\n",
       "      Whole weight  \n",
       "2197        0.3625  \n",
       "3662        0.7530  \n",
       "1266        0.3705  \n",
       "485         0.9080  \n",
       "2083        1.7725  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2 = X_test[['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'body', 'Area', 'Whole weight']]\n",
    "X_test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 피처 스케일링\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_2)\n",
    "X_test_scaled  = scaler.fit_transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 사용자 정의 평가 지표 클래스\n",
    "class EvalAccuracy(tf.keras.metrics.Metric): # TensorFlow의 Metric 클래스를 상속 받음\n",
    "\n",
    "    def __init__(self, name=\"eval_accuracy\", **kwargs): # 부모 클래스의 __init__() 메소드를 호출하여 필요한 초기화를 수행\n",
    "        super(EvalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.correct = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "        # add_weight() 메소드를 사용하여 평가 지표를 계산하는데 필요한 변수를 생성(각 배치에서의 평가 결과를 누적하기 위해)\n",
    "        # add_weight() 는 텐서플로우 Layer 클래스의 메서드(새로운 가중치를 추가하는 기능, 여기서는 평가 지표를 계산하는 데 사용되는 일종의 내부 변수를 의미)\n",
    "        # 이 구문이 실행되면, EvalAccuracy 인스턴스는 새로운 가중치를 추가하고 그 가중치를 self.correct에 저장한다.\n",
    "        # 이 self.correct는 update_state() 메서드에서 업데이트되며, '현재까지 처리한 모든 배치에 대한 평가 지표의 평균을 저장'한다.\n",
    "\n",
    "    def update_state(self, y_true, y_predict, sample_weight=None):\n",
    "        value = tf.abs((y_predict - y_true) / y_true)\n",
    "        self.correct.assign(tf.reduce_mean(value)) # 오차율을 계산해서 correct 변수에 누적한 후, assign() 메소드를 사용하여 correct 변수의 값을 업데이트\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - self.correct\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 에포크마다 평가 지표 초기화\n",
    "        self.correct.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:-37]\n",
    "y_test = y_test[:-37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 65.7715 - eval_accuracy: 0.8126 - val_loss: 12.5983 - val_eval_accuracy: 0.8267\n",
      "Epoch 2/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6476 - eval_accuracy: 0.5959 - val_loss: 14.2202 - val_eval_accuracy: 0.8297\n",
      "Epoch 3/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0351 - eval_accuracy: 0.8467 - val_loss: 10.7496 - val_eval_accuracy: 0.8099\n",
      "Epoch 4/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4686 - eval_accuracy: 0.7878 - val_loss: 10.4408 - val_eval_accuracy: 0.8139\n",
      "Epoch 5/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2058 - eval_accuracy: 0.8477 - val_loss: 10.3562 - val_eval_accuracy: 0.8323\n",
      "Epoch 6/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9987 - eval_accuracy: 0.6930 - val_loss: 10.3872 - val_eval_accuracy: 0.8357\n",
      "Epoch 7/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9574 - eval_accuracy: 0.5888 - val_loss: 11.0540 - val_eval_accuracy: 0.8431\n",
      "Epoch 8/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8771 - eval_accuracy: 0.7455 - val_loss: 10.0989 - val_eval_accuracy: 0.8319\n",
      "Epoch 9/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8718 - eval_accuracy: 0.8781 - val_loss: 10.0756 - val_eval_accuracy: 0.8179\n",
      "Epoch 10/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8368 - eval_accuracy: 0.8161 - val_loss: 10.3094 - val_eval_accuracy: 0.8394\n",
      "Epoch 11/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8658 - eval_accuracy: 0.7448 - val_loss: 11.4512 - val_eval_accuracy: 0.8467\n",
      "Epoch 12/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8738 - eval_accuracy: 0.7962 - val_loss: 10.0971 - val_eval_accuracy: 0.8132\n",
      "Epoch 13/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8241 - eval_accuracy: 0.6813 - val_loss: 10.9322 - val_eval_accuracy: 0.7654\n",
      "Epoch 14/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8684 - eval_accuracy: 0.8240 - val_loss: 10.0678 - val_eval_accuracy: 0.8208\n",
      "Epoch 15/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8615 - eval_accuracy: 0.6647 - val_loss: 10.9589 - val_eval_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8126 - eval_accuracy: 0.7348 - val_loss: 10.6371 - val_eval_accuracy: 0.8429\n",
      "Epoch 17/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8626 - eval_accuracy: 0.5908 - val_loss: 14.2215 - val_eval_accuracy: 0.6742\n",
      "Epoch 18/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9389 - eval_accuracy: 0.6693 - val_loss: 10.1740 - val_eval_accuracy: 0.8374\n",
      "Epoch 19/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8458 - eval_accuracy: 0.7212 - val_loss: 10.1513 - val_eval_accuracy: 0.8056\n",
      "Epoch 20/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8718 - eval_accuracy: 0.7606 - val_loss: 10.2581 - val_eval_accuracy: 0.7971\n",
      "Epoch 21/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8486 - eval_accuracy: 0.7423 - val_loss: 10.0624 - val_eval_accuracy: 0.8204\n",
      "Epoch 22/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8441 - eval_accuracy: 0.8368 - val_loss: 10.5031 - val_eval_accuracy: 0.7840\n",
      "Epoch 23/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8838 - eval_accuracy: 0.7245 - val_loss: 10.8517 - val_eval_accuracy: 0.8436\n",
      "Epoch 24/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8977 - eval_accuracy: 0.8177 - val_loss: 10.7931 - val_eval_accuracy: 0.7715\n",
      "Epoch 25/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8393 - eval_accuracy: 0.8073 - val_loss: 10.1039 - val_eval_accuracy: 0.8348\n",
      "Epoch 26/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8574 - eval_accuracy: 0.7601 - val_loss: 11.0566 - val_eval_accuracy: 0.8444\n",
      "Epoch 27/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8415 - eval_accuracy: 0.6268 - val_loss: 10.0749 - val_eval_accuracy: 0.8308\n",
      "Epoch 28/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8044 - eval_accuracy: 0.8038 - val_loss: 10.4606 - val_eval_accuracy: 0.8400\n",
      "Epoch 29/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8058 - eval_accuracy: 0.8308 - val_loss: 10.2498 - val_eval_accuracy: 0.8376\n",
      "Epoch 30/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8444 - eval_accuracy: 0.7319 - val_loss: 10.0707 - val_eval_accuracy: 0.8158\n",
      "Epoch 31/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7979 - eval_accuracy: 0.8618 - val_loss: 10.7799 - val_eval_accuracy: 0.8423\n",
      "Epoch 32/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8425 - eval_accuracy: 0.7541 - val_loss: 10.1154 - val_eval_accuracy: 0.8352\n",
      "Epoch 33/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8226 - eval_accuracy: 0.9303 - val_loss: 10.2296 - val_eval_accuracy: 0.8373\n",
      "Epoch 34/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7998 - eval_accuracy: 0.6589 - val_loss: 10.6528 - val_eval_accuracy: 0.8415\n",
      "Epoch 35/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8980 - eval_accuracy: 0.5505 - val_loss: 10.8321 - val_eval_accuracy: 0.8426\n",
      "Epoch 36/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8500 - eval_accuracy: 0.8141 - val_loss: 10.2162 - val_eval_accuracy: 0.8371\n",
      "Epoch 37/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8108 - eval_accuracy: 0.8137 - val_loss: 10.9445 - val_eval_accuracy: 0.7638\n",
      "Epoch 38/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8030 - eval_accuracy: 0.8453 - val_loss: 10.6741 - val_eval_accuracy: 0.8414\n",
      "Epoch 39/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7885 - eval_accuracy: 0.6809 - val_loss: 11.7451 - val_eval_accuracy: 0.7348\n",
      "Epoch 40/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8320 - eval_accuracy: 0.6310 - val_loss: 12.6938 - val_eval_accuracy: 0.8310\n",
      "Epoch 41/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9273 - eval_accuracy: 0.7828 - val_loss: 10.1434 - val_eval_accuracy: 0.8047\n",
      "Epoch 42/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8599 - eval_accuracy: 0.6637 - val_loss: 10.5189 - val_eval_accuracy: 0.7822\n",
      "Epoch 43/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8377 - eval_accuracy: 0.6739 - val_loss: 10.3798 - val_eval_accuracy: 0.8382\n",
      "Epoch 44/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8046 - eval_accuracy: 0.8656 - val_loss: 11.1375 - val_eval_accuracy: 0.8438\n",
      "Epoch 45/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8016 - eval_accuracy: 0.6588 - val_loss: 10.1378 - val_eval_accuracy: 0.8352\n",
      "Epoch 46/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7929 - eval_accuracy: 0.7855 - val_loss: 10.6660 - val_eval_accuracy: 0.8408\n",
      "Epoch 47/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8098 - eval_accuracy: 0.8571 - val_loss: 10.4475 - val_eval_accuracy: 0.7854\n",
      "Epoch 48/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8460 - eval_accuracy: 0.6879 - val_loss: 11.2884 - val_eval_accuracy: 0.8444\n",
      "Epoch 49/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8687 - eval_accuracy: 0.7633 - val_loss: 10.0541 - val_eval_accuracy: 0.8198\n",
      "Epoch 50/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7881 - eval_accuracy: 0.6313 - val_loss: 11.1781 - val_eval_accuracy: 0.8439\n",
      "Epoch 51/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8626 - eval_accuracy: 0.8368 - val_loss: 10.1136 - val_eval_accuracy: 0.8343\n",
      "Epoch 52/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8214 - eval_accuracy: 0.4805 - val_loss: 10.1063 - val_eval_accuracy: 0.8337\n",
      "Epoch 53/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8202 - eval_accuracy: 0.7456 - val_loss: 10.4030 - val_eval_accuracy: 0.7872\n",
      "Epoch 54/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7927 - eval_accuracy: 0.8277 - val_loss: 10.0968 - val_eval_accuracy: 0.8094\n",
      "Epoch 55/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8257 - eval_accuracy: 0.7966 - val_loss: 10.4062 - val_eval_accuracy: 0.8380\n",
      "Epoch 56/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8216 - eval_accuracy: 0.7896 - val_loss: 10.2158 - val_eval_accuracy: 0.8358\n",
      "Epoch 57/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8331 - eval_accuracy: 0.8196 - val_loss: 10.0517 - val_eval_accuracy: 0.8219\n",
      "Epoch 58/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8239 - eval_accuracy: 0.7771 - val_loss: 10.3929 - val_eval_accuracy: 0.8377\n",
      "Epoch 59/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8053 - eval_accuracy: 0.8260 - val_loss: 10.1903 - val_eval_accuracy: 0.8001\n",
      "Epoch 60/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8236 - eval_accuracy: 0.7921 - val_loss: 10.6955 - val_eval_accuracy: 0.8405\n",
      "Epoch 61/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8452 - eval_accuracy: 0.8111 - val_loss: 10.5949 - val_eval_accuracy: 0.8395\n",
      "Epoch 62/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8131 - eval_accuracy: 0.7692 - val_loss: 10.7320 - val_eval_accuracy: 0.8405\n",
      "Epoch 63/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8350 - eval_accuracy: 0.7749 - val_loss: 10.0787 - val_eval_accuracy: 0.8313\n",
      "Epoch 64/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8033 - eval_accuracy: 0.6873 - val_loss: 10.2578 - val_eval_accuracy: 0.8365\n",
      "Epoch 65/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8401 - eval_accuracy: 0.6530 - val_loss: 10.8561 - val_eval_accuracy: 0.8414\n",
      "Epoch 66/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8202 - eval_accuracy: 0.6045 - val_loss: 10.3571 - val_eval_accuracy: 0.8374\n",
      "Epoch 67/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8540 - eval_accuracy: 0.7430 - val_loss: 12.2166 - val_eval_accuracy: 0.7205\n",
      "Epoch 68/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8402 - eval_accuracy: 0.7874 - val_loss: 10.2255 - val_eval_accuracy: 0.8355\n",
      "Epoch 69/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8073 - eval_accuracy: 0.8969 - val_loss: 10.1515 - val_eval_accuracy: 0.8343\n",
      "Epoch 70/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8232 - eval_accuracy: 0.7718 - val_loss: 10.1768 - val_eval_accuracy: 0.8007\n",
      "Epoch 71/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8130 - eval_accuracy: 0.6272 - val_loss: 10.8306 - val_eval_accuracy: 0.8407\n",
      "Epoch 72/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7987 - eval_accuracy: 0.6002 - val_loss: 10.2656 - val_eval_accuracy: 0.7945\n",
      "Epoch 73/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8192 - eval_accuracy: 0.6962 - val_loss: 10.4174 - val_eval_accuracy: 0.7861\n",
      "Epoch 74/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8657 - eval_accuracy: 0.7187 - val_loss: 10.4455 - val_eval_accuracy: 0.8381\n",
      "Epoch 75/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8577 - eval_accuracy: 0.6934 - val_loss: 10.1520 - val_eval_accuracy: 0.8343\n",
      "Epoch 76/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8389 - eval_accuracy: 0.5886 - val_loss: 10.7787 - val_eval_accuracy: 0.8406\n",
      "Epoch 77/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8208 - eval_accuracy: 0.8950 - val_loss: 10.0501 - val_eval_accuracy: 0.8214\n",
      "Epoch 78/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7761 - eval_accuracy: 0.5390 - val_loss: 11.6908 - val_eval_accuracy: 0.8390\n",
      "Epoch 79/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8394 - eval_accuracy: 0.7853 - val_loss: 10.3298 - val_eval_accuracy: 0.8364\n",
      "Epoch 80/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8525 - eval_accuracy: 0.7909 - val_loss: 10.5244 - val_eval_accuracy: 0.8382\n",
      "Epoch 81/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8435 - eval_accuracy: 0.7873 - val_loss: 10.5049 - val_eval_accuracy: 0.8381\n",
      "Epoch 82/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8132 - eval_accuracy: 0.4650 - val_loss: 10.6054 - val_eval_accuracy: 0.8387\n",
      "Epoch 83/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8203 - eval_accuracy: 0.7564 - val_loss: 10.0463 - val_eval_accuracy: 0.8205\n",
      "Epoch 84/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8345 - eval_accuracy: 0.7439 - val_loss: 10.0479 - val_eval_accuracy: 0.8193\n",
      "Epoch 85/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8211 - eval_accuracy: 0.6288 - val_loss: 10.1744 - val_eval_accuracy: 0.8341\n",
      "Epoch 86/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7887 - eval_accuracy: 0.7764 - val_loss: 10.1026 - val_eval_accuracy: 0.8327\n",
      "Epoch 87/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7856 - eval_accuracy: 0.5945 - val_loss: 10.2100 - val_eval_accuracy: 0.7976\n",
      "Epoch 88/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8059 - eval_accuracy: 0.5129 - val_loss: 11.5844 - val_eval_accuracy: 0.8398\n",
      "Epoch 89/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8586 - eval_accuracy: 0.8424 - val_loss: 10.1005 - val_eval_accuracy: 0.8078\n",
      "Epoch 90/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8313 - eval_accuracy: 0.8011 - val_loss: 10.6772 - val_eval_accuracy: 0.8392\n",
      "Epoch 91/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8145 - eval_accuracy: 0.7439 - val_loss: 10.0757 - val_eval_accuracy: 0.8115\n",
      "Epoch 92/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8105 - eval_accuracy: 0.5805 - val_loss: 10.5668 - val_eval_accuracy: 0.8382\n",
      "Epoch 93/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8457 - eval_accuracy: 0.5918 - val_loss: 11.0366 - val_eval_accuracy: 0.8413\n",
      "Epoch 94/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8093 - eval_accuracy: 0.7516 - val_loss: 10.2496 - val_eval_accuracy: 0.7946\n",
      "Epoch 95/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8309 - eval_accuracy: 0.7954 - val_loss: 10.0606 - val_eval_accuracy: 0.8282\n",
      "Epoch 96/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8143 - eval_accuracy: 0.7186 - val_loss: 10.0475 - val_eval_accuracy: 0.8185\n",
      "Epoch 97/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7918 - eval_accuracy: 0.9397 - val_loss: 10.0673 - val_eval_accuracy: 0.8124\n",
      "Epoch 98/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8123 - eval_accuracy: 0.7456 - val_loss: 10.0849 - val_eval_accuracy: 0.8318\n",
      "Epoch 99/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8187 - eval_accuracy: 0.8314 - val_loss: 10.3395 - val_eval_accuracy: 0.7892\n",
      "Epoch 100/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8674 - eval_accuracy: 0.7142 - val_loss: 10.0549 - val_eval_accuracy: 0.8266\n",
      "Epoch 101/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7903 - eval_accuracy: 0.5704 - val_loss: 10.0747 - val_eval_accuracy: 0.8306\n",
      "Epoch 102/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7962 - eval_accuracy: 0.7762 - val_loss: 11.0916 - val_eval_accuracy: 0.7559\n",
      "Epoch 103/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8370 - eval_accuracy: 0.8564 - val_loss: 10.0502 - val_eval_accuracy: 0.8257\n",
      "Epoch 104/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7871 - eval_accuracy: 0.8315 - val_loss: 10.0488 - val_eval_accuracy: 0.8169\n",
      "Epoch 105/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8070 - eval_accuracy: 0.6477 - val_loss: 10.0449 - val_eval_accuracy: 0.8209\n",
      "Epoch 106/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7979 - eval_accuracy: 0.6987 - val_loss: 10.0476 - val_eval_accuracy: 0.8241\n",
      "Epoch 107/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7923 - eval_accuracy: 0.7232 - val_loss: 10.4045 - val_eval_accuracy: 0.7856\n",
      "Epoch 108/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8375 - eval_accuracy: 0.7291 - val_loss: 10.1504 - val_eval_accuracy: 0.8332\n",
      "Epoch 109/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7761 - eval_accuracy: 0.8305 - val_loss: 10.1070 - val_eval_accuracy: 0.8063\n",
      "Epoch 110/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8197 - eval_accuracy: 0.7142 - val_loss: 10.0482 - val_eval_accuracy: 0.8235\n",
      "Epoch 111/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7940 - eval_accuracy: 0.7661 - val_loss: 10.2082 - val_eval_accuracy: 0.7972\n",
      "Epoch 112/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8246 - eval_accuracy: 0.7940 - val_loss: 11.0363 - val_eval_accuracy: 0.8411\n",
      "Epoch 113/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8427 - eval_accuracy: 0.7245 - val_loss: 10.8275 - val_eval_accuracy: 0.8397\n",
      "Epoch 114/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8583 - eval_accuracy: 0.6315 - val_loss: 10.9866 - val_eval_accuracy: 0.8409\n",
      "Epoch 115/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7867 - eval_accuracy: 0.6571 - val_loss: 10.1048 - val_eval_accuracy: 0.8075\n",
      "Epoch 116/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8302 - eval_accuracy: 0.7024 - val_loss: 10.8103 - val_eval_accuracy: 0.8397\n",
      "Epoch 117/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.8239 - eval_accuracy: 0.7291 - val_loss: 10.8517 - val_eval_accuracy: 0.8399\n",
      "Epoch 118/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8586 - eval_accuracy: 0.7642 - val_loss: 10.5474 - val_eval_accuracy: 0.8377\n",
      "Epoch 119/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7830 - eval_accuracy: 0.7821 - val_loss: 10.0674 - val_eval_accuracy: 0.8291\n",
      "Epoch 120/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7509 - eval_accuracy: 0.8326 - val_loss: 10.1555 - val_eval_accuracy: 0.8332\n",
      "Epoch 121/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7428 - eval_accuracy: 0.8023 - val_loss: 10.0525 - val_eval_accuracy: 0.8167\n",
      "Epoch 122/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7663 - eval_accuracy: 0.8314 - val_loss: 10.0587 - val_eval_accuracy: 0.8270\n",
      "Epoch 123/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7466 - eval_accuracy: 0.5688 - val_loss: 10.0487 - val_eval_accuracy: 0.8219\n",
      "Epoch 124/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7587 - eval_accuracy: 0.6373 - val_loss: 10.1282 - val_eval_accuracy: 0.8327\n",
      "Epoch 125/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7510 - eval_accuracy: 0.8084 - val_loss: 10.0712 - val_eval_accuracy: 0.8296\n",
      "Epoch 126/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7582 - eval_accuracy: 0.6647 - val_loss: 10.1304 - val_eval_accuracy: 0.8327\n",
      "Epoch 127/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7490 - eval_accuracy: 0.6814 - val_loss: 10.1382 - val_eval_accuracy: 0.8328\n",
      "Epoch 128/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7519 - eval_accuracy: 0.6952 - val_loss: 10.1105 - val_eval_accuracy: 0.8322\n",
      "Epoch 129/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7454 - eval_accuracy: 0.7739 - val_loss: 10.1046 - val_eval_accuracy: 0.8321\n",
      "Epoch 130/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7446 - eval_accuracy: 0.6161 - val_loss: 10.0832 - val_eval_accuracy: 0.8312\n",
      "Epoch 131/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7488 - eval_accuracy: 0.6797 - val_loss: 10.0932 - val_eval_accuracy: 0.8317\n",
      "Epoch 132/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7399 - eval_accuracy: 0.7695 - val_loss: 10.1910 - val_eval_accuracy: 0.8337\n",
      "Epoch 133/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7559 - eval_accuracy: 0.7362 - val_loss: 10.1666 - val_eval_accuracy: 0.8333\n",
      "Epoch 134/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7476 - eval_accuracy: 0.7223 - val_loss: 10.0675 - val_eval_accuracy: 0.8290\n",
      "Epoch 135/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7486 - eval_accuracy: 0.8053 - val_loss: 10.0701 - val_eval_accuracy: 0.8293\n",
      "Epoch 136/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7500 - eval_accuracy: 0.9240 - val_loss: 10.0915 - val_eval_accuracy: 0.8316\n",
      "Epoch 137/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7577 - eval_accuracy: 0.7223 - val_loss: 10.0561 - val_eval_accuracy: 0.8261\n",
      "Epoch 138/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7529 - eval_accuracy: 0.5950 - val_loss: 10.1422 - val_eval_accuracy: 0.8328\n",
      "Epoch 139/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7473 - eval_accuracy: 0.8128 - val_loss: 10.0468 - val_eval_accuracy: 0.8214\n",
      "Epoch 140/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7607 - eval_accuracy: 0.7983 - val_loss: 10.1453 - val_eval_accuracy: 0.8329\n",
      "Epoch 141/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7508 - eval_accuracy: 0.6710 - val_loss: 10.0539 - val_eval_accuracy: 0.8162\n",
      "Epoch 142/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7590 - eval_accuracy: 0.7245 - val_loss: 10.1319 - val_eval_accuracy: 0.8326\n",
      "Epoch 143/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7524 - eval_accuracy: 0.5285 - val_loss: 10.1069 - val_eval_accuracy: 0.8321\n",
      "Epoch 144/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7540 - eval_accuracy: 0.8860 - val_loss: 10.1105 - val_eval_accuracy: 0.8321\n",
      "Epoch 145/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7511 - eval_accuracy: 0.5668 - val_loss: 10.1312 - val_eval_accuracy: 0.8326\n",
      "Epoch 146/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7503 - eval_accuracy: 0.7224 - val_loss: 10.0491 - val_eval_accuracy: 0.8188\n",
      "Epoch 147/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7625 - eval_accuracy: 0.8343 - val_loss: 10.0519 - val_eval_accuracy: 0.8241\n",
      "Epoch 148/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7555 - eval_accuracy: 0.9401 - val_loss: 10.0711 - val_eval_accuracy: 0.8294\n",
      "Epoch 149/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7553 - eval_accuracy: 0.7779 - val_loss: 10.1436 - val_eval_accuracy: 0.8328\n",
      "Epoch 150/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7509 - eval_accuracy: 0.6861 - val_loss: 10.0738 - val_eval_accuracy: 0.8297\n",
      "Epoch 151/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7504 - eval_accuracy: 0.7695 - val_loss: 10.0893 - val_eval_accuracy: 0.8314\n",
      "Epoch 152/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7469 - eval_accuracy: 0.6593 - val_loss: 10.1633 - val_eval_accuracy: 0.8332\n",
      "Epoch 153/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7595 - eval_accuracy: 0.7809 - val_loss: 10.1445 - val_eval_accuracy: 0.8328\n",
      "Epoch 154/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7500 - eval_accuracy: 0.7762 - val_loss: 10.0804 - val_eval_accuracy: 0.8306\n",
      "Epoch 155/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7436 - eval_accuracy: 0.7767 - val_loss: 10.1454 - val_eval_accuracy: 0.8328\n",
      "Epoch 156/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7527 - eval_accuracy: 0.8145 - val_loss: 10.1516 - val_eval_accuracy: 0.8329\n",
      "Epoch 157/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7540 - eval_accuracy: 0.4348 - val_loss: 10.2129 - val_eval_accuracy: 0.8339\n",
      "Epoch 158/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7520 - eval_accuracy: 0.7569 - val_loss: 10.0561 - val_eval_accuracy: 0.8255\n",
      "Epoch 159/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7406 - eval_accuracy: 0.7081 - val_loss: 10.1240 - val_eval_accuracy: 0.8045\n",
      "Epoch 160/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7838 - eval_accuracy: 0.7391 - val_loss: 10.1360 - val_eval_accuracy: 0.8326\n",
      "Epoch 161/1000\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7461 - eval_accuracy: 0.7247 - val_loss: 10.1252 - val_eval_accuracy: 0.8323\n",
      "Epoch 162/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7494 - eval_accuracy: 0.8490 - val_loss: 10.0811 - val_eval_accuracy: 0.8305\n",
      "Epoch 163/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7479 - eval_accuracy: 0.7879 - val_loss: 10.0667 - val_eval_accuracy: 0.8280\n",
      "Epoch 164/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7515 - eval_accuracy: 0.6474 - val_loss: 10.0948 - val_eval_accuracy: 0.8316\n",
      "Epoch 165/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7509 - eval_accuracy: 0.8187 - val_loss: 10.0625 - val_eval_accuracy: 0.8272\n",
      "Epoch 166/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7492 - eval_accuracy: 0.7120 - val_loss: 10.1254 - val_eval_accuracy: 0.8323\n",
      "Epoch 167/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7492 - eval_accuracy: 0.7555 - val_loss: 10.1458 - val_eval_accuracy: 0.8328\n",
      "Epoch 168/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7570 - eval_accuracy: 0.7477 - val_loss: 10.1403 - val_eval_accuracy: 0.8326\n",
      "Epoch 169/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7460 - eval_accuracy: 0.9168 - val_loss: 10.0591 - val_eval_accuracy: 0.8264\n",
      "Epoch 170/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7596 - eval_accuracy: 0.8024 - val_loss: 10.0850 - val_eval_accuracy: 0.8309\n",
      "Epoch 171/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7509 - eval_accuracy: 0.7032 - val_loss: 10.0499 - val_eval_accuracy: 0.8209\n",
      "Epoch 172/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7576 - eval_accuracy: 0.7508 - val_loss: 10.1156 - val_eval_accuracy: 0.8321\n",
      "Epoch 173/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7411 - eval_accuracy: 0.7715 - val_loss: 10.1267 - val_eval_accuracy: 0.8323\n",
      "Epoch 174/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7417 - eval_accuracy: 0.8911 - val_loss: 10.1167 - val_eval_accuracy: 0.8321\n",
      "Epoch 175/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7397 - eval_accuracy: 0.6113 - val_loss: 10.1053 - val_eval_accuracy: 0.8318\n",
      "Epoch 176/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7403 - eval_accuracy: 0.7071 - val_loss: 10.1077 - val_eval_accuracy: 0.8319\n",
      "Epoch 177/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7406 - eval_accuracy: 0.2261 - val_loss: 10.1214 - val_eval_accuracy: 0.8322\n",
      "Epoch 178/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7401 - eval_accuracy: 0.6873 - val_loss: 10.1234 - val_eval_accuracy: 0.8323\n",
      "Epoch 179/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7410 - eval_accuracy: 0.8674 - val_loss: 10.0974 - val_eval_accuracy: 0.8316\n",
      "Epoch 180/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7397 - eval_accuracy: 0.5802 - val_loss: 10.0977 - val_eval_accuracy: 0.8316\n",
      "Epoch 181/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7399 - eval_accuracy: 0.8443 - val_loss: 10.0967 - val_eval_accuracy: 0.8316\n",
      "Epoch 182/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7397 - eval_accuracy: 0.8872 - val_loss: 10.0895 - val_eval_accuracy: 0.8312\n",
      "Epoch 183/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7402 - eval_accuracy: 0.5834 - val_loss: 10.0972 - val_eval_accuracy: 0.8316\n",
      "Epoch 184/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7396 - eval_accuracy: 0.6699 - val_loss: 10.1020 - val_eval_accuracy: 0.8317\n",
      "Epoch 185/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7393 - eval_accuracy: 0.7479 - val_loss: 10.0884 - val_eval_accuracy: 0.8312\n",
      "Epoch 186/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7408 - eval_accuracy: 0.7708 - val_loss: 10.0887 - val_eval_accuracy: 0.8312\n",
      "Epoch 187/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7410 - eval_accuracy: 0.8553 - val_loss: 10.0928 - val_eval_accuracy: 0.8314\n",
      "Epoch 188/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.4796 - val_loss: 10.0894 - val_eval_accuracy: 0.8312\n",
      "Epoch 189/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7397 - eval_accuracy: 0.8593 - val_loss: 10.0921 - val_eval_accuracy: 0.8313\n",
      "Epoch 190/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7390 - eval_accuracy: 0.6958 - val_loss: 10.0835 - val_eval_accuracy: 0.8307\n",
      "Epoch 191/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7400 - eval_accuracy: 0.6398 - val_loss: 10.0926 - val_eval_accuracy: 0.8314\n",
      "Epoch 192/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7404 - eval_accuracy: 0.8513 - val_loss: 10.0957 - val_eval_accuracy: 0.8315\n",
      "Epoch 193/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7402 - eval_accuracy: 0.8509 - val_loss: 10.0993 - val_eval_accuracy: 0.8317\n",
      "Epoch 194/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7404 - eval_accuracy: 0.8516 - val_loss: 10.1063 - val_eval_accuracy: 0.8318\n",
      "Epoch 195/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.7273 - val_loss: 10.0933 - val_eval_accuracy: 0.8314\n",
      "Epoch 196/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7408 - eval_accuracy: 0.7835 - val_loss: 10.1013 - val_eval_accuracy: 0.8317\n",
      "Epoch 197/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7397 - eval_accuracy: 0.7162 - val_loss: 10.0988 - val_eval_accuracy: 0.8316\n",
      "Epoch 198/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7389 - eval_accuracy: 0.8322 - val_loss: 10.1003 - val_eval_accuracy: 0.8317\n",
      "Epoch 199/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7396 - eval_accuracy: 0.6698 - val_loss: 10.0734 - val_eval_accuracy: 0.8293\n",
      "Epoch 200/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7416 - eval_accuracy: 0.5351 - val_loss: 10.0889 - val_eval_accuracy: 0.8312\n",
      "Epoch 201/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7384 - eval_accuracy: 0.7985 - val_loss: 10.1067 - val_eval_accuracy: 0.8318\n",
      "Epoch 202/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7392 - eval_accuracy: 0.7540 - val_loss: 10.0869 - val_eval_accuracy: 0.8310\n",
      "Epoch 203/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.6026 - val_loss: 10.1034 - val_eval_accuracy: 0.8318\n",
      "Epoch 204/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7408 - eval_accuracy: 0.5837 - val_loss: 10.1155 - val_eval_accuracy: 0.8320\n",
      "Epoch 205/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7409 - eval_accuracy: 0.5053 - val_loss: 10.1131 - val_eval_accuracy: 0.8320\n",
      "Epoch 206/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7393 - eval_accuracy: 0.8542 - val_loss: 10.1125 - val_eval_accuracy: 0.8320\n",
      "Epoch 207/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7399 - eval_accuracy: 0.8030 - val_loss: 10.0913 - val_eval_accuracy: 0.8313\n",
      "Epoch 208/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7407 - eval_accuracy: 0.7439 - val_loss: 10.0744 - val_eval_accuracy: 0.8296\n",
      "Epoch 209/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7432 - eval_accuracy: 0.7960 - val_loss: 10.0769 - val_eval_accuracy: 0.8299\n",
      "Epoch 210/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7417 - eval_accuracy: 0.7039 - val_loss: 10.0801 - val_eval_accuracy: 0.8304\n",
      "Epoch 211/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7399 - eval_accuracy: 0.8166 - val_loss: 10.0897 - val_eval_accuracy: 0.8312\n",
      "Epoch 212/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7409 - eval_accuracy: 0.7727 - val_loss: 10.0843 - val_eval_accuracy: 0.8308\n",
      "Epoch 213/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7402 - eval_accuracy: 0.8036 - val_loss: 10.0916 - val_eval_accuracy: 0.8313\n",
      "Epoch 214/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7399 - eval_accuracy: 0.8019 - val_loss: 10.0992 - val_eval_accuracy: 0.8316\n",
      "Epoch 215/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7400 - eval_accuracy: 0.6774 - val_loss: 10.1042 - val_eval_accuracy: 0.8318\n",
      "Epoch 216/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.8453 - val_loss: 10.1013 - val_eval_accuracy: 0.8317\n",
      "Epoch 217/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7400 - eval_accuracy: 0.7511 - val_loss: 10.0954 - val_eval_accuracy: 0.8315\n",
      "Epoch 218/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7403 - eval_accuracy: 0.7395 - val_loss: 10.1090 - val_eval_accuracy: 0.8319\n",
      "Epoch 219/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7400 - eval_accuracy: 0.8291 - val_loss: 10.1117 - val_eval_accuracy: 0.8319\n",
      "Epoch 220/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7403 - eval_accuracy: 0.7487 - val_loss: 10.1113 - val_eval_accuracy: 0.8319\n",
      "Epoch 221/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7394 - eval_accuracy: 0.7156 - val_loss: 10.0952 - val_eval_accuracy: 0.8315\n",
      "Epoch 222/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7396 - eval_accuracy: 0.8113 - val_loss: 10.0871 - val_eval_accuracy: 0.8310\n",
      "Epoch 223/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7404 - eval_accuracy: 0.7395 - val_loss: 10.0744 - val_eval_accuracy: 0.8295\n",
      "Epoch 224/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7414 - eval_accuracy: 0.9033 - val_loss: 10.0879 - val_eval_accuracy: 0.8311\n",
      "Epoch 225/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7401 - eval_accuracy: 0.7871 - val_loss: 10.0954 - val_eval_accuracy: 0.8315\n",
      "Epoch 226/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7399 - eval_accuracy: 0.8162 - val_loss: 10.0943 - val_eval_accuracy: 0.8314\n",
      "Epoch 227/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.7693 - val_loss: 10.0942 - val_eval_accuracy: 0.8314\n",
      "Epoch 228/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7396 - eval_accuracy: 0.8272 - val_loss: 10.0904 - val_eval_accuracy: 0.8312\n",
      "Epoch 229/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7404 - eval_accuracy: 0.8053 - val_loss: 10.0903 - val_eval_accuracy: 0.8312\n",
      "Epoch 230/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7403 - eval_accuracy: 0.8325 - val_loss: 10.0899 - val_eval_accuracy: 0.8312\n",
      "Epoch 231/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7407 - eval_accuracy: 0.7471 - val_loss: 10.0906 - val_eval_accuracy: 0.8312\n",
      "Epoch 232/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7401 - eval_accuracy: 0.7786 - val_loss: 10.0937 - val_eval_accuracy: 0.8314\n",
      "Epoch 233/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7398 - eval_accuracy: 0.7193 - val_loss: 10.1072 - val_eval_accuracy: 0.8318\n",
      "Epoch 234/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7392 - eval_accuracy: 0.7070 - val_loss: 10.1018 - val_eval_accuracy: 0.8317\n",
      "Epoch 235/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7392 - eval_accuracy: 0.8758 - val_loss: 10.1075 - val_eval_accuracy: 0.8318\n",
      "Epoch 236/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7395 - eval_accuracy: 0.5885 - val_loss: 10.0987 - val_eval_accuracy: 0.8316\n",
      "Epoch 237/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7394 - eval_accuracy: 0.7404 - val_loss: 10.1145 - val_eval_accuracy: 0.8320\n",
      "Epoch 238/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7404 - eval_accuracy: 0.8327 - val_loss: 10.1116 - val_eval_accuracy: 0.8319\n",
      "Epoch 239/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7394 - eval_accuracy: 0.8010 - val_loss: 10.1070 - val_eval_accuracy: 0.8318\n",
      "Epoch 240/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7392 - eval_accuracy: 0.8341 - val_loss: 10.0930 - val_eval_accuracy: 0.8314\n",
      "Epoch 241/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7394 - eval_accuracy: 0.7625 - val_loss: 10.0891 - val_eval_accuracy: 0.8311\n",
      "Epoch 242/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7377 - eval_accuracy: 0.5950 - val_loss: 10.0896 - val_eval_accuracy: 0.8312\n",
      "Epoch 243/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7376 - eval_accuracy: 0.7836 - val_loss: 10.0928 - val_eval_accuracy: 0.8313\n",
      "Epoch 244/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7373 - eval_accuracy: 0.3778 - val_loss: 10.0940 - val_eval_accuracy: 0.8314\n",
      "Epoch 245/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7373 - eval_accuracy: 0.7735 - val_loss: 10.0938 - val_eval_accuracy: 0.8314\n",
      "Epoch 246/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.6260 - val_loss: 10.0964 - val_eval_accuracy: 0.8315\n",
      "Epoch 247/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7373 - eval_accuracy: 0.6968 - val_loss: 10.0980 - val_eval_accuracy: 0.8316\n",
      "Epoch 248/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7370 - eval_accuracy: 0.8099 - val_loss: 10.0964 - val_eval_accuracy: 0.8315\n",
      "Epoch 249/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7373 - eval_accuracy: 0.5664 - val_loss: 10.0983 - val_eval_accuracy: 0.8316\n",
      "Epoch 250/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7373 - eval_accuracy: 0.5585 - val_loss: 10.1004 - val_eval_accuracy: 0.8316\n",
      "Epoch 251/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.7984 - val_loss: 10.0961 - val_eval_accuracy: 0.8315\n",
      "Epoch 252/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.8306 - val_loss: 10.0975 - val_eval_accuracy: 0.8315\n",
      "Epoch 253/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.5881 - val_loss: 10.0975 - val_eval_accuracy: 0.8315\n",
      "Epoch 254/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7368 - eval_accuracy: 0.6207 - val_loss: 10.0998 - val_eval_accuracy: 0.8316\n",
      "Epoch 255/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7370 - eval_accuracy: 0.6405 - val_loss: 10.0991 - val_eval_accuracy: 0.8316\n",
      "Epoch 256/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.7249 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 257/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7370 - eval_accuracy: 0.8159 - val_loss: 10.0972 - val_eval_accuracy: 0.8315\n",
      "Epoch 258/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7370 - eval_accuracy: 0.8164 - val_loss: 10.0962 - val_eval_accuracy: 0.8315\n",
      "Epoch 259/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.7594 - val_loss: 10.0959 - val_eval_accuracy: 0.8315\n",
      "Epoch 260/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.6949 - val_loss: 10.0963 - val_eval_accuracy: 0.8315\n",
      "Epoch 261/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.8681 - val_loss: 10.0956 - val_eval_accuracy: 0.8315\n",
      "Epoch 262/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7373 - eval_accuracy: 0.7075 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 263/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.8832 - val_loss: 10.0970 - val_eval_accuracy: 0.8315\n",
      "Epoch 264/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.8359 - val_loss: 10.0969 - val_eval_accuracy: 0.8315\n",
      "Epoch 265/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.6235 - val_loss: 10.0962 - val_eval_accuracy: 0.8315\n",
      "Epoch 266/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7369 - eval_accuracy: 0.7704 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 267/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7368 - eval_accuracy: 0.8556 - val_loss: 10.0965 - val_eval_accuracy: 0.8315\n",
      "Epoch 268/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7370 - eval_accuracy: 0.6513 - val_loss: 10.0960 - val_eval_accuracy: 0.8315\n",
      "Epoch 269/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7373 - eval_accuracy: 0.5688 - val_loss: 10.0988 - val_eval_accuracy: 0.8316\n",
      "Epoch 270/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.7650 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 271/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7369 - eval_accuracy: 0.5807 - val_loss: 10.0999 - val_eval_accuracy: 0.8316\n",
      "Epoch 272/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7370 - eval_accuracy: 0.6400 - val_loss: 10.1002 - val_eval_accuracy: 0.8316\n",
      "Epoch 273/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.6717 - val_loss: 10.1026 - val_eval_accuracy: 0.8317\n",
      "Epoch 274/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.5906 - val_loss: 10.1026 - val_eval_accuracy: 0.8317\n",
      "Epoch 275/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.6824 - val_loss: 10.1037 - val_eval_accuracy: 0.8317\n",
      "Epoch 276/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7369 - eval_accuracy: 0.7625 - val_loss: 10.1030 - val_eval_accuracy: 0.8317\n",
      "Epoch 277/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7369 - eval_accuracy: 0.6499 - val_loss: 10.1025 - val_eval_accuracy: 0.8317\n",
      "Epoch 278/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.7846 - val_loss: 10.1023 - val_eval_accuracy: 0.8317\n",
      "Epoch 279/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.8362 - val_loss: 10.1009 - val_eval_accuracy: 0.8316\n",
      "Epoch 280/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7369 - eval_accuracy: 0.7068 - val_loss: 10.0988 - val_eval_accuracy: 0.8316\n",
      "Epoch 281/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7370 - eval_accuracy: 0.5843 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 282/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.4400 - val_loss: 10.0976 - val_eval_accuracy: 0.8315\n",
      "Epoch 283/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7369 - eval_accuracy: 0.7154 - val_loss: 10.1004 - val_eval_accuracy: 0.8316\n",
      "Epoch 284/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7372 - eval_accuracy: 0.8690 - val_loss: 10.0997 - val_eval_accuracy: 0.8316\n",
      "Epoch 285/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.6975 - val_loss: 10.0974 - val_eval_accuracy: 0.8315\n",
      "Epoch 286/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7372 - eval_accuracy: 0.2746 - val_loss: 10.1006 - val_eval_accuracy: 0.8316\n",
      "Epoch 287/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.3573 - val_loss: 10.1017 - val_eval_accuracy: 0.8316\n",
      "Epoch 288/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7374 - eval_accuracy: 0.6660 - val_loss: 10.1042 - val_eval_accuracy: 0.8317\n",
      "Epoch 289/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7373 - eval_accuracy: 0.7875 - val_loss: 10.1026 - val_eval_accuracy: 0.8317\n",
      "Epoch 290/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7371 - eval_accuracy: 0.6418 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 291/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7370 - eval_accuracy: 0.6129 - val_loss: 10.0998 - val_eval_accuracy: 0.8316\n",
      "Epoch 292/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.8023 - val_loss: 10.0951 - val_eval_accuracy: 0.8315\n",
      "Epoch 293/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7370 - eval_accuracy: 0.8886 - val_loss: 10.0960 - val_eval_accuracy: 0.8315\n",
      "Epoch 294/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7371 - eval_accuracy: 0.6916 - val_loss: 10.0990 - val_eval_accuracy: 0.8316\n",
      "Epoch 295/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.8545 - val_loss: 10.0989 - val_eval_accuracy: 0.8316\n",
      "Epoch 296/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7366 - eval_accuracy: 0.5882 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 297/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.9051 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 298/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.4680 - val_loss: 10.0988 - val_eval_accuracy: 0.8316\n",
      "Epoch 299/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7748 - val_loss: 10.0991 - val_eval_accuracy: 0.8316\n",
      "Epoch 300/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7986 - val_loss: 10.0992 - val_eval_accuracy: 0.8316\n",
      "Epoch 301/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7366 - eval_accuracy: 0.5985 - val_loss: 10.0994 - val_eval_accuracy: 0.8316\n",
      "Epoch 302/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.5161 - val_loss: 10.1001 - val_eval_accuracy: 0.8316\n",
      "Epoch 303/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.8328 - val_loss: 10.1002 - val_eval_accuracy: 0.8316\n",
      "Epoch 304/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.6219 - val_loss: 10.1003 - val_eval_accuracy: 0.8316\n",
      "Epoch 305/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.8314 - val_loss: 10.1003 - val_eval_accuracy: 0.8316\n",
      "Epoch 306/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7451 - val_loss: 10.1004 - val_eval_accuracy: 0.8316\n",
      "Epoch 307/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.6790 - val_loss: 10.1000 - val_eval_accuracy: 0.8316\n",
      "Epoch 308/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7719 - val_loss: 10.0998 - val_eval_accuracy: 0.8316\n",
      "Epoch 309/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.9058 - val_loss: 10.0998 - val_eval_accuracy: 0.8316\n",
      "Epoch 310/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7343 - val_loss: 10.0999 - val_eval_accuracy: 0.8316\n",
      "Epoch 311/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.5563 - val_loss: 10.1002 - val_eval_accuracy: 0.8316\n",
      "Epoch 312/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7025 - val_loss: 10.1007 - val_eval_accuracy: 0.8316\n",
      "Epoch 313/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7444 - val_loss: 10.1008 - val_eval_accuracy: 0.8316\n",
      "Epoch 314/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.1986 - val_loss: 10.1010 - val_eval_accuracy: 0.8316\n",
      "Epoch 315/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7907 - val_loss: 10.1005 - val_eval_accuracy: 0.8316\n",
      "Epoch 316/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.6490 - val_loss: 10.1007 - val_eval_accuracy: 0.8316\n",
      "Epoch 317/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.8374 - val_loss: 10.1005 - val_eval_accuracy: 0.8316\n",
      "Epoch 318/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7911 - val_loss: 10.1000 - val_eval_accuracy: 0.8316\n",
      "Epoch 319/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.6613 - val_loss: 10.0998 - val_eval_accuracy: 0.8316\n",
      "Epoch 320/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7945 - val_loss: 10.0992 - val_eval_accuracy: 0.8316\n",
      "Epoch 321/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.8548 - val_loss: 10.0994 - val_eval_accuracy: 0.8316\n",
      "Epoch 322/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7493 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 323/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7549 - val_loss: 10.0977 - val_eval_accuracy: 0.8315\n",
      "Epoch 324/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7786 - val_loss: 10.0979 - val_eval_accuracy: 0.8315\n",
      "Epoch 325/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.6928 - val_loss: 10.0973 - val_eval_accuracy: 0.8315\n",
      "Epoch 326/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.6946 - val_loss: 10.0970 - val_eval_accuracy: 0.8315\n",
      "Epoch 327/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7930 - val_loss: 10.0969 - val_eval_accuracy: 0.8315\n",
      "Epoch 328/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.8910 - val_loss: 10.0967 - val_eval_accuracy: 0.8315\n",
      "Epoch 329/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7366 - eval_accuracy: 0.6722 - val_loss: 10.0969 - val_eval_accuracy: 0.8315\n",
      "Epoch 330/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7252 - val_loss: 10.0971 - val_eval_accuracy: 0.8315\n",
      "Epoch 331/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.7454 - val_loss: 10.0970 - val_eval_accuracy: 0.8315\n",
      "Epoch 332/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7366 - eval_accuracy: 0.6826 - val_loss: 10.0969 - val_eval_accuracy: 0.8315\n",
      "Epoch 333/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7365 - eval_accuracy: 0.3972 - val_loss: 10.0975 - val_eval_accuracy: 0.8315\n",
      "Epoch 334/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.7819 - val_loss: 10.0978 - val_eval_accuracy: 0.8315\n",
      "Epoch 335/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7365 - eval_accuracy: 0.3881 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 336/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6454 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 337/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7530 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 338/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.4814 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 339/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8597 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 340/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8015 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 341/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7345 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 342/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8322 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 343/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.5109 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 344/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8392 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 345/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6417 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 346/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8733 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 347/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7400 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 348/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7683 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 349/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7942 - val_loss: 10.0984 - val_eval_accuracy: 0.8316\n",
      "Epoch 350/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7881 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 351/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8360 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 352/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5387 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 353/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6267 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 354/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7178 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 355/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.4894 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 356/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8165 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 357/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7664 - val_loss: 10.0986 - val_eval_accuracy: 0.8316\n",
      "Epoch 358/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6416 - val_loss: 10.0985 - val_eval_accuracy: 0.8316\n",
      "Epoch 359/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7892 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 360/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7841 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 361/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7207 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 362/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6376 - val_loss: 10.0979 - val_eval_accuracy: 0.8315\n",
      "Epoch 363/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8135 - val_loss: 10.0979 - val_eval_accuracy: 0.8315\n",
      "Epoch 364/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6192 - val_loss: 10.0979 - val_eval_accuracy: 0.8315\n",
      "Epoch 365/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: -0.0815 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 366/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7260 - val_loss: 10.0980 - val_eval_accuracy: 0.8315\n",
      "Epoch 367/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6984 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 368/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7782 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 369/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8627 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 370/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6335 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 371/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7865 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 372/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8065 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 373/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7463 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 374/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8083 - val_loss: 10.0981 - val_eval_accuracy: 0.8315\n",
      "Epoch 375/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6378 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 376/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5175 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 377/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8784 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 378/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6707 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 379/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5631 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 380/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6598 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 381/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8061 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 382/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7285 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 383/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7784 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 384/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.3546 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 385/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7536 - val_loss: 10.0982 - val_eval_accuracy: 0.8315\n",
      "Epoch 386/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7354 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 387/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8451 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 388/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7587 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 389/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6470 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 390/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8653 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 391/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5688 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 392/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6628 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 393/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8333 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 394/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7611 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 395/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7308 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 396/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8923 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 397/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7843 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 398/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8000 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 399/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8942 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 400/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5611 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 401/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7813 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 402/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7379 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 403/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6563 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 404/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6353 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 405/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6543 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 406/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8228 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 407/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7805 - val_loss: 10.0983 - val_eval_accuracy: 0.8315\n",
      "Epoch 408/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: -0.0178 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 409/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7124 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 410/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8451 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 411/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6862 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 412/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7826 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 413/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7073 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 414/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6566 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 415/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8665 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 416/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8024 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 417/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7959 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 418/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8037 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 419/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7473 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 420/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8346 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 421/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7836 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 422/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6670 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 423/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8109 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 424/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7434 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 425/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6751 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 426/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7619 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 427/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6672 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 428/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8174 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 429/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7112 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 430/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7135 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 431/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8623 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 432/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7380 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 433/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8047 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 434/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7946 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 435/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6993 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 436/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6693 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 437/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7818 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 438/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7289 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 439/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7869 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 440/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7843 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 441/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5316 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 442/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8151 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 443/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8204 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 444/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8352 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 445/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8398 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 446/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7319 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 447/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8339 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 448/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7863 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 449/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6070 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 450/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.8097 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 451/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7690 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 452/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7570 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 453/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.7962 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 454/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7651 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 455/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6955 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 456/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8455 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 457/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7710 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 458/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.5808 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 459/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.6342 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 460/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7841 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 461/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8456 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 462/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.7430 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 463/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.9502 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 464/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.4454 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 465/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6817 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 466/1000\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.7364 - eval_accuracy: 0.6581 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Epoch 467/1000\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7364 - eval_accuracy: 0.8475 - val_loss: 10.0984 - val_eval_accuracy: 0.8315\n",
      "Accuracy: 0.6802869439125061\n",
      " MSE: 9.909558296203613\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=256, activation='relu', input_shape=(len(X_train_2.keys()),)), # (len(X_train.keys()),)로 입력해야 튜플 형태로 입력되어 오류가 발생하지 않음\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer= optimizer, \n",
    "              metrics=[EvalAccuracy()])\n",
    "\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_scaled, y_train, validation_split=0.3, epochs=1000, batch_size=50, verbose=1, callbacks=[es, rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
