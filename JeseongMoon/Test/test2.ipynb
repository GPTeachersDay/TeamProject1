{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 10) (836, 10) (3341,) (836,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_dataset(csv_path, TRAIN_RATIO=0.8):\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 성별 원핫 인코딩\n",
    "    df=pd.get_dummies(df,columns=['Sex'])\n",
    "    \n",
    "    # 학습 데이터 분리\n",
    "    X = df.drop('Rings', axis=1)\n",
    "    y = df['Rings']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "csv_path = 'D:\\project\\Teamproject1\\colabo\\Data\\Regression_data.csv'\n",
    "X_train, X_test, y_train, y_test = load_dataset(csv_path)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M  \n",
       "461          0.265      1      0      0  \n",
       "2835         0.250      0      0      1  \n",
       "1378         0.354      1      0      0  \n",
       "2569         0.111      0      1      0  \n",
       "369          0.470      1      0      0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전복 전체 무게가 살 + 내장 + 껍질보다 적게 나가는 경우는 말이 안됨\n",
    "body = X_train['Whole weight'] - (X_train['Shucked weight'] + X_train['Viscera weight'] + X_train['Shell weight'])\n",
    "X_train['body'] = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = X_train[X_train['body'] < 0].index\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = X_test['Whole weight'] - (X_test['Shucked weight'] + X_test['Viscera weight'] + X_test['Shell weight'])\n",
    "X_test['body'] = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2 = X_test[X_test['body'] < 0].index\n",
    "index2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제해줌\n",
    "X_train.drop(index, axis=0, inplace=True)\n",
    "X_test.drop(index2, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenth가 Diameter보다 크다.\n",
    "<br>--> Length는 장축의 길이, Diameter는 단축의 지름으로 판단됨\n",
    "<br>타원(전복 껍데기)의 둘레 및 넓이 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length가 Diameter보다 큰게 딱 1개 있음 --> 그럴 수도 있으니 삭제는 안함\n",
    "index3 = X_train[X_train['Diameter'] > X_train['Length']].index\n",
    "index3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index4 = X_test[X_test['Diameter'] > X_test['Length']].index\n",
    "index4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 넓이 ( a * b * π)\n",
    "area = 0.5 * X_train['Length'] * 0.5 * X_train['Diameter'] * np.pi\n",
    "X_train['Area'] = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 넓이 \n",
    "area2 = 0.5 * X_test['Length'] * 0.5 * X_test['Diameter'] * np.pi\n",
    "X_test['Area'] = area2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter = np.pi * np.sqrt(0.5 * ((X_train['Length'] ** 2) + (X_train['Diameter'] ** 2)))\n",
    "X_train['Perimeter'] = perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 껍질의 둘레 (근사) ( 2π*(0.5 * √(a^2 + b^2)))\n",
    "perimeter2 = np.pi * np.sqrt(0.5 * ((X_test['Length'] ** 2) + (X_test['Diameter'] ** 2)))\n",
    "X_test['Perimeter'] = perimeter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>1.660072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>1.572837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2930</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.769361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>1.277329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.974085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "461    0.585     0.465   0.170        0.9915          0.3865          0.2240   \n",
       "2835   0.570     0.420   0.140        0.8745          0.4160          0.1650   \n",
       "1378   0.620     0.500   0.150        1.2930          0.5960          0.3135   \n",
       "2569   0.460     0.345   0.115        0.4215          0.1895          0.1020   \n",
       "369    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
       "\n",
       "      Shell weight  Sex_F  Sex_I  Sex_M    body      Area  Perimeter  \n",
       "461          0.265      1      0      0  0.1160  0.213648   1.660072  \n",
       "2835         0.250      0      0      1  0.0435  0.188024   1.572837  \n",
       "1378         0.354      1      0      0  0.0295  0.243473   1.769361  \n",
       "2569         0.111      0      1      0  0.0190  0.124643   1.277329  \n",
       "369          0.470      1      0      0  0.2700  0.303478   1.974085  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell weight      0.619796\n",
      "Diameter          0.559512\n",
      "Perimeter         0.548978\n",
      "Length            0.539317\n",
      "Height            0.534439\n",
      "body              0.533203\n",
      "Area              0.532949\n",
      "Whole weight      0.525487\n",
      "Viscera weight    0.489945\n",
      "Shucked weight    0.403014\n",
      "Sex_F             0.242466\n",
      "Sex_M             0.178722\n",
      "Sex_I            -0.431255\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟값과 각 변수들 간의 상관관계\n",
    "co = X_train.corrwith(y_train)\n",
    "\n",
    "# 상관계수를 내림차순으로 정리\n",
    "print(co.sort_values(ascending=False))\n",
    "\n",
    "# 절대값\n",
    "co_abs = abs(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Whole weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.572837</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.8745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.769361</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>1.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1.277329</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.974085</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>1.7190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height    body      Area  \\\n",
       "461          0.265     0.465   1.660072   0.585   0.170  0.1160  0.213648   \n",
       "2835         0.250     0.420   1.572837   0.570   0.140  0.0435  0.188024   \n",
       "1378         0.354     0.500   1.769361   0.620   0.150  0.0295  0.243473   \n",
       "2569         0.111     0.345   1.277329   0.460   0.115  0.0190  0.124643   \n",
       "369          0.470     0.560   1.974085   0.690   0.215  0.2700  0.303478   \n",
       "\n",
       "      Whole weight  \n",
       "461         0.9915  \n",
       "2835        0.8745  \n",
       "1378        1.2930  \n",
       "2569        0.4215  \n",
       "369         1.7190  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = X_train[['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'body', 'Area', 'Whole weight']]\n",
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>body</th>\n",
       "      <th>Area</th>\n",
       "      <th>Whole weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.126273</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>0.240</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.578631</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.194386</td>\n",
       "      <td>0.7530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.284024</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.126449</td>\n",
       "      <td>0.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.660072</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.9080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.550</td>\n",
       "      <td>1.951489</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.295899</td>\n",
       "      <td>1.7725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shell weight  Diameter  Perimeter  Length  Height    body      Area  \\\n",
       "2197         0.125     0.305   1.126273   0.405   0.105  0.0105  0.097016   \n",
       "3662         0.240     0.450   1.578631   0.550   0.140  0.0360  0.194386   \n",
       "1266         0.114     0.350   1.284024   0.460   0.105  0.0220  0.126449   \n",
       "485          0.315     0.465   1.660072   0.585   0.140  0.0505  0.213648   \n",
       "2083         0.490     0.550   1.951489   0.685   0.200  0.0825  0.295899   \n",
       "\n",
       "      Whole weight  \n",
       "2197        0.3625  \n",
       "3662        0.7530  \n",
       "1266        0.3705  \n",
       "485         0.9080  \n",
       "2083        1.7725  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2 = X_test[['Shell weight', 'Diameter', 'Perimeter', 'Length', 'Height', 'body', 'Area', 'Whole weight']]\n",
    "X_test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 피처 스케일링\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_2)\n",
    "X_test_scaled  = scaler.fit_transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 사용자 정의 평가 지표 클래스\n",
    "class EvalAccuracy(tf.keras.metrics.Metric): # TensorFlow의 Metric 클래스를 상속 받음\n",
    "\n",
    "    def __init__(self, name=\"eval_accuracy\", **kwargs): # 부모 클래스의 __init__() 메소드를 호출하여 필요한 초기화를 수행\n",
    "        super(EvalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.correct = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "        # add_weight() 메소드를 사용하여 평가 지표를 계산하는데 필요한 변수를 생성(각 배치에서의 평가 결과를 누적하기 위해)\n",
    "        # add_weight() 는 텐서플로우 Layer 클래스의 메서드(새로운 가중치를 추가하는 기능, 여기서는 평가 지표를 계산하는 데 사용되는 일종의 내부 변수를 의미)\n",
    "        # 이 구문이 실행되면, EvalAccuracy 인스턴스는 새로운 가중치를 추가하고 그 가중치를 self.correct에 저장한다.\n",
    "        # 이 self.correct는 update_state() 메서드에서 업데이트되며, '현재까지 처리한 모든 배치에 대한 평가 지표의 평균을 저장'한다.\n",
    "\n",
    "    def update_state(self, y_true, y_predict, sample_weight=None):\n",
    "        value = tf.abs((y_predict - y_true) / y_true)\n",
    "        self.correct.assign(tf.reduce_mean(value)) # 오차율을 계산해서 correct 변수에 누적한 후, assign() 메소드를 사용하여 correct 변수의 값을 업데이트\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - self.correct\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 에포크마다 평가 지표 초기화\n",
    "        self.correct.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:-37]\n",
    "y_test = y_test[:-37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "226/226 [==============================] - 1s 1ms/step - loss: 23.4821 - eval_accuracy: 0.7454 - val_loss: 10.4787 - val_eval_accuracy: 0.8805\n",
      "Epoch 2/150\n",
      "226/226 [==============================] - 0s 889us/step - loss: 11.2334 - eval_accuracy: 0.7659 - val_loss: 12.0423 - val_eval_accuracy: 0.8432\n",
      "Epoch 3/150\n",
      "226/226 [==============================] - 0s 951us/step - loss: 11.0945 - eval_accuracy: 0.8452 - val_loss: 10.2645 - val_eval_accuracy: 0.8730\n",
      "Epoch 4/150\n",
      "226/226 [==============================] - 0s 916us/step - loss: 11.0702 - eval_accuracy: 0.7863 - val_loss: 10.0621 - val_eval_accuracy: 0.8856\n",
      "Epoch 5/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 11.0270 - eval_accuracy: 0.8392 - val_loss: 10.1114 - val_eval_accuracy: 0.8878\n",
      "Epoch 6/150\n",
      "226/226 [==============================] - 0s 920us/step - loss: 11.1055 - eval_accuracy: 0.6922 - val_loss: 10.4059 - val_eval_accuracy: 0.8762\n",
      "Epoch 7/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 11.0403 - eval_accuracy: 0.5969 - val_loss: 10.4914 - val_eval_accuracy: 0.8746\n",
      "Epoch 8/150\n",
      "226/226 [==============================] - 0s 916us/step - loss: 10.9905 - eval_accuracy: 0.7464 - val_loss: 10.1264 - val_eval_accuracy: 0.8873\n",
      "Epoch 9/150\n",
      "226/226 [==============================] - 0s 907us/step - loss: 11.0690 - eval_accuracy: 0.8807 - val_loss: 10.0708 - val_eval_accuracy: 0.8876\n",
      "Epoch 10/150\n",
      "226/226 [==============================] - 0s 902us/step - loss: 10.9702 - eval_accuracy: 0.8187 - val_loss: 10.2304 - val_eval_accuracy: 0.8819\n",
      "Epoch 11/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.9634 - eval_accuracy: 0.8080 - val_loss: 11.3108 - val_eval_accuracy: 0.8592\n",
      "Epoch 12/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.9443 - eval_accuracy: 0.8079 - val_loss: 10.0593 - val_eval_accuracy: 0.8848\n",
      "Epoch 13/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.9258 - eval_accuracy: 0.6902 - val_loss: 10.3484 - val_eval_accuracy: 0.8713\n",
      "Epoch 14/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.9028 - eval_accuracy: 0.8239 - val_loss: 10.0860 - val_eval_accuracy: 0.8805\n",
      "Epoch 15/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.8844 - eval_accuracy: 0.6529 - val_loss: 10.3822 - val_eval_accuracy: 0.8769\n",
      "Epoch 16/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.9087 - eval_accuracy: 0.7301 - val_loss: 10.4283 - val_eval_accuracy: 0.8755\n",
      "Epoch 17/150\n",
      "226/226 [==============================] - 0s 858us/step - loss: 10.8499 - eval_accuracy: 0.5954 - val_loss: 11.4114 - val_eval_accuracy: 0.8365\n",
      "Epoch 18/150\n",
      "226/226 [==============================] - 0s 880us/step - loss: 10.9634 - eval_accuracy: 0.6425 - val_loss: 10.0588 - val_eval_accuracy: 0.8835\n",
      "Epoch 19/150\n",
      "226/226 [==============================] - 0s 964us/step - loss: 10.9617 - eval_accuracy: 0.7047 - val_loss: 10.4142 - val_eval_accuracy: 0.8698\n",
      "Epoch 20/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.9630 - eval_accuracy: 0.7547 - val_loss: 10.0581 - val_eval_accuracy: 0.8842\n",
      "Epoch 21/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8710 - eval_accuracy: 0.7370 - val_loss: 10.0773 - val_eval_accuracy: 0.8815\n",
      "Epoch 22/150\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 10.9204 - eval_accuracy: 0.8391 - val_loss: 10.1446 - val_eval_accuracy: 0.8777\n",
      "Epoch 23/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 10.9123 - eval_accuracy: 0.7414 - val_loss: 10.5138 - val_eval_accuracy: 0.8733\n",
      "Epoch 24/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 10.9063 - eval_accuracy: 0.8126 - val_loss: 10.1073 - val_eval_accuracy: 0.8793\n",
      "Epoch 25/150\n",
      "226/226 [==============================] - 0s 996us/step - loss: 10.9241 - eval_accuracy: 0.8001 - val_loss: 10.0886 - val_eval_accuracy: 0.8880\n",
      "Epoch 26/150\n",
      "226/226 [==============================] - 0s 924us/step - loss: 10.8799 - eval_accuracy: 0.7582 - val_loss: 10.4334 - val_eval_accuracy: 0.8750\n",
      "Epoch 27/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8519 - eval_accuracy: 0.6316 - val_loss: 10.0708 - val_eval_accuracy: 0.8880\n",
      "Epoch 28/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.8910 - eval_accuracy: 0.7978 - val_loss: 10.1180 - val_eval_accuracy: 0.8866\n",
      "Epoch 29/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.9062 - eval_accuracy: 0.8330 - val_loss: 10.3393 - val_eval_accuracy: 0.8779\n",
      "Epoch 30/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.9227 - eval_accuracy: 0.7355 - val_loss: 10.2593 - val_eval_accuracy: 0.8804\n",
      "Epoch 31/150\n",
      "226/226 [==============================] - 0s 858us/step - loss: 10.8522 - eval_accuracy: 0.8639 - val_loss: 10.4787 - val_eval_accuracy: 0.8739\n",
      "Epoch 32/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8695 - eval_accuracy: 0.7539 - val_loss: 10.0598 - val_eval_accuracy: 0.8872\n",
      "Epoch 33/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8991 - eval_accuracy: 0.9381 - val_loss: 10.2215 - val_eval_accuracy: 0.8818\n",
      "Epoch 34/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8385 - eval_accuracy: 0.6338 - val_loss: 10.1448 - val_eval_accuracy: 0.8853\n",
      "Epoch 35/150\n",
      "226/226 [==============================] - 0s 911us/step - loss: 10.9074 - eval_accuracy: 0.5179 - val_loss: 10.0685 - val_eval_accuracy: 0.8877\n",
      "Epoch 36/150\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 10.9175 - eval_accuracy: 0.8126 - val_loss: 10.1490 - val_eval_accuracy: 0.8850\n",
      "Epoch 37/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.8740 - eval_accuracy: 0.8101 - val_loss: 10.1554 - val_eval_accuracy: 0.8775\n",
      "Epoch 38/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.8550 - eval_accuracy: 0.8473 - val_loss: 10.5025 - val_eval_accuracy: 0.8734\n",
      "Epoch 39/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8479 - eval_accuracy: 0.6678 - val_loss: 10.8078 - val_eval_accuracy: 0.8609\n",
      "Epoch 40/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7741 - eval_accuracy: 0.6463 - val_loss: 11.5382 - val_eval_accuracy: 0.8528\n",
      "Epoch 41/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8290 - eval_accuracy: 0.7820 - val_loss: 10.1047 - val_eval_accuracy: 0.8799\n",
      "Epoch 42/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8938 - eval_accuracy: 0.6625 - val_loss: 10.0888 - val_eval_accuracy: 0.8888\n",
      "Epoch 43/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.8388 - eval_accuracy: 0.6798 - val_loss: 10.2563 - val_eval_accuracy: 0.8808\n",
      "Epoch 44/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 10.8448 - eval_accuracy: 0.8782 - val_loss: 10.9350 - val_eval_accuracy: 0.8653\n",
      "Epoch 45/150\n",
      "226/226 [==============================] - 0s 858us/step - loss: 10.8444 - eval_accuracy: 0.6599 - val_loss: 10.1119 - val_eval_accuracy: 0.8879\n",
      "Epoch 46/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8924 - eval_accuracy: 0.7900 - val_loss: 10.4008 - val_eval_accuracy: 0.8757\n",
      "Epoch 47/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.8582 - eval_accuracy: 0.8441 - val_loss: 10.3799 - val_eval_accuracy: 0.8711\n",
      "Epoch 48/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8511 - eval_accuracy: 0.7051 - val_loss: 10.7143 - val_eval_accuracy: 0.8688\n",
      "Epoch 49/150\n",
      "226/226 [==============================] - 0s 880us/step - loss: 10.7817 - eval_accuracy: 0.7690 - val_loss: 10.1516 - val_eval_accuracy: 0.8779\n",
      "Epoch 50/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8638 - eval_accuracy: 0.6226 - val_loss: 10.4311 - val_eval_accuracy: 0.8754\n",
      "Epoch 51/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8941 - eval_accuracy: 0.8339 - val_loss: 10.0672 - val_eval_accuracy: 0.8840\n",
      "Epoch 52/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8539 - eval_accuracy: 0.4668 - val_loss: 10.0819 - val_eval_accuracy: 0.8820\n",
      "Epoch 53/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 10.9019 - eval_accuracy: 0.7594 - val_loss: 10.3290 - val_eval_accuracy: 0.8723\n",
      "Epoch 54/150\n",
      "226/226 [==============================] - 0s 889us/step - loss: 10.8031 - eval_accuracy: 0.8258 - val_loss: 10.2399 - val_eval_accuracy: 0.8810\n",
      "Epoch 55/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8771 - eval_accuracy: 0.7950 - val_loss: 10.9614 - val_eval_accuracy: 0.8642\n",
      "Epoch 56/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8560 - eval_accuracy: 0.7495 - val_loss: 10.2137 - val_eval_accuracy: 0.8756\n",
      "Epoch 57/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.8751 - eval_accuracy: 0.8169 - val_loss: 10.0678 - val_eval_accuracy: 0.8848\n",
      "Epoch 58/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8429 - eval_accuracy: 0.7786 - val_loss: 10.0976 - val_eval_accuracy: 0.8889\n",
      "Epoch 59/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8364 - eval_accuracy: 0.8262 - val_loss: 10.0798 - val_eval_accuracy: 0.8830\n",
      "Epoch 60/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.8299 - eval_accuracy: 0.7946 - val_loss: 10.3170 - val_eval_accuracy: 0.8792\n",
      "Epoch 61/150\n",
      "226/226 [==============================] - 0s 960us/step - loss: 10.8562 - eval_accuracy: 0.8179 - val_loss: 10.4825 - val_eval_accuracy: 0.8739\n",
      "Epoch 62/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.8772 - eval_accuracy: 0.7710 - val_loss: 10.2034 - val_eval_accuracy: 0.8827\n",
      "Epoch 63/150\n",
      "226/226 [==============================] - 0s 889us/step - loss: 10.8459 - eval_accuracy: 0.7790 - val_loss: 10.2153 - val_eval_accuracy: 0.8826\n",
      "Epoch 64/150\n",
      "226/226 [==============================] - 0s 907us/step - loss: 10.8409 - eval_accuracy: 0.6855 - val_loss: 10.1156 - val_eval_accuracy: 0.8883\n",
      "Epoch 65/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8645 - eval_accuracy: 0.6314 - val_loss: 10.1088 - val_eval_accuracy: 0.8885\n",
      "Epoch 66/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7616 - eval_accuracy: 0.6103 - val_loss: 10.1123 - val_eval_accuracy: 0.8881\n",
      "Epoch 67/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.8537 - eval_accuracy: 0.7425 - val_loss: 10.3746 - val_eval_accuracy: 0.8712\n",
      "Epoch 68/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8134 - eval_accuracy: 0.7904 - val_loss: 10.7182 - val_eval_accuracy: 0.8691\n",
      "Epoch 69/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.8440 - eval_accuracy: 0.8939 - val_loss: 10.2114 - val_eval_accuracy: 0.8825\n",
      "Epoch 70/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8491 - eval_accuracy: 0.7705 - val_loss: 10.0723 - val_eval_accuracy: 0.8874\n",
      "Epoch 71/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8377 - eval_accuracy: 0.6191 - val_loss: 10.1637 - val_eval_accuracy: 0.8843\n",
      "Epoch 72/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.8358 - eval_accuracy: 0.6000 - val_loss: 10.0658 - val_eval_accuracy: 0.8856\n",
      "Epoch 73/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.8349 - eval_accuracy: 0.6970 - val_loss: 10.0985 - val_eval_accuracy: 0.8810\n",
      "Epoch 74/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.8582 - eval_accuracy: 0.7115 - val_loss: 10.0933 - val_eval_accuracy: 0.8890\n",
      "Epoch 75/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.8457 - eval_accuracy: 0.6935 - val_loss: 10.2085 - val_eval_accuracy: 0.8832\n",
      "Epoch 76/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.8606 - eval_accuracy: 0.5904 - val_loss: 10.5037 - val_eval_accuracy: 0.8735\n",
      "Epoch 77/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8481 - eval_accuracy: 0.8941 - val_loss: 10.0740 - val_eval_accuracy: 0.8867\n",
      "Epoch 78/150\n",
      "226/226 [==============================] - 0s 911us/step - loss: 10.8073 - eval_accuracy: 0.5395 - val_loss: 10.4593 - val_eval_accuracy: 0.8747\n",
      "Epoch 79/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.8680 - eval_accuracy: 0.7860 - val_loss: 10.0938 - val_eval_accuracy: 0.8883\n",
      "Epoch 80/150\n",
      "226/226 [==============================] - 0s 898us/step - loss: 10.8540 - eval_accuracy: 0.7960 - val_loss: 10.3183 - val_eval_accuracy: 0.8785\n",
      "Epoch 81/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8266 - eval_accuracy: 0.7873 - val_loss: 10.2102 - val_eval_accuracy: 0.8830\n",
      "Epoch 82/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.7797 - eval_accuracy: 0.4513 - val_loss: 10.1608 - val_eval_accuracy: 0.8856\n",
      "Epoch 83/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7841 - eval_accuracy: 0.7578 - val_loss: 10.2899 - val_eval_accuracy: 0.8790\n",
      "Epoch 84/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.8071 - eval_accuracy: 0.7514 - val_loss: 10.1597 - val_eval_accuracy: 0.8850\n",
      "Epoch 85/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8576 - eval_accuracy: 0.6344 - val_loss: 10.2826 - val_eval_accuracy: 0.8796\n",
      "Epoch 86/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.8347 - eval_accuracy: 0.7767 - val_loss: 10.0763 - val_eval_accuracy: 0.8869\n",
      "Epoch 87/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.8369 - eval_accuracy: 0.5974 - val_loss: 10.1445 - val_eval_accuracy: 0.8867\n",
      "Epoch 88/150\n",
      "226/226 [==============================] - 0s 960us/step - loss: 10.8590 - eval_accuracy: 0.5230 - val_loss: 10.3613 - val_eval_accuracy: 0.8774\n",
      "Epoch 89/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8387 - eval_accuracy: 0.8408 - val_loss: 10.0817 - val_eval_accuracy: 0.8876\n",
      "Epoch 90/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.8591 - eval_accuracy: 0.7982 - val_loss: 10.2963 - val_eval_accuracy: 0.8799\n",
      "Epoch 91/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.8199 - eval_accuracy: 0.7469 - val_loss: 10.0825 - val_eval_accuracy: 0.8876\n",
      "Epoch 92/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8250 - eval_accuracy: 0.5805 - val_loss: 10.1491 - val_eval_accuracy: 0.8858\n",
      "Epoch 93/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.8328 - eval_accuracy: 0.5970 - val_loss: 10.6171 - val_eval_accuracy: 0.8708\n",
      "Epoch 94/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.8233 - eval_accuracy: 0.7569 - val_loss: 10.1292 - val_eval_accuracy: 0.8794\n",
      "Epoch 95/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8541 - eval_accuracy: 0.8000 - val_loss: 10.2514 - val_eval_accuracy: 0.8811\n",
      "Epoch 96/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8206 - eval_accuracy: 0.7180 - val_loss: 10.1637 - val_eval_accuracy: 0.8852\n",
      "Epoch 97/150\n",
      "226/226 [==============================] - 0s 884us/step - loss: 10.8181 - eval_accuracy: 0.9311 - val_loss: 10.1613 - val_eval_accuracy: 0.8779\n",
      "Epoch 98/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7721 - eval_accuracy: 0.7464 - val_loss: 10.0969 - val_eval_accuracy: 0.8818\n",
      "Epoch 99/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8549 - eval_accuracy: 0.8331 - val_loss: 10.0802 - val_eval_accuracy: 0.8860\n",
      "Epoch 100/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.8535 - eval_accuracy: 0.7147 - val_loss: 10.0980 - val_eval_accuracy: 0.8891\n",
      "Epoch 101/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.8359 - eval_accuracy: 0.5644 - val_loss: 10.0815 - val_eval_accuracy: 0.8878\n",
      "Epoch 102/150\n",
      "226/226 [==============================] - 0s 858us/step - loss: 10.7805 - eval_accuracy: 0.7618 - val_loss: 10.1974 - val_eval_accuracy: 0.8828\n",
      "Epoch 103/150\n",
      "226/226 [==============================] - 0s 956us/step - loss: 10.8112 - eval_accuracy: 0.8538 - val_loss: 10.0787 - val_eval_accuracy: 0.8872\n",
      "Epoch 104/150\n",
      "226/226 [==============================] - 0s 938us/step - loss: 10.8058 - eval_accuracy: 0.8315 - val_loss: 10.1869 - val_eval_accuracy: 0.8837\n",
      "Epoch 105/150\n",
      "226/226 [==============================] - 0s 929us/step - loss: 10.7825 - eval_accuracy: 0.6482 - val_loss: 10.1300 - val_eval_accuracy: 0.8878\n",
      "Epoch 106/150\n",
      "226/226 [==============================] - 0s 924us/step - loss: 10.8362 - eval_accuracy: 0.6966 - val_loss: 10.0853 - val_eval_accuracy: 0.8843\n",
      "Epoch 107/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.7482 - eval_accuracy: 0.7216 - val_loss: 10.1224 - val_eval_accuracy: 0.8886\n",
      "Epoch 108/150\n",
      "226/226 [==============================] - 0s 969us/step - loss: 10.7427 - eval_accuracy: 0.7219 - val_loss: 10.1075 - val_eval_accuracy: 0.8890\n",
      "Epoch 109/150\n",
      "226/226 [==============================] - 0s 911us/step - loss: 10.7149 - eval_accuracy: 0.8277 - val_loss: 10.0827 - val_eval_accuracy: 0.8853\n",
      "Epoch 110/150\n",
      "226/226 [==============================] - 0s 982us/step - loss: 10.7548 - eval_accuracy: 0.7104 - val_loss: 10.1053 - val_eval_accuracy: 0.8889\n",
      "Epoch 111/150\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 10.7492 - eval_accuracy: 0.7761 - val_loss: 10.0945 - val_eval_accuracy: 0.8879\n",
      "Epoch 112/150\n",
      "226/226 [==============================] - 0s 947us/step - loss: 10.7355 - eval_accuracy: 0.7882 - val_loss: 10.3419 - val_eval_accuracy: 0.8787\n",
      "Epoch 113/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.7638 - eval_accuracy: 0.7176 - val_loss: 10.1511 - val_eval_accuracy: 0.8864\n",
      "Epoch 114/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.7477 - eval_accuracy: 0.6539 - val_loss: 10.1078 - val_eval_accuracy: 0.8892\n",
      "Epoch 115/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7330 - eval_accuracy: 0.6584 - val_loss: 10.1845 - val_eval_accuracy: 0.8847\n",
      "Epoch 116/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.7541 - eval_accuracy: 0.7083 - val_loss: 10.1508 - val_eval_accuracy: 0.8865\n",
      "Epoch 117/150\n",
      "226/226 [==============================] - 0s 880us/step - loss: 10.7435 - eval_accuracy: 0.7151 - val_loss: 10.2087 - val_eval_accuracy: 0.8836\n",
      "Epoch 118/150\n",
      "226/226 [==============================] - 0s 871us/step - loss: 10.7454 - eval_accuracy: 0.7462 - val_loss: 10.2416 - val_eval_accuracy: 0.8822\n",
      "Epoch 119/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.7501 - eval_accuracy: 0.7756 - val_loss: 10.1004 - val_eval_accuracy: 0.8885\n",
      "Epoch 120/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.7368 - eval_accuracy: 0.8308 - val_loss: 10.2509 - val_eval_accuracy: 0.8817\n",
      "Epoch 121/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.7446 - eval_accuracy: 0.8044 - val_loss: 10.0823 - val_eval_accuracy: 0.8850\n",
      "Epoch 122/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.7553 - eval_accuracy: 0.8313 - val_loss: 10.1325 - val_eval_accuracy: 0.8877\n",
      "Epoch 123/150\n",
      "226/226 [==============================] - 0s 898us/step - loss: 10.7361 - eval_accuracy: 0.5679 - val_loss: 10.0845 - val_eval_accuracy: 0.8861\n",
      "Epoch 124/150\n",
      "226/226 [==============================] - 0s 853us/step - loss: 10.7495 - eval_accuracy: 0.6371 - val_loss: 10.1543 - val_eval_accuracy: 0.8863\n",
      "Epoch 125/150\n",
      "226/226 [==============================] - 0s 840us/step - loss: 10.7441 - eval_accuracy: 0.8045 - val_loss: 10.0884 - val_eval_accuracy: 0.8868\n",
      "Epoch 126/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.7490 - eval_accuracy: 0.6620 - val_loss: 10.1651 - val_eval_accuracy: 0.8857\n",
      "Epoch 127/150\n",
      "226/226 [==============================] - 0s 933us/step - loss: 10.7380 - eval_accuracy: 0.6732 - val_loss: 10.0989 - val_eval_accuracy: 0.8884\n",
      "Epoch 128/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7459 - eval_accuracy: 0.6866 - val_loss: 10.1170 - val_eval_accuracy: 0.8890\n",
      "Epoch 129/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.7487 - eval_accuracy: 0.7720 - val_loss: 10.1091 - val_eval_accuracy: 0.8892\n",
      "Epoch 130/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.7367 - eval_accuracy: 0.6170 - val_loss: 10.0924 - val_eval_accuracy: 0.8875\n",
      "Epoch 131/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.7441 - eval_accuracy: 0.6758 - val_loss: 10.1065 - val_eval_accuracy: 0.8888\n",
      "Epoch 132/150\n",
      "226/226 [==============================] - 0s 893us/step - loss: 10.7356 - eval_accuracy: 0.7721 - val_loss: 10.2063 - val_eval_accuracy: 0.8838\n",
      "Epoch 133/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.7371 - eval_accuracy: 0.7387 - val_loss: 10.2587 - val_eval_accuracy: 0.8817\n",
      "Epoch 134/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.7390 - eval_accuracy: 0.7178 - val_loss: 10.0877 - val_eval_accuracy: 0.8864\n",
      "Epoch 135/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.7483 - eval_accuracy: 0.8055 - val_loss: 10.0883 - val_eval_accuracy: 0.8864\n",
      "Epoch 136/150\n",
      "226/226 [==============================] - 0s 862us/step - loss: 10.7430 - eval_accuracy: 0.9196 - val_loss: 10.1452 - val_eval_accuracy: 0.8871\n",
      "Epoch 137/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.7423 - eval_accuracy: 0.7193 - val_loss: 10.0940 - val_eval_accuracy: 0.8874\n",
      "Epoch 138/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7437 - eval_accuracy: 0.5885 - val_loss: 10.1101 - val_eval_accuracy: 0.8892\n",
      "Epoch 139/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.7430 - eval_accuracy: 0.8139 - val_loss: 10.0888 - val_eval_accuracy: 0.8868\n",
      "Epoch 140/150\n",
      "226/226 [==============================] - 0s 898us/step - loss: 10.7462 - eval_accuracy: 0.8020 - val_loss: 10.1721 - val_eval_accuracy: 0.8854\n",
      "Epoch 141/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.7463 - eval_accuracy: 0.6685 - val_loss: 10.0898 - val_eval_accuracy: 0.8869\n",
      "Epoch 142/150\n",
      "226/226 [==============================] - 0s 867us/step - loss: 10.7435 - eval_accuracy: 0.7256 - val_loss: 10.1873 - val_eval_accuracy: 0.8847\n",
      "Epoch 143/150\n",
      "226/226 [==============================] - 0s 831us/step - loss: 10.7432 - eval_accuracy: 0.5235 - val_loss: 10.1057 - val_eval_accuracy: 0.8887\n",
      "Epoch 144/150\n",
      "226/226 [==============================] - 0s 849us/step - loss: 10.7455 - eval_accuracy: 0.8860 - val_loss: 10.1391 - val_eval_accuracy: 0.8876\n",
      "Epoch 145/150\n",
      "226/226 [==============================] - 0s 876us/step - loss: 10.7416 - eval_accuracy: 0.5741 - val_loss: 10.1948 - val_eval_accuracy: 0.8843\n",
      "Epoch 146/150\n",
      "226/226 [==============================] - 0s 871us/step - loss: 10.7398 - eval_accuracy: 0.7255 - val_loss: 10.0966 - val_eval_accuracy: 0.8877\n",
      "Epoch 147/150\n",
      "226/226 [==============================] - 0s 836us/step - loss: 10.7443 - eval_accuracy: 0.8355 - val_loss: 10.0955 - val_eval_accuracy: 0.8873\n",
      "Epoch 148/150\n",
      "226/226 [==============================] - 0s 844us/step - loss: 10.7432 - eval_accuracy: 0.9410 - val_loss: 10.1175 - val_eval_accuracy: 0.8892\n",
      "Epoch 149/150\n",
      "226/226 [==============================] - 0s 858us/step - loss: 10.7422 - eval_accuracy: 0.7780 - val_loss: 10.1586 - val_eval_accuracy: 0.8866\n",
      "Epoch 150/150\n",
      "226/226 [==============================] - 0s 929us/step - loss: 10.7283 - eval_accuracy: 0.6877 - val_loss: 10.1329 - val_eval_accuracy: 0.8883\n",
      "Accuracy: 0.6668540239334106\n",
      " MSE: 9.828749656677246\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=256, activation='relu', input_shape=(len(X_train_2.keys()),)), # (len(X_train.keys()),)로 입력해야 튜플 형태로 입력되어 오류가 발생하지 않음\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer= optimizer, \n",
    "              metrics=[EvalAccuracy()])\n",
    "\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_scaled, y_train, validation_split=0.3, epochs=150, batch_size=10, verbose=1, callbacks=[es, rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
