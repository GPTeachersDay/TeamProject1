{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 02:23:06.291322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 추출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메서드 정의\n",
    "def main(URL = 'D:/project/Teamproject1/JeseongMoon/Dataset/binary_classification_data.csv'):\n",
    "    \n",
    "    # 랜덤 시드 고정\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    global df, LEARNING_RATE, EPOCH_COUNT, MB_SIZE, REPORT, TRAIN_RATIO, X, y, X_train, X_test, y_train, y_test, y_pred\n",
    "    \n",
    "    df = load_dataset(URL) # 데이터 로드\n",
    "    Regression_Model() # 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/moonjeseong/Desktop/project/TeamProject1/JeseongMoon/Dataset/binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14318, 8) (3580, 8) (14318,) (3580,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_RATIO = 0.8\n",
    "# 학습 데이터 분리\n",
    "X = df.drop('target_class', axis=1)\n",
    "y = df['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_RATIO, random_state = 83)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13984</th>\n",
       "      <td>127.203125</td>\n",
       "      <td>52.269189</td>\n",
       "      <td>-0.222664</td>\n",
       "      <td>-0.101506</td>\n",
       "      <td>15.086120</td>\n",
       "      <td>54.658243</td>\n",
       "      <td>3.364636</td>\n",
       "      <td>9.392991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>52.968750</td>\n",
       "      <td>31.446367</td>\n",
       "      <td>3.410426</td>\n",
       "      <td>16.839254</td>\n",
       "      <td>41.168896</td>\n",
       "      <td>67.290303</td>\n",
       "      <td>1.648880</td>\n",
       "      <td>1.635625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>124.750000</td>\n",
       "      <td>35.676717</td>\n",
       "      <td>0.178535</td>\n",
       "      <td>1.837915</td>\n",
       "      <td>1.110368</td>\n",
       "      <td>11.973404</td>\n",
       "      <td>14.471259</td>\n",
       "      <td>246.172871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14864</th>\n",
       "      <td>100.164062</td>\n",
       "      <td>48.281689</td>\n",
       "      <td>0.561865</td>\n",
       "      <td>0.633153</td>\n",
       "      <td>1.925585</td>\n",
       "      <td>15.784724</td>\n",
       "      <td>9.617048</td>\n",
       "      <td>105.568196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17160</th>\n",
       "      <td>96.734375</td>\n",
       "      <td>46.709121</td>\n",
       "      <td>0.377105</td>\n",
       "      <td>0.152048</td>\n",
       "      <td>2.836120</td>\n",
       "      <td>18.707122</td>\n",
       "      <td>8.906146</td>\n",
       "      <td>92.142170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "13984                       127.203125   \n",
       "3126                         52.968750   \n",
       "13748                       124.750000   \n",
       "14864                       100.164062   \n",
       "17160                        96.734375   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "13984                                      52.269189   \n",
       "3126                                       31.446367   \n",
       "13748                                      35.676717   \n",
       "14864                                      48.281689   \n",
       "17160                                      46.709121   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "13984                                   -0.222664   \n",
       "3126                                     3.410426   \n",
       "13748                                    0.178535   \n",
       "14864                                    0.561865   \n",
       "17160                                    0.377105   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "13984                            -0.101506                  15.086120   \n",
       "3126                             16.839254                  41.168896   \n",
       "13748                             1.837915                   1.110368   \n",
       "14864                             0.633153                   1.925585   \n",
       "17160                             0.152048                   2.836120   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "13984                                54.658243   \n",
       "3126                                 67.290303   \n",
       "13748                                11.973404   \n",
       "14864                                15.784724   \n",
       "17160                                18.707122   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \n",
       "13984                              3.364636                       9.392991  \n",
       "3126                               1.648880                       1.635625  \n",
       "13748                             14.471259                     246.172871  \n",
       "14864                              9.617048                     105.568196  \n",
       "17160                              8.906146                      92.142170  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13971</th>\n",
       "      <td>118.890625</td>\n",
       "      <td>44.510223</td>\n",
       "      <td>0.223548</td>\n",
       "      <td>0.057119</td>\n",
       "      <td>1.369565</td>\n",
       "      <td>13.526842</td>\n",
       "      <td>14.222397</td>\n",
       "      <td>234.325537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>113.562500</td>\n",
       "      <td>47.418804</td>\n",
       "      <td>0.168827</td>\n",
       "      <td>-0.035996</td>\n",
       "      <td>2.205686</td>\n",
       "      <td>13.998608</td>\n",
       "      <td>10.654285</td>\n",
       "      <td>146.149662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>103.226562</td>\n",
       "      <td>40.028547</td>\n",
       "      <td>0.469162</td>\n",
       "      <td>0.883947</td>\n",
       "      <td>3.876254</td>\n",
       "      <td>19.969912</td>\n",
       "      <td>6.818652</td>\n",
       "      <td>54.926998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>123.609375</td>\n",
       "      <td>51.892352</td>\n",
       "      <td>0.288274</td>\n",
       "      <td>-0.199181</td>\n",
       "      <td>29.039298</td>\n",
       "      <td>67.633561</td>\n",
       "      <td>1.915681</td>\n",
       "      <td>1.718845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>134.960938</td>\n",
       "      <td>58.112418</td>\n",
       "      <td>-0.016643</td>\n",
       "      <td>-0.415690</td>\n",
       "      <td>4.735786</td>\n",
       "      <td>24.653527</td>\n",
       "      <td>6.325710</td>\n",
       "      <td>43.993983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "13971                       118.890625   \n",
       "4322                        113.562500   \n",
       "14042                       103.226562   \n",
       "7102                        123.609375   \n",
       "1003                        134.960938   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "13971                                      44.510223   \n",
       "4322                                       47.418804   \n",
       "14042                                      40.028547   \n",
       "7102                                       51.892352   \n",
       "1003                                       58.112418   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "13971                                    0.223548   \n",
       "4322                                     0.168827   \n",
       "14042                                    0.469162   \n",
       "7102                                     0.288274   \n",
       "1003                                    -0.016643   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "13971                             0.057119                   1.369565   \n",
       "4322                             -0.035996                   2.205686   \n",
       "14042                             0.883947                   3.876254   \n",
       "7102                             -0.199181                  29.039298   \n",
       "1003                             -0.415690                   4.735786   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "13971                                13.526842   \n",
       "4322                                 13.998608   \n",
       "14042                                19.969912   \n",
       "7102                                 67.633561   \n",
       "1003                                 24.653527   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \n",
       "13971                             14.222397                     234.325537  \n",
       "4322                              10.654285                     146.149662  \n",
       "14042                              6.818652                      54.926998  \n",
       "7102                               1.915681                       1.718845  \n",
       "1003                               6.325710                      43.993983  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.979922</td>\n",
       "      <td>46.524674</td>\n",
       "      <td>0.477455</td>\n",
       "      <td>1.748246</td>\n",
       "      <td>12.444476</td>\n",
       "      <td>26.217401</td>\n",
       "      <td>8.333270</td>\n",
       "      <td>105.312684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.526123</td>\n",
       "      <td>6.782110</td>\n",
       "      <td>1.052675</td>\n",
       "      <td>6.072202</td>\n",
       "      <td>29.200648</td>\n",
       "      <td>19.425697</td>\n",
       "      <td>4.491693</td>\n",
       "      <td>106.165624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.812500</td>\n",
       "      <td>24.772042</td>\n",
       "      <td>-1.876011</td>\n",
       "      <td>-1.755332</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>7.370432</td>\n",
       "      <td>-2.812353</td>\n",
       "      <td>-1.976976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.710938</td>\n",
       "      <td>42.362011</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>-0.186510</td>\n",
       "      <td>1.917224</td>\n",
       "      <td>14.416392</td>\n",
       "      <td>5.797204</td>\n",
       "      <td>35.364865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>114.914062</td>\n",
       "      <td>46.954915</td>\n",
       "      <td>0.223197</td>\n",
       "      <td>0.197768</td>\n",
       "      <td>2.788880</td>\n",
       "      <td>18.415923</td>\n",
       "      <td>8.460192</td>\n",
       "      <td>83.517364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.015625</td>\n",
       "      <td>51.001216</td>\n",
       "      <td>0.476759</td>\n",
       "      <td>0.937653</td>\n",
       "      <td>5.414716</td>\n",
       "      <td>28.217723</td>\n",
       "      <td>10.721939</td>\n",
       "      <td>140.055368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.617188</td>\n",
       "      <td>91.206475</td>\n",
       "      <td>8.069522</td>\n",
       "      <td>68.101622</td>\n",
       "      <td>211.948997</td>\n",
       "      <td>110.642211</td>\n",
       "      <td>34.539844</td>\n",
       "      <td>1191.000837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "count                     14318.000000   \n",
       "mean                        110.979922   \n",
       "std                          25.526123   \n",
       "min                           5.812500   \n",
       "25%                         100.710938   \n",
       "50%                         114.914062   \n",
       "75%                         127.015625   \n",
       "max                         192.617188   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "count                                   14318.000000   \n",
       "mean                                       46.524674   \n",
       "std                                         6.782110   \n",
       "min                                        24.772042   \n",
       "25%                                        42.362011   \n",
       "50%                                        46.954915   \n",
       "75%                                        51.001216   \n",
       "max                                        91.206475   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "count                                14318.000000   \n",
       "mean                                     0.477455   \n",
       "std                                      1.052675   \n",
       "min                                     -1.876011   \n",
       "25%                                      0.028368   \n",
       "50%                                      0.223197   \n",
       "75%                                      0.476759   \n",
       "max                                      8.069522   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "count                         14318.000000               14318.000000   \n",
       "mean                              1.748246                  12.444476   \n",
       "std                               6.072202                  29.200648   \n",
       "min                              -1.755332                   0.213211   \n",
       "25%                              -0.186510                   1.917224   \n",
       "50%                               0.197768                   2.788880   \n",
       "75%                               0.937653                   5.414716   \n",
       "max                              68.101622                 211.948997   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "count                             14318.000000   \n",
       "mean                                 26.217401   \n",
       "std                                  19.425697   \n",
       "min                                   7.370432   \n",
       "25%                                  14.416392   \n",
       "50%                                  18.415923   \n",
       "75%                                  28.217723   \n",
       "max                                 110.642211   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \n",
       "count                          14318.000000                   14318.000000  \n",
       "mean                               8.333270                     105.312684  \n",
       "std                                4.491693                     106.165624  \n",
       "min                               -2.812353                      -1.976976  \n",
       "25%                                5.797204                      35.364865  \n",
       "50%                                8.460192                      83.517364  \n",
       "75%                               10.721939                     140.055368  \n",
       "max                               34.539844                    1191.000837  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통합 프로필:\n",
    "<br>\n",
    "<br>평균: 평균 값은 대략 111으로 중앙값과 거의 비슷하며, 최소값과 최대값 사이에는 큰 차이가 있어 표준편차 값이 25.6으로 큽니다.\n",
    "<br>표준 편차: 평균 표준 편차는 46.6으로 중앙값에 가깝고, 최소값과 최대값을 보면 데이터 세트 전체에 정규 분포가 나타나는 것으로 보입니다.\n",
    "<br>초과 첨도: 데이터의 75% 이상이 0.5 아래에 있으며, 첨도가 낮은 경우 꼬리가 가벼우거나 이상치가 부족한 경향이 있습니다.\n",
    "<br>비대칭도: 데이터의 75% 이상이 1.0 아래에 있어 통합 프로필의 대부분은 약간만 비대칭인 것으로 나타납니다.\n",
    "<br>\n",
    "<br>DM-SNR 곡선:\n",
    "<br>\n",
    "<br>평균: 표준 편차가 매우 높은 편입니다. 29로, 값의 75%가 5.6 아래에 있고 최대 값은 극단적으로 높습니다. 대부분의 곡선의 평균 값은 낮은 편이 될 것으로 기대할 수 있습니다.\n",
    "<br>표준 편차: 이것도 최대 값이 매우 높아 보이며, 값의 75%가 28 아래에 있으며 중앙값은 19이고 평균은 26입니다. 평균의 높은 크기는 극단적으로 높은 값의 영향을 받은 것이지만, 해당 값들이 포함되지 않았다면 표준 편차는 중앙값 주변에 위치할 것으로 예상됩니다.\n",
    "<br>초과 첨도: 값들은 상당히 높으며, 평균 값은 8.23이고 최대 값은 34입니다. 값들은 정규 분포를 나타내는 것으로 보입니다.\n",
    "<br>비대칭도: 값들은 상당히 높으며, 평균 값은 102이고 최대 값은 1191으로 매우 높은 값을 가지고 있습니다. 이는 75분위 값과 비교했을 때 극도로 높은 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train set\n",
      "Missing values in feature  Mean of the integrated profile : 0\n",
      "Missing values in feature  Standard deviation of the integrated profile : 0\n",
      "Missing values in feature  Excess kurtosis of the integrated profile : 0\n",
      "Missing values in feature  Skewness of the integrated profile : 0\n",
      "Missing values in feature  Mean of the DM-SNR curve : 0\n",
      "Missing values in feature  Standard deviation of the DM-SNR curve : 0\n",
      "Missing values in feature  Excess kurtosis of the DM-SNR curve : 0\n",
      "Missing values in feature  Skewness of the DM-SNR curve : 0\n",
      "\n",
      "\n",
      "For Test set\n",
      "Missing values in feature  Mean of the integrated profile : 0\n",
      "Missing values in feature  Standard deviation of the integrated profile : 0\n",
      "Missing values in feature  Excess kurtosis of the integrated profile : 0\n",
      "Missing values in feature  Skewness of the integrated profile : 0\n",
      "Missing values in feature  Mean of the DM-SNR curve : 0\n",
      "Missing values in feature  Standard deviation of the DM-SNR curve : 0\n",
      "Missing values in feature  Excess kurtosis of the DM-SNR curve : 0\n",
      "Missing values in feature  Skewness of the DM-SNR curve : 0\n"
     ]
    }
   ],
   "source": [
    "print('For Train set')\n",
    "for feature in X_train.columns:\n",
    "    print('Missing values in feature ' + str(feature) + ' : ' + str(len(X_train[X_train[feature].isnull() == True])))\n",
    "\n",
    "print('\\n')\n",
    "print('For Test set')\n",
    "for feature in X_test.columns:\n",
    "    print('Missing values in feature ' + str(feature) + ' : ' + str(len(X_test[X_test[feature].isnull() == True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.909345\n",
       "1    0.090655\n",
       "Name: target_class, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13020\n",
       "1     1298\n",
       "Name: target_class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>데이터셋은 매우 불균형합니다. \n",
    "<br>펄서가 1,153개이고 펄서가 아닌 것은 11,375개입니다. \n",
    "<br>모델 구축 과정 전에 데이터셋을 샘플링해야 할 수도 있습니다.\n",
    "<br>\n",
    "<br>분류 모델을 평가하기 위해 고려해야 할 가장 중요한 지표는 F1 점수와 재현율입니다. \n",
    "<br>이는 대상 클래스가 극도로 적기 때문에 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "sns.heatmap(X_train.corr(), annot=True, fmt='.2f', cmap='Blues',mask=np.triu(X_train.corr(),+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>2개의 종속 변수 간의 상관 관계:\n",
    "<br>\n",
    "<br>높은 양의 상관 관계:\n",
    "<br>\n",
    "<br>편향된 통합 프로필의 왜도와 DM-SNR 곡선의 초과 첨도\n",
    "<br>DM-SNR 곡선의 왜도와 DM-SNR 곡선의 초과 첨도\n",
    "<br>DM-SNR 곡선의 평균과 표준 편차\n",
    "<br>---------------------------------------------------\n",
    "<br>높은 음의 상관 관계:\n",
    "<br>\n",
    "<br>통합 프로필의 평균과 통합 프로필의 초과 첨도\n",
    "<br>통합 프로필의 평균과 통합 프로필의 왜도\n",
    "<br>DM-SNR 곡선의 초과 첨도와 표준 편차\n",
    "<br>---------------------------------------------------\n",
    "<br>독립 변수와 종속 변수 간의 상관 관계:\n",
    "<br>\n",
    "<br>통합 프로필의 초과 첨도와 통합 프로필의 왜도는 Target_class와 높은 양의 상관 관계를 가지고 있습니다. \n",
    "<br>통합 프로필의 평균은 Target_class와 높은 음의 상관 관계를 가지고 있습니다.\n",
    "<br>\n",
    "<br>상관 관계는 데이터에서 다중공선성을 나타내며, \n",
    "<br>모델 구축 과정에서 바람직하지 않으므로 데이터 전처리 과정에서 처리되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1298,) (13020,)\n"
     ]
    }
   ],
   "source": [
    "y_train_1 = y_train[y_train == 1] #creating a dataset for only true pulsars for EDA\n",
    "y_train_0 = y_train[y_train == 0] #creating a dataset for only non pulsars for EDA\n",
    "print(y_train_1.shape, y_train_0.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>통합 프로필:\n",
    "<br>\n",
    "<br>평균: 이상치가 없으며, 약간 오른쪽으로 치우친 분포입니다. 평균은 56.52이고 표준 편차는 29.81입니다.\n",
    "<br>표준 편차: 이상치가 있으며, 오른쪽으로 치우친 분포입니다. 평균은 38.7이고 표준 편차는 7.87입니다.\n",
    "<br>초과 첨도: 이상치가 없으며, 약간 오른쪽으로 치우친 분포입니다. 평균은 3.12이고 표준 편차는 1.87입니다.\n",
    "<br>왜도: 이상치가 있으며, 오른쪽으로 치우친 분포입니다. 평균은 15.56이고 표준 편차는 14.14입니다.\n",
    "<br>\n",
    "<br>일반적으로 정규 분포를 따른다고 가정한다면, 펄서 별의 통합 프로필은 평균 약 56, 높은 표준 편차 약 38, \n",
    "<br>평균 왜도 약 15로 오른쪽으로 치우친 경향을 가지며, 평균 초과 첨도 약 3.12으로 \n",
    "<br>매우 뾰족한 곡선과 두꺼운 꼬리를 가질 것으로 예상할 수 있습니다.\n",
    "\n",
    "<br>DM-SNR 곡선:\n",
    "<br>\n",
    "<br>평균: 이상치가 매우 적게 있으며, 오른쪽으로 치우친 분포입니다. 평균은 44.91이고 표준 편차는 45.13입니다.\n",
    "<br>표준 편차: 이상치가 없으며, 약간 오른쪽으로 치우친 분포입니다. 평균은 56.92이고 표준 편차는 19.73입니다.\n",
    "<br>초과 첨도: 이상치가 있으며, 극단적으로 오른쪽으로 치우친 분포입니다. 평균은 2.78이고 표준 편차는 3.20입니다.\n",
    "<br>왜도: 이상치가 있으며, 극단적으로 오른쪽으로 치우친 분포입니다. 평균은 17.93이고 표준 편차는 46.92입니다.\n",
    "<br>\n",
    "<br>일반적으로 정규 분포를 따른다고 가정한다면, 펄서 별의 DM-SNR 곡선은 평균 약 45, 높은 표준 편차 약 57, \n",
    "<br>평균 왜도 약 18로 오른쪽으로 치우친 경향을 가지며, 평균 초과 첨도 약 2.78으로 \n",
    "<br>매우 뾰족한 곡선과 두꺼운 꼬리를 가질 것으로 예상할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Integrated Profile (통합 프로필):\n",
    "<br>\n",
    "<br>평균: 이상치가 있으며, 평균은 116.56이고 표준 편차는 17.43입니다. 정규 분포에 가까운 형태입니다.\n",
    "<br>표준 편차: 이상치가 있으며, 평균은 47.31이고 표준 편차는 6.15입니다. 거의 정규 분포에 가깝지만 오른쪽으로 꼬리가 있습니다.\n",
    "<br>초과 첨도: 이상치가 있으며, 평균은 0.20이고 표준 편차는 0.33입니다. 양쪽 꼬리를 가진 거의 정규 분포에 가깝습니다.\n",
    "<br>왜도: 이상치가 있으며, 오른쪽으로 치우친 분포입니다. 평균은 0.38이고 표준 편차는 0.98입니다.\n",
    "\n",
    "<br>일반적으로 정규 분포를 따른다고 가정한다면, 비펄서 별의 통합 프로필은 평균 약 117, 높은 표준 편차 약 47, \n",
    "<br>왜도가 거의 없는 분포 (평균 왜도 약 0.38)를 가질 것으로 예상할 수 있으며, 약간 뾰족한 곡선을 가질 것으로 예상됩니다 (평균 초과 첨도 약 0.38).\n",
    "<br>\n",
    "<br>DM-SNR Curve (DM-SNR 곡선):\n",
    "<br>\n",
    "<br>평균: 이상치가 몇 개 있으며, 극단적으로 오른쪽으로 치우친 분포입니다. 평균은 8.90이고 표준 편차는 24.59입니다.\n",
    "<br>표준 편차: 이상치가 몇 개 있으며, 오른쪽으로 치우친 분포입니다. 평균은 23.24이고 표준 편차는 16.71입니다.\n",
    "<br>초과 첨도: 이상치가 있으며, 약간 오른쪽으로 치우친 분포입니다. 평균은 8.89이고 표준 편차는 4.26입니다.\n",
    "<br>왜도: 이상치가 있으며, 오른쪽으로 치우친 분포입니다. 평균은 114.36이고 표준 편차는 107.81입니다.\n",
    "<br>\n",
    "<br>일반적으로 정규 분포를 따른다고 가정한다면, 비펄서 별의 DM-SNR 곡선은 평균 약 9, 높은 표준 편차 약 23, \n",
    "<br>오른쪽으로 치우친 분포 (평균 왜도 약 114)를 가질 것으로 예상되며, \n",
    "<br>약간 뾰족한 곡선과 두꺼운 꼬리를 가질 것으로 예상됩니다 (평균 초과 첨도 약 8.89)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler() \n",
    "X_trains = ss.fit_transform(X_train)\n",
    "X_tests = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(random_state=42).fit(X_trains, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_param_grid = {'C': [0.01,0.1, 1, 10],  \n",
    "              'gamma': [0.09, 0.1, 0.2, 0.001], \n",
    "              'kernel': ['rbf'],\n",
    "              'tol':[0.001,0.0001],\n",
    "              'degree':[2,3]}\n",
    "\n",
    "SVM_grid1 = GridSearchCV(SVM, param_grid = SVM_param_grid, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;degree&#x27;: [2, 3],\n",
       "                         &#x27;gamma&#x27;: [0.09, 0.1, 0.2, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;],\n",
       "                         &#x27;tol&#x27;: [0.001, 0.0001]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;degree&#x27;: [2, 3],\n",
       "                         &#x27;gamma&#x27;: [0.09, 0.1, 0.2, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;],\n",
       "                         &#x27;tol&#x27;: [0.001, 0.0001]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10], 'degree': [2, 3],\n",
       "                         'gamma': [0.09, 0.1, 0.2, 0.001], 'kernel': ['rbf'],\n",
       "                         'tol': [0.001, 0.0001]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_grid1.fit(X_trains, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, gamma=0.2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, gamma=0.2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, gamma=0.2, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, gamma=0.09, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, gamma=0.09, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, gamma=0.09, random_state=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_grid = svm.SVC(C=10,degree=2, gamma=0.09, kernel='rbf', random_state=1)\n",
    "SVM_grid.fit(X_trains, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of the training data:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     13020\n",
      "           1       0.95      0.84      0.89      1298\n",
      "\n",
      "    accuracy                           0.98     14318\n",
      "   macro avg       0.97      0.92      0.94     14318\n",
      "weighted avg       0.98      0.98      0.98     14318\n",
      " \n",
      "\n",
      "Classification Report of the test data:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3239\n",
      "           1       0.95      0.81      0.88       341\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.97      0.90      0.93      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report of the training data:\\n\\n',metrics.classification_report(y_train, SVM_grid.predict(X_trains)),'\\n')\n",
    "print('Classification Report of the test data:\\n\\n',metrics.classification_report(y_test, SVM_grid.predict(X_tests)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM best accuracy : 0.978\n"
     ]
    }
   ],
   "source": [
    "y_pred = SVM_grid.predict(X_tests)\n",
    "print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score :  0.9782122905027933\n",
      "Recall Score :  0.9782122905027933\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision Score : \",precision_score(y_test, y_pred, pos_label='positive',average='micro'))\n",
    "print(\"Recall Score : \",recall_score(y_test, y_pred, pos_label='positive',average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_grid = np.linspace(0.0,1.0,100)\n",
    "TPR = []                                                 \n",
    "FPR = []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR, TPR, cutoffs = metrics.roc_curve(y_test,y_pred,pos_label=1)      # positive label = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.plot(FPR,TPR,linewidth=1.0)\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/moonjeseong/opt/anaconda3/envs/project/lib/python3.10/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치정규화, 오버샘플링, elu, adamax, es, rlrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE를 사용하여 오버샘플링 수행\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_trains, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "87/87 [==============================] - 2s 6ms/step - loss: 0.1729 - accuracy: 0.9415 - val_loss: 0.6506 - val_accuracy: 0.6377 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9500 - val_loss: 0.4942 - val_accuracy: 0.7601 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9508 - val_loss: 0.3827 - val_accuracy: 0.8293 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9504 - val_loss: 0.2527 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9511 - val_loss: 0.1925 - val_accuracy: 0.9391 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9514 - val_loss: 0.1497 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9513 - val_loss: 0.1361 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.9510 - val_loss: 0.1490 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9523 - val_loss: 0.1350 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9518 - val_loss: 0.1103 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9520 - val_loss: 0.1328 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9519 - val_loss: 0.1189 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9517 - val_loss: 0.1117 - val_accuracy: 0.9693 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9522 - val_loss: 0.1162 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9531 - val_loss: 0.1433 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9521 - val_loss: 0.1357 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9523 - val_loss: 0.1071 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9510 - val_loss: 0.1183 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9531 - val_loss: 0.1179 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9533 - val_loss: 0.1046 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9533 - val_loss: 0.1106 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9526 - val_loss: 0.1055 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9527 - val_loss: 0.0982 - val_accuracy: 0.9751 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9528 - val_loss: 0.1165 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9540 - val_loss: 0.1148 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9541 - val_loss: 0.1174 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9537 - val_loss: 0.1131 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9535 - val_loss: 0.1259 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9536 - val_loss: 0.1056 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9538 - val_loss: 0.1272 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9547 - val_loss: 0.1317 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 0.1273 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9536 - val_loss: 0.1062 - val_accuracy: 0.9712 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9541 - val_loss: 0.1251 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9548 - val_loss: 0.1373 - val_accuracy: 0.9567 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9540 - val_loss: 0.1492 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9556 - val_loss: 0.1010 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: 0.1193 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9551 - val_loss: 0.1234 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9551 - val_loss: 0.1425 - val_accuracy: 0.9534 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9549 - val_loss: 0.1084 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9564 - val_loss: 0.1297 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9554 - val_loss: 0.1229 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9565 - val_loss: 0.1142 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9568 - val_loss: 0.1130 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9565 - val_loss: 0.1241 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9565 - val_loss: 0.1152 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9567 - val_loss: 0.1370 - val_accuracy: 0.9567 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9571 - val_loss: 0.1128 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9555 - val_loss: 0.1041 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9581 - val_loss: 0.1160 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9571 - val_loss: 0.1114 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9574 - val_loss: 0.1142 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9572 - val_loss: 0.1361 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9579 - val_loss: 0.1104 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9578 - val_loss: 0.1425 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9573 - val_loss: 0.1013 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: 0.1029 - val_accuracy: 0.9712 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9585 - val_loss: 0.1385 - val_accuracy: 0.9525 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9586 - val_loss: 0.1555 - val_accuracy: 0.9433 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9594 - val_loss: 0.1092 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9600 - val_loss: 0.1338 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.1290 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9603 - val_loss: 0.1284 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9602 - val_loss: 0.1151 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9582 - val_loss: 0.1245 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9608 - val_loss: 0.1177 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9599 - val_loss: 0.1089 - val_accuracy: 0.9707 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9601 - val_loss: 0.1068 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9602 - val_loss: 0.1062 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9596 - val_loss: 0.1106 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9602 - val_loss: 0.1216 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9595 - val_loss: 0.1244 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9617 - val_loss: 0.1133 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9608 - val_loss: 0.1331 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9611 - val_loss: 0.1071 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9605 - val_loss: 0.1001 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9619 - val_loss: 0.1134 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9614 - val_loss: 0.1244 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9623 - val_loss: 0.1054 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9627 - val_loss: 0.1139 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9618 - val_loss: 0.1175 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9623 - val_loss: 0.1088 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9623 - val_loss: 0.1048 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9632 - val_loss: 0.1176 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9632 - val_loss: 0.1158 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9636 - val_loss: 0.1210 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1312 - val_accuracy: 0.9601 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9638 - val_loss: 0.1263 - val_accuracy: 0.9603 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9638 - val_loss: 0.1173 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9645 - val_loss: 0.1109 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9635 - val_loss: 0.1240 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9639 - val_loss: 0.1111 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9642 - val_loss: 0.0998 - val_accuracy: 0.9743 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9641 - val_loss: 0.1338 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9635 - val_loss: 0.1188 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9647 - val_loss: 0.1237 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.9645 - val_loss: 0.1033 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9636 - val_loss: 0.1076 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9646 - val_loss: 0.1447 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9652 - val_loss: 0.1405 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9655 - val_loss: 0.1232 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9647 - val_loss: 0.1343 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9651 - val_loss: 0.1261 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9653 - val_loss: 0.1103 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9654 - val_loss: 0.1260 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9658 - val_loss: 0.1002 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "87/87 [==============================] - 2s 29ms/step - loss: 0.0893 - accuracy: 0.9653 - val_loss: 0.1127 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9651 - val_loss: 0.1193 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9656 - val_loss: 0.1194 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9658 - val_loss: 0.1254 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9657 - val_loss: 0.1095 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9673 - val_loss: 0.1071 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9659 - val_loss: 0.1297 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 0.0870 - accuracy: 0.9669 - val_loss: 0.1233 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9682 - val_loss: 0.1159 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.1153 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9669 - val_loss: 0.1105 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9680 - val_loss: 0.1182 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9666 - val_loss: 0.1260 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9660 - val_loss: 0.1239 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9678 - val_loss: 0.1280 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9675 - val_loss: 0.1177 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9663 - val_loss: 0.1129 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9680 - val_loss: 0.1182 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9672 - val_loss: 0.1136 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9669 - val_loss: 0.1150 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9680 - val_loss: 0.1100 - val_accuracy: 0.9707 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.9680 - val_loss: 0.1179 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9679 - val_loss: 0.1287 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9675 - val_loss: 0.1169 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9685 - val_loss: 0.1211 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9666 - val_loss: 0.1045 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9699 - val_loss: 0.1306 - val_accuracy: 0.9603 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9678 - val_loss: 0.1217 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9672 - val_loss: 0.1258 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9690 - val_loss: 0.1104 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9687 - val_loss: 0.1054 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9695 - val_loss: 0.1366 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1261 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9688 - val_loss: 0.1127 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9697 - val_loss: 0.1101 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9694 - val_loss: 0.1150 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9689 - val_loss: 0.1072 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9697 - val_loss: 0.1179 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9690 - val_loss: 0.1344 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9708 - val_loss: 0.1217 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9684 - val_loss: 0.1208 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9699 - val_loss: 0.1443 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9707 - val_loss: 0.1286 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9710 - val_loss: 0.1194 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9692 - val_loss: 0.1359 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9707 - val_loss: 0.1201 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9702 - val_loss: 0.1089 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9714 - val_loss: 0.1296 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9709 - val_loss: 0.1230 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 157/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9710 - val_loss: 0.1391 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9706 - val_loss: 0.1421 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9712 - val_loss: 0.1246 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9707 - val_loss: 0.1201 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9717 - val_loss: 0.1227 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9704 - val_loss: 0.1196 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9720 - val_loss: 0.1279 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9729 - val_loss: 0.1399 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9704 - val_loss: 0.1188 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9722 - val_loss: 0.1374 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9723 - val_loss: 0.1212 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9720 - val_loss: 0.1353 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9720 - val_loss: 0.1215 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9719 - val_loss: 0.1180 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9728 - val_loss: 0.1364 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9716 - val_loss: 0.1346 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9724 - val_loss: 0.1169 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9721 - val_loss: 0.1230 - val_accuracy: 0.9693 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9736 - val_loss: 0.1250 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9721 - val_loss: 0.1328 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9721 - val_loss: 0.1462 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9727 - val_loss: 0.1281 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9733 - val_loss: 0.1267 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9728 - val_loss: 0.1371 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9736 - val_loss: 0.1261 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9734 - val_loss: 0.1227 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9728 - val_loss: 0.1195 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9736 - val_loss: 0.1333 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9735 - val_loss: 0.1330 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9751 - val_loss: 0.1348 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9746 - val_loss: 0.1293 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9733 - val_loss: 0.1343 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9748 - val_loss: 0.1248 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9743 - val_loss: 0.1292 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 191/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9740 - val_loss: 0.1232 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 192/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9742 - val_loss: 0.1411 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 193/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9734 - val_loss: 0.1377 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 194/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9756 - val_loss: 0.1206 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 195/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9754 - val_loss: 0.1239 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 196/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9740 - val_loss: 0.1356 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 197/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9738 - val_loss: 0.1319 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 198/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9756 - val_loss: 0.1349 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 199/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9755 - val_loss: 0.1398 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 200/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9747 - val_loss: 0.1240 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 201/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9751 - val_loss: 0.1306 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 202/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9753 - val_loss: 0.1434 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 203/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.1263 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 204/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9755 - val_loss: 0.1301 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 205/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9751 - val_loss: 0.1405 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 206/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9750 - val_loss: 0.1398 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 207/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9767 - val_loss: 0.1251 - val_accuracy: 0.9707 - lr: 0.0010\n",
      "Epoch 208/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9753 - val_loss: 0.1432 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 209/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9758 - val_loss: 0.1351 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 210/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9758 - val_loss: 0.1405 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 211/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9755 - val_loss: 0.1551 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 212/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9764 - val_loss: 0.1540 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 213/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9746 - val_loss: 0.1546 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 214/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9760 - val_loss: 0.1292 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 215/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9763 - val_loss: 0.1469 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 216/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9762 - val_loss: 0.1406 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 217/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9767 - val_loss: 0.1405 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 218/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9765 - val_loss: 0.1479 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 219/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9765 - val_loss: 0.1345 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 220/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9764 - val_loss: 0.1427 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 221/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9769 - val_loss: 0.1365 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 222/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9767 - val_loss: 0.1385 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 223/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9771 - val_loss: 0.1262 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 224/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9764 - val_loss: 0.1445 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 225/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9764 - val_loss: 0.1591 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 226/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9762 - val_loss: 0.1412 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 227/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9780 - val_loss: 0.1615 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 228/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9765 - val_loss: 0.1432 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 229/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9771 - val_loss: 0.1365 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 230/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9768 - val_loss: 0.1289 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 231/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.1372 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 232/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 0.1418 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 233/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9775 - val_loss: 0.1397 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 234/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9765 - val_loss: 0.1328 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 235/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9782 - val_loss: 0.1467 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 236/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9790 - val_loss: 0.1425 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 237/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9780 - val_loss: 0.1512 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 238/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9762 - val_loss: 0.1473 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 239/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9778 - val_loss: 0.1388 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 240/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9784 - val_loss: 0.1435 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 241/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9785 - val_loss: 0.1366 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 242/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9790 - val_loss: 0.1451 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 243/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9779 - val_loss: 0.1451 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 244/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9796 - val_loss: 0.1487 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 245/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9784 - val_loss: 0.1586 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 246/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9790 - val_loss: 0.1500 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 247/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9786 - val_loss: 0.1453 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 248/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9784 - val_loss: 0.1462 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 249/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9776 - val_loss: 0.1389 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 250/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9784 - val_loss: 0.1448 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 251/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9796 - val_loss: 0.1382 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 252/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9797 - val_loss: 0.1456 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 253/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9799 - val_loss: 0.1463 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 254/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9786 - val_loss: 0.1458 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 255/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9792 - val_loss: 0.1669 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 256/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9793 - val_loss: 0.1394 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 257/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9789 - val_loss: 0.1478 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 258/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: 0.1540 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 259/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9813 - val_loss: 0.1515 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 260/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9801 - val_loss: 0.1362 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 261/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9790 - val_loss: 0.1373 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 262/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9795 - val_loss: 0.1468 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 263/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9797 - val_loss: 0.1540 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 264/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9804 - val_loss: 0.1385 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 265/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.1595 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 266/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9802 - val_loss: 0.1456 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 267/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9805 - val_loss: 0.1517 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 268/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9789 - val_loss: 0.1534 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 269/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9808 - val_loss: 0.1479 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 270/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9807 - val_loss: 0.1447 - val_accuracy: 0.9693 - lr: 0.0010\n",
      "Epoch 271/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9795 - val_loss: 0.1596 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 272/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.1430 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 273/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9811 - val_loss: 0.1515 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 274/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9813 - val_loss: 0.1577 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 275/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9798 - val_loss: 0.1551 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 276/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9808 - val_loss: 0.1635 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 277/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9806 - val_loss: 0.1523 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 278/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9813 - val_loss: 0.1796 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 279/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9806 - val_loss: 0.1532 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 280/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9806 - val_loss: 0.1565 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 281/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9802 - val_loss: 0.1506 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 282/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9811 - val_loss: 0.1536 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 283/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9806 - val_loss: 0.1474 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 284/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9803 - val_loss: 0.1569 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 285/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9812 - val_loss: 0.1599 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 286/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9805 - val_loss: 0.1532 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 287/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9814 - val_loss: 0.1471 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 288/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9816 - val_loss: 0.1511 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 289/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9803 - val_loss: 0.1580 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 290/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9815 - val_loss: 0.1511 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 291/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.1453 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 292/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9816 - val_loss: 0.1604 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 293/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9823 - val_loss: 0.1550 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 294/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9826 - val_loss: 0.1513 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 295/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9814 - val_loss: 0.1606 - val_accuracy: 0.9601 - lr: 0.0010\n",
      "Epoch 296/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9812 - val_loss: 0.1547 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 297/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9828 - val_loss: 0.1576 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 298/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9819 - val_loss: 0.1566 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 299/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9815 - val_loss: 0.1565 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 300/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9825 - val_loss: 0.1444 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "112/112 [==============================] - 0s 738us/step\n",
      "Accuracy: 0.9689944386482239\n",
      " MSE: 0.14435574412345886\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='elu', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='elu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='elu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='elu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_oversampled, y_train_oversampled, epochs=300, batch_size=300, verbose=1, \n",
    "          validation_data=(X_tests, y_test), callbacks=[es, rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_tests)\n",
    "    \n",
    "loss, accuracy = model.evaluate(X_tests, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치정규화, 클래스 가중치 부여, relu, adamax, es, rlrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m model2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m256\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_trains\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[1;32m      3\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[39m# 클래스 가중치 계산\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m class_weights \u001b[39m=\u001b[39m class_weight\u001b[39m.\u001b[39;49mcompute_class_weight(\u001b[39m'\u001b[39;49m\u001b[39mbalanced\u001b[39;49m\u001b[39m'\u001b[39;49m, np\u001b[39m.\u001b[39;49munique(y_train), y_train)\n\u001b[1;32m     15\u001b[0m class_weights \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(class_weights))\n\u001b[1;32m     17\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdamax()\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model2.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model2.fit(X_trains, y_train, epochs=500, batch_size=32, verbose=1, \n",
    "          validation_data=(X_tests, y_test), callbacks=[es, rlrp], class_weight=class_weights)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model2.predict(X_tests)\n",
    "    \n",
    "loss, accuracy = model2.evaluate(X_tests, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치정규화, relu, adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "448/448 [==============================] - 2s 2ms/step - loss: 0.2373 - accuracy: 0.9564 - val_loss: 0.1212 - val_accuracy: 0.9774\n",
      "Epoch 2/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1107 - accuracy: 0.9766 - val_loss: 0.0863 - val_accuracy: 0.9768\n",
      "Epoch 3/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0824 - accuracy: 0.9788 - val_loss: 0.0750 - val_accuracy: 0.9782\n",
      "Epoch 4/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9782 - val_loss: 0.0750 - val_accuracy: 0.9788\n",
      "Epoch 5/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9801 - val_loss: 0.0754 - val_accuracy: 0.9807\n",
      "Epoch 6/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9794 - val_loss: 0.0749 - val_accuracy: 0.9799\n",
      "Epoch 7/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0705 - accuracy: 0.9795 - val_loss: 0.0715 - val_accuracy: 0.9796\n",
      "Epoch 8/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9794 - val_loss: 0.0707 - val_accuracy: 0.9791\n",
      "Epoch 9/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0678 - accuracy: 0.9789 - val_loss: 0.0721 - val_accuracy: 0.9788\n",
      "Epoch 10/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0668 - accuracy: 0.9801 - val_loss: 0.0744 - val_accuracy: 0.9782\n",
      "Epoch 11/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9796 - val_loss: 0.0707 - val_accuracy: 0.9791\n",
      "Epoch 12/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9800 - val_loss: 0.0715 - val_accuracy: 0.9788\n",
      "Epoch 13/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.0741 - val_accuracy: 0.9785\n",
      "Epoch 14/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.0707 - val_accuracy: 0.9793\n",
      "Epoch 15/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9810 - val_loss: 0.0748 - val_accuracy: 0.9791\n",
      "Epoch 16/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0631 - accuracy: 0.9814 - val_loss: 0.0775 - val_accuracy: 0.9765\n",
      "Epoch 17/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9808 - val_loss: 0.0728 - val_accuracy: 0.9788\n",
      "Epoch 18/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9814 - val_loss: 0.0732 - val_accuracy: 0.9785\n",
      "Epoch 19/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.0735 - val_accuracy: 0.9785\n",
      "Epoch 20/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.0707 - val_accuracy: 0.9791\n",
      "Epoch 21/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.0730 - val_accuracy: 0.9793\n",
      "Epoch 22/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9814 - val_loss: 0.0763 - val_accuracy: 0.9788\n",
      "Epoch 23/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9815 - val_loss: 0.0741 - val_accuracy: 0.9779\n",
      "Epoch 24/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.0736 - val_accuracy: 0.9785\n",
      "Epoch 25/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.0737 - val_accuracy: 0.9785\n",
      "Epoch 26/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0755 - val_accuracy: 0.9785\n",
      "Epoch 27/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 0.0740 - val_accuracy: 0.9782\n",
      "Epoch 28/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0604 - accuracy: 0.9816 - val_loss: 0.0717 - val_accuracy: 0.9782\n",
      "Epoch 29/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.0731 - val_accuracy: 0.9777\n",
      "Epoch 30/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.0765 - val_accuracy: 0.9779\n",
      "Epoch 31/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9823 - val_loss: 0.0733 - val_accuracy: 0.9785\n",
      "Epoch 32/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9828 - val_loss: 0.0801 - val_accuracy: 0.9777\n",
      "Epoch 33/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.0769 - val_accuracy: 0.9785\n",
      "Epoch 34/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.0724 - val_accuracy: 0.9799\n",
      "Epoch 35/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9817 - val_loss: 0.0740 - val_accuracy: 0.9788\n",
      "Epoch 36/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.0743 - val_accuracy: 0.9788\n",
      "Epoch 37/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9818 - val_loss: 0.0737 - val_accuracy: 0.9785\n",
      "Epoch 38/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9818 - val_loss: 0.0755 - val_accuracy: 0.9788\n",
      "Epoch 39/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 0.0714 - val_accuracy: 0.9779\n",
      "Epoch 40/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0752 - val_accuracy: 0.9777\n",
      "Epoch 41/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.0735 - val_accuracy: 0.9791\n",
      "Epoch 42/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.0754 - val_accuracy: 0.9777\n",
      "Epoch 43/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0764 - val_accuracy: 0.9777\n",
      "Epoch 44/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.0746 - val_accuracy: 0.9788\n",
      "Epoch 45/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 0.0746 - val_accuracy: 0.9799\n",
      "Epoch 46/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9823 - val_loss: 0.0782 - val_accuracy: 0.9788\n",
      "Epoch 47/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0771 - val_accuracy: 0.9777\n",
      "Epoch 48/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.0873 - val_accuracy: 0.9754\n",
      "Epoch 49/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.0769 - val_accuracy: 0.9779\n",
      "Epoch 50/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.0760 - val_accuracy: 0.9782\n",
      "Epoch 51/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9825 - val_loss: 0.0773 - val_accuracy: 0.9779\n",
      "Epoch 52/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0769 - val_accuracy: 0.9802\n",
      "Epoch 53/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9830 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
      "Epoch 54/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0561 - accuracy: 0.9818 - val_loss: 0.0773 - val_accuracy: 0.9782\n",
      "Epoch 55/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0783 - val_accuracy: 0.9779\n",
      "Epoch 56/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0558 - accuracy: 0.9827 - val_loss: 0.0767 - val_accuracy: 0.9799\n",
      "Epoch 57/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.0752 - val_accuracy: 0.9785\n",
      "Epoch 58/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0558 - accuracy: 0.9825 - val_loss: 0.0794 - val_accuracy: 0.9777\n",
      "Epoch 59/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0774 - val_accuracy: 0.9779\n",
      "Epoch 60/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
      "Epoch 61/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 0.0789 - val_accuracy: 0.9791\n",
      "Epoch 62/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 0.0782 - val_accuracy: 0.9777\n",
      "Epoch 63/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.0792 - val_accuracy: 0.9768\n",
      "Epoch 64/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.0771 - val_accuracy: 0.9793\n",
      "Epoch 65/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.0800 - val_accuracy: 0.9782\n",
      "Epoch 66/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9828 - val_loss: 0.0792 - val_accuracy: 0.9791\n",
      "Epoch 67/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0822 - val_accuracy: 0.9774\n",
      "Epoch 68/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.0835 - val_accuracy: 0.9777\n",
      "Epoch 69/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0809 - val_accuracy: 0.9782\n",
      "Epoch 70/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.0826 - val_accuracy: 0.9779\n",
      "Epoch 71/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.0839 - val_accuracy: 0.9774\n",
      "Epoch 72/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0815 - val_accuracy: 0.9791\n",
      "Epoch 73/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0791 - val_accuracy: 0.9782\n",
      "Epoch 74/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0813 - val_accuracy: 0.9788\n",
      "Epoch 75/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0513 - accuracy: 0.9835 - val_loss: 0.0801 - val_accuracy: 0.9791\n",
      "Epoch 76/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.0849 - val_accuracy: 0.9763\n",
      "Epoch 77/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0853 - val_accuracy: 0.9771\n",
      "Epoch 78/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0527 - accuracy: 0.9831 - val_loss: 0.0820 - val_accuracy: 0.9785\n",
      "Epoch 79/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.0830 - val_accuracy: 0.9791\n",
      "Epoch 80/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.0845 - val_accuracy: 0.9779\n",
      "Epoch 81/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0851 - val_accuracy: 0.9785\n",
      "Epoch 82/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.0905 - val_accuracy: 0.9774\n",
      "Epoch 83/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.0826 - val_accuracy: 0.9779\n",
      "Epoch 84/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.0850 - val_accuracy: 0.9791\n",
      "Epoch 85/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.0860 - val_accuracy: 0.9788\n",
      "Epoch 86/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0500 - accuracy: 0.9838 - val_loss: 0.0840 - val_accuracy: 0.9771\n",
      "Epoch 87/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 0.0838 - val_accuracy: 0.9782\n",
      "Epoch 88/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.0839 - val_accuracy: 0.9774\n",
      "Epoch 89/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 0.0880 - val_accuracy: 0.9763\n",
      "Epoch 90/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 0.0864 - val_accuracy: 0.9777\n",
      "Epoch 91/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0847 - val_accuracy: 0.9799\n",
      "Epoch 92/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0496 - accuracy: 0.9835 - val_loss: 0.0864 - val_accuracy: 0.9785\n",
      "Epoch 93/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.0872 - val_accuracy: 0.9779\n",
      "Epoch 94/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 0.0871 - val_accuracy: 0.9782\n",
      "Epoch 95/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.0884 - val_accuracy: 0.9779\n",
      "Epoch 96/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.0865 - val_accuracy: 0.9782\n",
      "Epoch 97/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.0896 - val_accuracy: 0.9763\n",
      "Epoch 98/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0926 - val_accuracy: 0.9777\n",
      "Epoch 99/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.0871 - val_accuracy: 0.9785\n",
      "Epoch 100/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.0862 - val_accuracy: 0.9777\n",
      "Epoch 101/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.0888 - val_accuracy: 0.9779\n",
      "Epoch 102/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 0.0895 - val_accuracy: 0.9788\n",
      "Epoch 103/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0896 - val_accuracy: 0.9771\n",
      "Epoch 104/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0927 - val_accuracy: 0.9768\n",
      "Epoch 105/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
      "Epoch 106/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0993 - val_accuracy: 0.9765\n",
      "Epoch 107/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9846 - val_loss: 0.0903 - val_accuracy: 0.9768\n",
      "Epoch 108/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0471 - accuracy: 0.9839 - val_loss: 0.0888 - val_accuracy: 0.9791\n",
      "Epoch 109/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.0920 - val_accuracy: 0.9768\n",
      "Epoch 110/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 0.0926 - val_accuracy: 0.9777\n",
      "Epoch 111/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.0897 - val_accuracy: 0.9760\n",
      "Epoch 112/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0929 - val_accuracy: 0.9760\n",
      "Epoch 113/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.0919 - val_accuracy: 0.9757\n",
      "Epoch 114/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.0933 - val_accuracy: 0.9765\n",
      "Epoch 115/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.0912 - val_accuracy: 0.9754\n",
      "Epoch 116/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0944 - val_accuracy: 0.9771\n",
      "Epoch 117/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.0917 - val_accuracy: 0.9768\n",
      "Epoch 118/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0979 - val_accuracy: 0.9782\n",
      "Epoch 119/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.0969 - val_accuracy: 0.9774\n",
      "Epoch 120/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.0965 - val_accuracy: 0.9765\n",
      "Epoch 121/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9848 - val_loss: 0.0943 - val_accuracy: 0.9760\n",
      "Epoch 122/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.0941 - val_accuracy: 0.9768\n",
      "Epoch 123/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.0974 - val_accuracy: 0.9774\n",
      "Epoch 124/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0418 - accuracy: 0.9867 - val_loss: 0.0987 - val_accuracy: 0.9765\n",
      "Epoch 125/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0979 - val_accuracy: 0.9754\n",
      "Epoch 126/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 0.0946 - val_accuracy: 0.9771\n",
      "Epoch 127/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0980 - val_accuracy: 0.9763\n",
      "Epoch 128/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0985 - val_accuracy: 0.9782\n",
      "Epoch 129/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.0995 - val_accuracy: 0.9746\n",
      "Epoch 130/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9859 - val_loss: 0.1006 - val_accuracy: 0.9768\n",
      "Epoch 131/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0985 - val_accuracy: 0.9774\n",
      "Epoch 132/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.0920 - val_accuracy: 0.9763\n",
      "Epoch 133/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.0987 - val_accuracy: 0.9774\n",
      "Epoch 134/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.0926 - val_accuracy: 0.9782\n",
      "Epoch 135/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9867 - val_loss: 0.0955 - val_accuracy: 0.9757\n",
      "Epoch 136/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.0948 - val_accuracy: 0.9760\n",
      "Epoch 137/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.0953 - val_accuracy: 0.9777\n",
      "Epoch 138/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 0.0943 - val_accuracy: 0.9774\n",
      "Epoch 139/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0420 - accuracy: 0.9862 - val_loss: 0.0928 - val_accuracy: 0.9779\n",
      "Epoch 140/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0432 - accuracy: 0.9865 - val_loss: 0.1010 - val_accuracy: 0.9754\n",
      "Epoch 141/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 0.1011 - val_accuracy: 0.9765\n",
      "Epoch 142/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0431 - accuracy: 0.9852 - val_loss: 0.1035 - val_accuracy: 0.9749\n",
      "Epoch 143/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0987 - val_accuracy: 0.9763\n",
      "Epoch 144/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.0986 - val_accuracy: 0.9771\n",
      "Epoch 145/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.1005 - val_accuracy: 0.9768\n",
      "Epoch 146/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.1019 - val_accuracy: 0.9757\n",
      "Epoch 147/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0992 - val_accuracy: 0.9771\n",
      "Epoch 148/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9869 - val_loss: 0.1029 - val_accuracy: 0.9760\n",
      "Epoch 149/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.1007 - val_accuracy: 0.9763\n",
      "Epoch 150/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.1045 - val_accuracy: 0.9771\n",
      "Epoch 151/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.1034 - val_accuracy: 0.9757\n",
      "Epoch 152/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.9857 - val_loss: 0.1022 - val_accuracy: 0.9765\n",
      "Epoch 153/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9862 - val_loss: 0.1018 - val_accuracy: 0.9768\n",
      "Epoch 154/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.1062 - val_accuracy: 0.9743\n",
      "Epoch 155/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.1037 - val_accuracy: 0.9774\n",
      "Epoch 156/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.1031 - val_accuracy: 0.9779\n",
      "Epoch 157/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.1023 - val_accuracy: 0.9765\n",
      "Epoch 158/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0993 - val_accuracy: 0.9779\n",
      "Epoch 159/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 0.1004 - val_accuracy: 0.9763\n",
      "Epoch 160/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.1064 - val_accuracy: 0.9763\n",
      "Epoch 161/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.1060 - val_accuracy: 0.9768\n",
      "Epoch 162/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.1055 - val_accuracy: 0.9765\n",
      "Epoch 163/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1110 - val_accuracy: 0.9765\n",
      "Epoch 164/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.1028 - val_accuracy: 0.9771\n",
      "Epoch 165/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9871 - val_loss: 0.1077 - val_accuracy: 0.9788\n",
      "Epoch 166/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.1020 - val_accuracy: 0.9777\n",
      "Epoch 167/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 0.1044 - val_accuracy: 0.9763\n",
      "Epoch 168/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.1035 - val_accuracy: 0.9763\n",
      "Epoch 169/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0385 - accuracy: 0.9867 - val_loss: 0.0986 - val_accuracy: 0.9771\n",
      "Epoch 170/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.1040 - val_accuracy: 0.9763\n",
      "Epoch 171/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.1056 - val_accuracy: 0.9760\n",
      "Epoch 172/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.1051 - val_accuracy: 0.9754\n",
      "Epoch 173/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9873 - val_loss: 0.1122 - val_accuracy: 0.9740\n",
      "Epoch 174/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.1069 - val_accuracy: 0.9777\n",
      "Epoch 175/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.1126 - val_accuracy: 0.9751\n",
      "Epoch 176/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.1107 - val_accuracy: 0.9768\n",
      "Epoch 177/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.1130 - val_accuracy: 0.9757\n",
      "Epoch 178/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.1117 - val_accuracy: 0.9743\n",
      "Epoch 179/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.1046 - val_accuracy: 0.9774\n",
      "Epoch 180/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.1102 - val_accuracy: 0.9779\n",
      "Epoch 181/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 0.1143 - val_accuracy: 0.9751\n",
      "Epoch 182/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 0.1072 - val_accuracy: 0.9774\n",
      "Epoch 183/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.1050 - val_accuracy: 0.9763\n",
      "Epoch 184/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0366 - accuracy: 0.9870 - val_loss: 0.1098 - val_accuracy: 0.9757\n",
      "Epoch 185/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0369 - accuracy: 0.9874 - val_loss: 0.1064 - val_accuracy: 0.9768\n",
      "Epoch 186/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.1050 - val_accuracy: 0.9765\n",
      "Epoch 187/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.1023 - val_accuracy: 0.9777\n",
      "Epoch 188/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0368 - accuracy: 0.9876 - val_loss: 0.1081 - val_accuracy: 0.9765\n",
      "Epoch 189/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.1085 - val_accuracy: 0.9763\n",
      "Epoch 190/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.1071 - val_accuracy: 0.9771\n",
      "Epoch 191/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.1076 - val_accuracy: 0.9774\n",
      "Epoch 192/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.1062 - val_accuracy: 0.9771\n",
      "Epoch 193/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.1111 - val_accuracy: 0.9779\n",
      "Epoch 194/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.1121 - val_accuracy: 0.9743\n",
      "Epoch 195/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.1067 - val_accuracy: 0.9771\n",
      "Epoch 196/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1073 - val_accuracy: 0.9751\n",
      "Epoch 197/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.1157 - val_accuracy: 0.9771\n",
      "Epoch 198/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.1133 - val_accuracy: 0.9754\n",
      "Epoch 199/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0351 - accuracy: 0.9881 - val_loss: 0.1099 - val_accuracy: 0.9768\n",
      "Epoch 200/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.1131 - val_accuracy: 0.9779\n",
      "Epoch 201/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.1072 - val_accuracy: 0.9774\n",
      "Epoch 202/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.1059 - val_accuracy: 0.9774\n",
      "Epoch 203/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.1119 - val_accuracy: 0.9760\n",
      "Epoch 204/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.1079 - val_accuracy: 0.9788\n",
      "Epoch 205/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.1029 - val_accuracy: 0.9782\n",
      "Epoch 206/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.1093 - val_accuracy: 0.9788\n",
      "Epoch 207/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.1085 - val_accuracy: 0.9777\n",
      "Epoch 208/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.1032 - val_accuracy: 0.9771\n",
      "Epoch 209/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0354 - accuracy: 0.9874 - val_loss: 0.1053 - val_accuracy: 0.9774\n",
      "Epoch 210/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.1084 - val_accuracy: 0.9779\n",
      "Epoch 211/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0349 - accuracy: 0.9876 - val_loss: 0.1090 - val_accuracy: 0.9760\n",
      "Epoch 212/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.1133 - val_accuracy: 0.9765\n",
      "Epoch 213/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.1132 - val_accuracy: 0.9743\n",
      "Epoch 214/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0355 - accuracy: 0.9871 - val_loss: 0.1116 - val_accuracy: 0.9754\n",
      "Epoch 215/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0352 - accuracy: 0.9879 - val_loss: 0.1144 - val_accuracy: 0.9737\n",
      "Epoch 216/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.1128 - val_accuracy: 0.9746\n",
      "Epoch 217/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.1099 - val_accuracy: 0.9771\n",
      "Epoch 218/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.1142 - val_accuracy: 0.9763\n",
      "Epoch 219/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.1129 - val_accuracy: 0.9760\n",
      "Epoch 220/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.1156 - val_accuracy: 0.9774\n",
      "Epoch 221/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 0.1198 - val_accuracy: 0.9757\n",
      "Epoch 222/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.1106 - val_accuracy: 0.9754\n",
      "Epoch 223/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.1179 - val_accuracy: 0.9763\n",
      "Epoch 224/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.1196 - val_accuracy: 0.9754\n",
      "Epoch 225/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9886 - val_loss: 0.1123 - val_accuracy: 0.9771\n",
      "Epoch 226/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9882 - val_loss: 0.1193 - val_accuracy: 0.9760\n",
      "Epoch 227/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.1167 - val_accuracy: 0.9760\n",
      "Epoch 228/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9894 - val_loss: 0.1178 - val_accuracy: 0.9768\n",
      "Epoch 229/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9888 - val_loss: 0.1162 - val_accuracy: 0.9774\n",
      "Epoch 230/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.1225 - val_accuracy: 0.9768\n",
      "Epoch 231/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.1223 - val_accuracy: 0.9763\n",
      "Epoch 232/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.1230 - val_accuracy: 0.9740\n",
      "Epoch 233/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 0.1188 - val_accuracy: 0.9749\n",
      "Epoch 234/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.1165 - val_accuracy: 0.9774\n",
      "Epoch 235/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.1136 - val_accuracy: 0.9763\n",
      "Epoch 236/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.1174 - val_accuracy: 0.9763\n",
      "Epoch 237/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.1146 - val_accuracy: 0.9757\n",
      "Epoch 238/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.1119 - val_accuracy: 0.9771\n",
      "Epoch 239/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9888 - val_loss: 0.1161 - val_accuracy: 0.9751\n",
      "Epoch 240/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.1208 - val_accuracy: 0.9732\n",
      "Epoch 241/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9886 - val_loss: 0.1176 - val_accuracy: 0.9771\n",
      "Epoch 242/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.1253 - val_accuracy: 0.9765\n",
      "Epoch 243/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.1244 - val_accuracy: 0.9751\n",
      "Epoch 244/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 0.1184 - val_accuracy: 0.9754\n",
      "Epoch 245/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.1173 - val_accuracy: 0.9765\n",
      "Epoch 246/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.1193 - val_accuracy: 0.9777\n",
      "Epoch 247/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.1166 - val_accuracy: 0.9760\n",
      "Epoch 248/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.1213 - val_accuracy: 0.9757\n",
      "Epoch 249/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.1240 - val_accuracy: 0.9723\n",
      "Epoch 250/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9883 - val_loss: 0.1198 - val_accuracy: 0.9760\n",
      "Epoch 251/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.1196 - val_accuracy: 0.9757\n",
      "Epoch 252/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.1190 - val_accuracy: 0.9760\n",
      "Epoch 253/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.1134 - val_accuracy: 0.9746\n",
      "Epoch 254/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.1164 - val_accuracy: 0.9760\n",
      "Epoch 255/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9890 - val_loss: 0.1210 - val_accuracy: 0.9757\n",
      "Epoch 256/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.1165 - val_accuracy: 0.9763\n",
      "Epoch 257/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0296 - accuracy: 0.9889 - val_loss: 0.1142 - val_accuracy: 0.9774\n",
      "Epoch 258/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.1147 - val_accuracy: 0.9777\n",
      "Epoch 259/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.1218 - val_accuracy: 0.9749\n",
      "Epoch 260/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0301 - accuracy: 0.9892 - val_loss: 0.1202 - val_accuracy: 0.9754\n",
      "Epoch 261/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.1173 - val_accuracy: 0.9779\n",
      "Epoch 262/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1189 - val_accuracy: 0.9765\n",
      "Epoch 263/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.1181 - val_accuracy: 0.9760\n",
      "Epoch 264/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.1199 - val_accuracy: 0.9765\n",
      "Epoch 265/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9892 - val_loss: 0.1226 - val_accuracy: 0.9763\n",
      "Epoch 266/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9891 - val_loss: 0.1208 - val_accuracy: 0.9763\n",
      "Epoch 267/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.1180 - val_accuracy: 0.9746\n",
      "Epoch 268/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.1257 - val_accuracy: 0.9757\n",
      "Epoch 269/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.1208 - val_accuracy: 0.9757\n",
      "Epoch 270/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.1231 - val_accuracy: 0.9740\n",
      "Epoch 271/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9892 - val_loss: 0.1171 - val_accuracy: 0.9777\n",
      "Epoch 272/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.1168 - val_accuracy: 0.9765\n",
      "Epoch 273/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.1249 - val_accuracy: 0.9760\n",
      "Epoch 274/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.1132 - val_accuracy: 0.9763\n",
      "Epoch 275/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 0.1209 - val_accuracy: 0.9737\n",
      "Epoch 276/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.1161 - val_accuracy: 0.9763\n",
      "Epoch 277/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.1227 - val_accuracy: 0.9771\n",
      "Epoch 278/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.1223 - val_accuracy: 0.9768\n",
      "Epoch 279/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 280/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.1119 - val_accuracy: 0.9765\n",
      "Epoch 281/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.1256 - val_accuracy: 0.9743\n",
      "Epoch 282/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9904 - val_loss: 0.1233 - val_accuracy: 0.9743\n",
      "Epoch 283/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.1255 - val_accuracy: 0.9779\n",
      "Epoch 284/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.1286 - val_accuracy: 0.9751\n",
      "Epoch 285/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.1182 - val_accuracy: 0.9754\n",
      "Epoch 286/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.1209 - val_accuracy: 0.9751\n",
      "Epoch 287/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.1245 - val_accuracy: 0.9765\n",
      "Epoch 288/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9901 - val_loss: 0.1217 - val_accuracy: 0.9757\n",
      "Epoch 289/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.1231 - val_accuracy: 0.9765\n",
      "Epoch 290/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.1264 - val_accuracy: 0.9763\n",
      "Epoch 291/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9897 - val_loss: 0.1221 - val_accuracy: 0.9763\n",
      "Epoch 292/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.1228 - val_accuracy: 0.9765\n",
      "Epoch 293/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.1238 - val_accuracy: 0.9774\n",
      "Epoch 294/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.1263 - val_accuracy: 0.9760\n",
      "Epoch 295/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.1221 - val_accuracy: 0.9771\n",
      "Epoch 296/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.1175 - val_accuracy: 0.9749\n",
      "Epoch 297/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.1315 - val_accuracy: 0.9763\n",
      "Epoch 298/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.1187 - val_accuracy: 0.9777\n",
      "Epoch 299/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.1226 - val_accuracy: 0.9754\n",
      "Epoch 300/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.1228 - val_accuracy: 0.9771\n",
      "Epoch 301/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.1226 - val_accuracy: 0.9737\n",
      "Epoch 302/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.1225 - val_accuracy: 0.9768\n",
      "Epoch 303/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.1230 - val_accuracy: 0.9740\n",
      "Epoch 304/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.1178 - val_accuracy: 0.9765\n",
      "Epoch 305/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.1208 - val_accuracy: 0.9757\n",
      "Epoch 306/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.1247 - val_accuracy: 0.9763\n",
      "Epoch 307/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.1294 - val_accuracy: 0.9746\n",
      "Epoch 308/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.1293 - val_accuracy: 0.9746\n",
      "Epoch 309/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.1259 - val_accuracy: 0.9754\n",
      "Epoch 310/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.1265 - val_accuracy: 0.9760\n",
      "Epoch 311/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 0.1305 - val_accuracy: 0.9760\n",
      "Epoch 312/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.1347 - val_accuracy: 0.9737\n",
      "Epoch 313/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.1274 - val_accuracy: 0.9749\n",
      "Epoch 314/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.1240 - val_accuracy: 0.9771\n",
      "Epoch 315/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.1300 - val_accuracy: 0.9743\n",
      "Epoch 316/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9898 - val_loss: 0.1247 - val_accuracy: 0.9765\n",
      "Epoch 317/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.1284 - val_accuracy: 0.9760\n",
      "Epoch 318/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.1301 - val_accuracy: 0.9749\n",
      "Epoch 319/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1233 - val_accuracy: 0.9768\n",
      "Epoch 320/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.1225 - val_accuracy: 0.9763\n",
      "Epoch 321/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.1308 - val_accuracy: 0.9774\n",
      "Epoch 322/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.1264 - val_accuracy: 0.9788\n",
      "Epoch 323/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.1263 - val_accuracy: 0.9768\n",
      "Epoch 324/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.1305 - val_accuracy: 0.9749\n",
      "Epoch 325/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.1276 - val_accuracy: 0.9740\n",
      "Epoch 326/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.1280 - val_accuracy: 0.9729\n",
      "Epoch 327/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.1277 - val_accuracy: 0.9754\n",
      "Epoch 328/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.1261 - val_accuracy: 0.9754\n",
      "Epoch 329/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.1257 - val_accuracy: 0.9768\n",
      "Epoch 330/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.1293 - val_accuracy: 0.9749\n",
      "Epoch 331/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.1314 - val_accuracy: 0.9749\n",
      "Epoch 332/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.1355 - val_accuracy: 0.9712\n",
      "Epoch 333/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.1280 - val_accuracy: 0.9749\n",
      "Epoch 334/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.1304 - val_accuracy: 0.9763\n",
      "Epoch 335/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.1273 - val_accuracy: 0.9754\n",
      "Epoch 336/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.1243 - val_accuracy: 0.9765\n",
      "Epoch 337/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.1301 - val_accuracy: 0.9754\n",
      "Epoch 338/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 0.1356 - val_accuracy: 0.9740\n",
      "Epoch 339/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.1271 - val_accuracy: 0.9768\n",
      "Epoch 340/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.1386 - val_accuracy: 0.9718\n",
      "Epoch 341/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.1291 - val_accuracy: 0.9735\n",
      "Epoch 342/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.1292 - val_accuracy: 0.9768\n",
      "Epoch 343/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.1337 - val_accuracy: 0.9768\n",
      "Epoch 344/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.1411 - val_accuracy: 0.9729\n",
      "Epoch 345/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9903 - val_loss: 0.1355 - val_accuracy: 0.9757\n",
      "Epoch 346/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.1332 - val_accuracy: 0.9749\n",
      "Epoch 347/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.1360 - val_accuracy: 0.9751\n",
      "Epoch 348/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.1335 - val_accuracy: 0.9765\n",
      "Epoch 349/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.1430 - val_accuracy: 0.9729\n",
      "Epoch 350/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.1404 - val_accuracy: 0.9737\n",
      "Epoch 351/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.1337 - val_accuracy: 0.9732\n",
      "Epoch 352/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.1384 - val_accuracy: 0.9774\n",
      "Epoch 353/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.1438 - val_accuracy: 0.9746\n",
      "Epoch 354/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.1437 - val_accuracy: 0.9746\n",
      "Epoch 355/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.1390 - val_accuracy: 0.9749\n",
      "Epoch 356/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.1411 - val_accuracy: 0.9751\n",
      "Epoch 357/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.1363 - val_accuracy: 0.9746\n",
      "Epoch 358/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.1473 - val_accuracy: 0.9763\n",
      "Epoch 359/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.1381 - val_accuracy: 0.9765\n",
      "Epoch 360/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.1497 - val_accuracy: 0.9740\n",
      "Epoch 361/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.1381 - val_accuracy: 0.9768\n",
      "Epoch 362/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9919 - val_loss: 0.1360 - val_accuracy: 0.9754\n",
      "Epoch 363/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.1407 - val_accuracy: 0.9749\n",
      "Epoch 364/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.1310 - val_accuracy: 0.9774\n",
      "Epoch 365/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.1303 - val_accuracy: 0.9760\n",
      "Epoch 366/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.1348 - val_accuracy: 0.9746\n",
      "Epoch 367/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.1405 - val_accuracy: 0.9740\n",
      "Epoch 368/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.1398 - val_accuracy: 0.9746\n",
      "Epoch 369/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 0.1385 - val_accuracy: 0.9760\n",
      "Epoch 370/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.1353 - val_accuracy: 0.9763\n",
      "Epoch 371/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.1370 - val_accuracy: 0.9732\n",
      "Epoch 372/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.1451 - val_accuracy: 0.9723\n",
      "Epoch 373/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.1397 - val_accuracy: 0.9751\n",
      "Epoch 374/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.1336 - val_accuracy: 0.9746\n",
      "Epoch 375/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.1466 - val_accuracy: 0.9735\n",
      "Epoch 376/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.1432 - val_accuracy: 0.9746\n",
      "Epoch 377/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.1400 - val_accuracy: 0.9749\n",
      "Epoch 378/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.1400 - val_accuracy: 0.9763\n",
      "Epoch 379/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.1430 - val_accuracy: 0.9737\n",
      "Epoch 380/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.1416 - val_accuracy: 0.9751\n",
      "Epoch 381/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.1408 - val_accuracy: 0.9749\n",
      "Epoch 382/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1402 - val_accuracy: 0.9737\n",
      "Epoch 383/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9918 - val_loss: 0.1400 - val_accuracy: 0.9760\n",
      "Epoch 384/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.1439 - val_accuracy: 0.9746\n",
      "Epoch 385/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.1412 - val_accuracy: 0.9757\n",
      "Epoch 386/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.1391 - val_accuracy: 0.9737\n",
      "Epoch 387/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 0.1434 - val_accuracy: 0.9751\n",
      "Epoch 388/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.1490 - val_accuracy: 0.9751\n",
      "Epoch 389/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.1500 - val_accuracy: 0.9735\n",
      "Epoch 390/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.1402 - val_accuracy: 0.9765\n",
      "Epoch 391/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.1443 - val_accuracy: 0.9743\n",
      "Epoch 392/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.1440 - val_accuracy: 0.9765\n",
      "Epoch 393/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.1470 - val_accuracy: 0.9749\n",
      "Epoch 394/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1482 - val_accuracy: 0.9746\n",
      "Epoch 395/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.1429 - val_accuracy: 0.9751\n",
      "Epoch 396/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.1485 - val_accuracy: 0.9743\n",
      "Epoch 397/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.1434 - val_accuracy: 0.9751\n",
      "Epoch 398/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.1471 - val_accuracy: 0.9735\n",
      "Epoch 399/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.1483 - val_accuracy: 0.9746\n",
      "Epoch 400/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.1507 - val_accuracy: 0.9743\n",
      "Epoch 401/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.1407 - val_accuracy: 0.9732\n",
      "Epoch 402/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1463 - val_accuracy: 0.9718\n",
      "Epoch 403/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.1562 - val_accuracy: 0.9735\n",
      "Epoch 404/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.1596 - val_accuracy: 0.9765\n",
      "Epoch 405/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.1498 - val_accuracy: 0.9754\n",
      "Epoch 406/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.1546 - val_accuracy: 0.9735\n",
      "Epoch 407/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9735\n",
      "Epoch 408/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.1507 - val_accuracy: 0.9729\n",
      "Epoch 409/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9914 - val_loss: 0.1499 - val_accuracy: 0.9751\n",
      "Epoch 410/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.1451 - val_accuracy: 0.9735\n",
      "Epoch 411/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.1418 - val_accuracy: 0.9740\n",
      "Epoch 412/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.1448 - val_accuracy: 0.9757\n",
      "Epoch 413/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1448 - val_accuracy: 0.9757\n",
      "Epoch 414/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.1418 - val_accuracy: 0.9746\n",
      "Epoch 415/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.1431 - val_accuracy: 0.9740\n",
      "Epoch 416/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.1384 - val_accuracy: 0.9765\n",
      "Epoch 417/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9922 - val_loss: 0.1396 - val_accuracy: 0.9746\n",
      "Epoch 418/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 0.1431 - val_accuracy: 0.9732\n",
      "Epoch 419/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.1401 - val_accuracy: 0.9757\n",
      "Epoch 420/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.1442 - val_accuracy: 0.9760\n",
      "Epoch 421/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.1432 - val_accuracy: 0.9743\n",
      "Epoch 422/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9917 - val_loss: 0.1662 - val_accuracy: 0.9715\n",
      "Epoch 423/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.1505 - val_accuracy: 0.9746\n",
      "Epoch 424/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 0.1621 - val_accuracy: 0.9701\n",
      "Epoch 425/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.1503 - val_accuracy: 0.9740\n",
      "Epoch 426/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.1493 - val_accuracy: 0.9723\n",
      "Epoch 427/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.1465 - val_accuracy: 0.9751\n",
      "Epoch 428/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.1494 - val_accuracy: 0.9743\n",
      "Epoch 429/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.1484 - val_accuracy: 0.9749\n",
      "Epoch 430/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.1507 - val_accuracy: 0.9735\n",
      "Epoch 431/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.1506 - val_accuracy: 0.9740\n",
      "Epoch 432/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.1495 - val_accuracy: 0.9749\n",
      "Epoch 433/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.1470 - val_accuracy: 0.9754\n",
      "Epoch 434/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.1575 - val_accuracy: 0.9723\n",
      "Epoch 435/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.1452 - val_accuracy: 0.9760\n",
      "Epoch 436/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.1500 - val_accuracy: 0.9740\n",
      "Epoch 437/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.1490 - val_accuracy: 0.9749\n",
      "Epoch 438/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.1493 - val_accuracy: 0.9737\n",
      "Epoch 439/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.1510 - val_accuracy: 0.9746\n",
      "Epoch 440/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.1470 - val_accuracy: 0.9763\n",
      "Epoch 441/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.1590 - val_accuracy: 0.9746\n",
      "Epoch 442/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.1528 - val_accuracy: 0.9735\n",
      "Epoch 443/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.1563 - val_accuracy: 0.9746\n",
      "Epoch 444/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.1489 - val_accuracy: 0.9743\n",
      "Epoch 445/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.1581 - val_accuracy: 0.9715\n",
      "Epoch 446/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.1481 - val_accuracy: 0.9735\n",
      "Epoch 447/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.1528 - val_accuracy: 0.9743\n",
      "Epoch 448/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9923 - val_loss: 0.1499 - val_accuracy: 0.9735\n",
      "Epoch 449/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.1576 - val_accuracy: 0.9746\n",
      "Epoch 450/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.1463 - val_accuracy: 0.9751\n",
      "Epoch 451/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.1405 - val_accuracy: 0.9749\n",
      "Epoch 452/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.1435 - val_accuracy: 0.9749\n",
      "Epoch 453/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.1449 - val_accuracy: 0.9749\n",
      "Epoch 454/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.1584 - val_accuracy: 0.9740\n",
      "Epoch 455/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.1490 - val_accuracy: 0.9732\n",
      "Epoch 456/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.1414 - val_accuracy: 0.9757\n",
      "Epoch 457/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.1505 - val_accuracy: 0.9751\n",
      "Epoch 458/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.1473 - val_accuracy: 0.9743\n",
      "Epoch 459/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.1426 - val_accuracy: 0.9751\n",
      "Epoch 460/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.1442 - val_accuracy: 0.9751\n",
      "Epoch 461/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.1528 - val_accuracy: 0.9763\n",
      "Epoch 462/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.1564 - val_accuracy: 0.9749\n",
      "Epoch 463/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.1489 - val_accuracy: 0.9746\n",
      "Epoch 464/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.1488 - val_accuracy: 0.9754\n",
      "Epoch 465/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.1552 - val_accuracy: 0.9737\n",
      "Epoch 466/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.1439 - val_accuracy: 0.9768\n",
      "Epoch 467/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.1479 - val_accuracy: 0.9735\n",
      "Epoch 468/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.1467 - val_accuracy: 0.9754\n",
      "Epoch 469/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.1489 - val_accuracy: 0.9749\n",
      "Epoch 470/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.1508 - val_accuracy: 0.9751\n",
      "Epoch 471/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.1486 - val_accuracy: 0.9749\n",
      "Epoch 472/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.1598 - val_accuracy: 0.9726\n",
      "Epoch 473/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.1456 - val_accuracy: 0.9757\n",
      "Epoch 474/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0171 - accuracy: 0.9936 - val_loss: 0.1593 - val_accuracy: 0.9749\n",
      "Epoch 475/500\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.1552 - val_accuracy: 0.9771\n",
      "Epoch 476/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.1496 - val_accuracy: 0.9757\n",
      "Epoch 477/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.1565 - val_accuracy: 0.9746\n",
      "Epoch 478/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.1489 - val_accuracy: 0.9754\n",
      "Epoch 479/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.1522 - val_accuracy: 0.9740\n",
      "Epoch 480/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 0.1508 - val_accuracy: 0.9760\n",
      "Epoch 481/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.1473 - val_accuracy: 0.9746\n",
      "Epoch 482/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.1570 - val_accuracy: 0.9740\n",
      "Epoch 483/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.1569 - val_accuracy: 0.9743\n",
      "Epoch 484/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.1587 - val_accuracy: 0.9735\n",
      "Epoch 485/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1544 - val_accuracy: 0.9743\n",
      "Epoch 486/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.1579 - val_accuracy: 0.9732\n",
      "Epoch 487/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.1668 - val_accuracy: 0.9740\n",
      "Epoch 488/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.1649 - val_accuracy: 0.9735\n",
      "Epoch 489/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 0.1582 - val_accuracy: 0.9751\n",
      "Epoch 490/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9934 - val_loss: 0.1601 - val_accuracy: 0.9751\n",
      "Epoch 491/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9926 - val_loss: 0.1580 - val_accuracy: 0.9754\n",
      "Epoch 492/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.1553 - val_accuracy: 0.9743\n",
      "Epoch 493/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.1583 - val_accuracy: 0.9737\n",
      "Epoch 494/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.1570 - val_accuracy: 0.9760\n",
      "Epoch 495/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.1640 - val_accuracy: 0.9754\n",
      "Epoch 496/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1623 - val_accuracy: 0.9743\n",
      "Epoch 497/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.1590 - val_accuracy: 0.9737\n",
      "Epoch 498/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.1570 - val_accuracy: 0.9749\n",
      "Epoch 499/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.1573 - val_accuracy: 0.9754\n",
      "Epoch 500/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 0.1561 - val_accuracy: 0.9751\n",
      "Accuracy: 0.9751396775245667\n",
      " MSE: 0.15605786442756653\n"
     ]
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model3.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model3.fit(X_trains, y_train, epochs=500, batch_size=32, verbose=1, \n",
    "          validation_data=(X_tests, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model3.predict(X_tests)\n",
    "    \n",
    "loss, accuracy = model3.evaluate(X_tests, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "448/448 [==============================] - 2s 2ms/step - loss: 15.0536 - accuracy: 0.8788 - val_loss: 6.1301 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.7117 - accuracy: 0.9621 - val_loss: 2.2265 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6249 - accuracy: 0.9645 - val_loss: 1.1673 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.9315 - accuracy: 0.9642 - val_loss: 0.7164 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.9687 - val_loss: 0.4847 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "224/448 [==============>...............] - ETA: 0s - loss: 0.4405 - accuracy: 0.9700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m rlrp \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model4\u001b[39m.\u001b[39;49mfit(X_trains, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m     26\u001b[0m           validation_data\u001b[39m=\u001b[39;49m(X_tests, y_test), callbacks\u001b[39m=\u001b[39;49m[es, rlrp])\n\u001b[1;32m     28\u001b[0m \u001b[39m# 모델 평가\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[39m=\u001b[39m model4\u001b[39m.\u001b[39mpredict(X_tests)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     hook(batch, logs)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/callbacks.py:1171\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseen, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/utils/generic_utils.py:297\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m         info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m info\n\u001b[0;32m--> 297\u001b[0m     io_utils\u001b[39m.\u001b[39;49mprint_msg(message, line_break\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    298\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/keras/utils/io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(message)\n\u001b[0;32m---> 80\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     logging\u001b[39m.\u001b[39minfo(message)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/site-packages/ipykernel/iostream.py:526\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(evt\u001b[39m.\u001b[39mset)\n\u001b[1;32m    525\u001b[0m     \u001b[39m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflush_timeout):\n\u001b[1;32m    527\u001b[0m         \u001b[39m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    528\u001b[0m         \u001b[39m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIOStream.flush timed out\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39m__stderr__)\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout 추가\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout 추가\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model4.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='val_loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model4.fit(X_trains, y_train, epochs=500, batch_size=32, verbose=1, \n",
    "          validation_data=(X_tests, y_test), callbacks=[es, rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model4.predict(X_tests)\n",
    "    \n",
    "loss, accuracy = model4.evaluate(X_tests, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 3.0558 - accuracy: 0.9434 - val_loss: 2.5001 - val_accuracy: 0.9740 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1547 - accuracy: 0.9749 - val_loss: 1.8286 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6005 - accuracy: 0.9765 - val_loss: 1.3778 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2254 - accuracy: 0.9774 - val_loss: 1.0722 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.9624 - accuracy: 0.9777 - val_loss: 0.8565 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.7797 - accuracy: 0.9779 - val_loss: 0.7039 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.9775 - val_loss: 0.5846 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.9775 - val_loss: 0.4971 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.9785 - val_loss: 0.4253 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.9776 - val_loss: 0.3685 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.9771 - val_loss: 0.3361 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.3171 - accuracy: 0.9782 - val_loss: 0.3034 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.9777 - val_loss: 0.2812 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9783 - val_loss: 0.2495 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.2356 - accuracy: 0.9770 - val_loss: 0.2216 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9772 - val_loss: 0.2064 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9794 - val_loss: 0.1978 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 0.1893 - accuracy: 0.9780 - val_loss: 0.1768 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9776 - val_loss: 0.1743 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9793 - val_loss: 0.1658 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9788 - val_loss: 0.1603 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9778 - val_loss: 0.1435 - val_accuracy: 0.9785 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9779 - val_loss: 0.1474 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1388 - accuracy: 0.9785 - val_loss: 0.1288 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1319 - accuracy: 0.9786 - val_loss: 0.1283 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1258 - accuracy: 0.9780 - val_loss: 0.1208 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9775 - val_loss: 0.1149 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.9789 - val_loss: 0.1175 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1160 - accuracy: 0.9787 - val_loss: 0.1194 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1138 - accuracy: 0.9780 - val_loss: 0.1113 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9784 - val_loss: 0.1072 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.9786 - val_loss: 0.1148 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9787 - val_loss: 0.1048 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9785 - val_loss: 0.1038 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9792 - val_loss: 0.0994 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9780 - val_loss: 0.0996 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9794 - val_loss: 0.1017 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9782 - val_loss: 0.0932 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9782 - val_loss: 0.0954 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9786 - val_loss: 0.0934 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9793 - val_loss: 0.0923 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9790 - val_loss: 0.1086 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9786 - val_loss: 0.0942 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9798 - val_loss: 0.0939 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9804 - val_loss: 0.0929 - val_accuracy: 0.9785 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9793 - val_loss: 0.0958 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9794 - val_loss: 0.0920 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9796 - val_loss: 0.0924 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9790 - val_loss: 0.1005 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9798 - val_loss: 0.0906 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9806 - val_loss: 0.0886 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.9802 - val_loss: 0.0878 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9802 - val_loss: 0.0905 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9793 - val_loss: 0.0915 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9793 - val_loss: 0.0895 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9797 - val_loss: 0.0915 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.9800 - val_loss: 0.0902 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9794 - val_loss: 0.0889 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.9805 - val_loss: 0.0886 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9794 - val_loss: 0.0941 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9799 - val_loss: 0.0874 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9801 - val_loss: 0.0926 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0835 - accuracy: 0.9795 - val_loss: 0.0881 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9797 - val_loss: 0.0924 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9800 - val_loss: 0.0882 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.9807 - val_loss: 0.0880 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.9797 - val_loss: 0.0909 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0835 - accuracy: 0.9797 - val_loss: 0.0887 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9795 - val_loss: 0.0883 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9809 - val_loss: 0.0921 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0824 - accuracy: 0.9796 - val_loss: 0.0882 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9800 - val_loss: 0.0885 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9801 - val_loss: 0.0882 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9806 - val_loss: 0.0917 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9807 - val_loss: 0.0890 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.9807 - val_loss: 0.0919 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9804 - val_loss: 0.0870 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9811 - val_loss: 0.0863 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9806 - val_loss: 0.0873 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9803 - val_loss: 0.0863 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9798 - val_loss: 0.0853 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9804 - val_loss: 0.0881 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9804 - val_loss: 0.0874 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9793 - val_loss: 0.0883 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.9807 - val_loss: 0.0901 - val_accuracy: 0.9813 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9804 - val_loss: 0.0882 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9803 - val_loss: 0.0889 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9799 - val_loss: 0.0878 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9814 - val_loss: 0.0854 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9791 - val_loss: 0.0863 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9814 - val_loss: 0.0878 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9804 - val_loss: 0.0877 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0786 - accuracy: 0.9800 - val_loss: 0.0877 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9809 - val_loss: 0.0878 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9805 - val_loss: 0.0857 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9802 - val_loss: 0.0873 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9802 - val_loss: 0.0895 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9811 - val_loss: 0.0933 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9804 - val_loss: 0.0876 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9806 - val_loss: 0.0882 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0789 - accuracy: 0.9801 - val_loss: 0.0887 - val_accuracy: 0.9785 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9802 - val_loss: 0.0858 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9795 - val_loss: 0.0853 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9807 - val_loss: 0.0867 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9804 - val_loss: 0.0848 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9805 - val_loss: 0.0871 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9800 - val_loss: 0.0899 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9809 - val_loss: 0.0871 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9805 - val_loss: 0.0848 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9815 - val_loss: 0.0869 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9802 - val_loss: 0.0868 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9802 - val_loss: 0.0863 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0786 - accuracy: 0.9807 - val_loss: 0.0889 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9815 - val_loss: 0.0879 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9801 - val_loss: 0.0863 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9818 - val_loss: 0.0882 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9804 - val_loss: 0.0846 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9800 - val_loss: 0.0852 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9815 - val_loss: 0.0872 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9799 - val_loss: 0.0881 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9807 - val_loss: 0.0850 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0786 - accuracy: 0.9807 - val_loss: 0.0868 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9808 - val_loss: 0.0856 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9801 - val_loss: 0.0857 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9807 - val_loss: 0.0881 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9813 - val_loss: 0.0877 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9809 - val_loss: 0.0849 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.9809 - val_loss: 0.0843 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9806 - val_loss: 0.0874 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0776 - accuracy: 0.9807 - val_loss: 0.0859 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9800 - val_loss: 0.0858 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9811 - val_loss: 0.0864 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9814 - val_loss: 0.0845 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9803 - val_loss: 0.0861 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9819 - val_loss: 0.0856 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9812 - val_loss: 0.0840 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9807 - val_loss: 0.0872 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9811 - val_loss: 0.0868 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9802 - val_loss: 0.0852 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9804 - val_loss: 0.0889 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.9809 - val_loss: 0.0841 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0776 - accuracy: 0.9807 - val_loss: 0.0865 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9808 - val_loss: 0.0844 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9814 - val_loss: 0.0842 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9797 - val_loss: 0.0838 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9807 - val_loss: 0.0846 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9804 - val_loss: 0.0850 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9800 - val_loss: 0.0834 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9803 - val_loss: 0.0870 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9809 - val_loss: 0.0875 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9812 - val_loss: 0.0843 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9806 - val_loss: 0.0894 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9812 - val_loss: 0.0865 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9807 - val_loss: 0.0844 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9809 - val_loss: 0.0858 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9821 - val_loss: 0.0839 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 0.0857 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9816 - val_loss: 0.0850 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9811 - val_loss: 0.0849 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9814 - val_loss: 0.0861 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.0748 - accuracy: 0.9820 - val_loss: 0.0875 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9800 - val_loss: 0.0845 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9806 - val_loss: 0.0850 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.9809 - val_loss: 0.0876 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9815 - val_loss: 0.0904 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9803 - val_loss: 0.0889 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 168/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9808 - val_loss: 0.0855 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9807 - val_loss: 0.0868 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9814 - val_loss: 0.0875 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9802 - val_loss: 0.0879 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9811 - val_loss: 0.0870 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9807 - val_loss: 0.0872 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9814 - val_loss: 0.0853 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9809 - val_loss: 0.0844 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9800 - val_loss: 0.0875 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9806 - val_loss: 0.0886 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9814 - val_loss: 0.0849 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9817 - val_loss: 0.0844 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9815 - val_loss: 0.0845 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9812 - val_loss: 0.0857 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9823 - val_loss: 0.0865 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.9815 - val_loss: 0.0894 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9814 - val_loss: 0.0852 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9807 - val_loss: 0.0869 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0749 - accuracy: 0.9809 - val_loss: 0.0853 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9811 - val_loss: 0.0866 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9811 - val_loss: 0.0824 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 190/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9812 - val_loss: 0.0821 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 191/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9814 - val_loss: 0.0814 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 192/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9825 - val_loss: 0.0816 - val_accuracy: 0.9807 - lr: 2.0000e-04\n",
      "Epoch 193/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9819 - val_loss: 0.0821 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 194/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0828 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 195/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.0816 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 196/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9823 - val_loss: 0.0813 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 197/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9821 - val_loss: 0.0821 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 198/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9813 - val_loss: 0.0813 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 199/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9818 - val_loss: 0.0821 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 200/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9819 - val_loss: 0.0812 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 201/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9818 - val_loss: 0.0814 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 202/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9819 - val_loss: 0.0814 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 203/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9824 - val_loss: 0.0808 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 204/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9820 - val_loss: 0.0810 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 205/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9811 - val_loss: 0.0805 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 206/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 207/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9824 - val_loss: 0.0826 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 208/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9814 - val_loss: 0.0826 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 209/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9820 - val_loss: 0.0817 - val_accuracy: 0.9807 - lr: 2.0000e-04\n",
      "Epoch 210/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9823 - val_loss: 0.0808 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 211/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9820 - val_loss: 0.0809 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 212/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9823 - val_loss: 0.0819 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 213/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.0818 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 214/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9818 - val_loss: 0.0811 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 215/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9818 - val_loss: 0.0813 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 216/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9813 - val_loss: 0.0826 - val_accuracy: 0.9807 - lr: 2.0000e-04\n",
      "Epoch 217/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9825 - val_loss: 0.0827 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 218/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9820 - val_loss: 0.0819 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 219/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9817 - val_loss: 0.0822 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 220/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0824 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 221/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0819 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 222/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0816 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 223/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9821 - val_loss: 0.0815 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 224/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 0.0822 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 225/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9819 - val_loss: 0.0814 - val_accuracy: 0.9804 - lr: 2.0000e-04\n",
      "Epoch 226/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9823 - val_loss: 0.0813 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 227/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9827 - val_loss: 0.0815 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 228/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0819 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 229/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9834 - val_loss: 0.0819 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 230/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9821 - val_loss: 0.0813 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 231/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9827 - val_loss: 0.0823 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 232/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.0816 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 233/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9823 - val_loss: 0.0826 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 234/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.0826 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 235/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9824 - val_loss: 0.0813 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 236/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0823 - val_accuracy: 0.9785 - lr: 2.0000e-04\n",
      "Epoch 237/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9823 - val_loss: 0.0821 - val_accuracy: 0.9796 - lr: 2.0000e-04\n",
      "Epoch 238/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.0811 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 239/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 240/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9810 - val_loss: 0.0823 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 241/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.0813 - val_accuracy: 0.9799 - lr: 2.0000e-04\n",
      "Epoch 242/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9822 - val_loss: 0.0830 - val_accuracy: 0.9793 - lr: 2.0000e-04\n",
      "Epoch 243/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 0.0819 - val_accuracy: 0.9791 - lr: 2.0000e-04\n",
      "Epoch 244/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9817 - val_loss: 0.0816 - val_accuracy: 0.9807 - lr: 2.0000e-04\n",
      "Epoch 245/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9802 - lr: 2.0000e-04\n",
      "Epoch 246/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9827 - val_loss: 0.0803 - val_accuracy: 0.9807 - lr: 4.0000e-05\n",
      "Epoch 247/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 248/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9791 - lr: 4.0000e-05\n",
      "Epoch 249/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9821 - val_loss: 0.0806 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 250/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 251/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9814 - val_loss: 0.0809 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 252/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9823 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 253/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9822 - val_loss: 0.0805 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 254/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9820 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 255/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9823 - val_loss: 0.0806 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 256/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9830 - val_loss: 0.0808 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 257/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9816 - val_loss: 0.0806 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 258/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9821 - val_loss: 0.0808 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 259/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9824 - val_loss: 0.0807 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 260/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9818 - val_loss: 0.0807 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 261/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0810 - val_accuracy: 0.9791 - lr: 4.0000e-05\n",
      "Epoch 262/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.0810 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 263/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9823 - val_loss: 0.0811 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 264/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9826 - val_loss: 0.0810 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 265/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0808 - val_accuracy: 0.9788 - lr: 4.0000e-05\n",
      "Epoch 266/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9818 - val_loss: 0.0808 - val_accuracy: 0.9791 - lr: 4.0000e-05\n",
      "Epoch 267/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9833 - val_loss: 0.0808 - val_accuracy: 0.9791 - lr: 4.0000e-05\n",
      "Epoch 268/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9823 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 269/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9819 - val_loss: 0.0805 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 270/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9821 - val_loss: 0.0807 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 271/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9826 - val_loss: 0.0813 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 272/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9823 - val_loss: 0.0805 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 273/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9824 - val_loss: 0.0810 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 274/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9823 - val_loss: 0.0814 - val_accuracy: 0.9802 - lr: 4.0000e-05\n",
      "Epoch 275/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9827 - val_loss: 0.0815 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 276/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9838 - val_loss: 0.0808 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 277/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.0811 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 278/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9821 - val_loss: 0.0812 - val_accuracy: 0.9796 - lr: 4.0000e-05\n",
      "Epoch 279/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0812 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 280/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9832 - val_loss: 0.0809 - val_accuracy: 0.9802 - lr: 4.0000e-05\n",
      "Epoch 281/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 0.0809 - val_accuracy: 0.9791 - lr: 4.0000e-05\n",
      "Epoch 282/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9823 - val_loss: 0.0813 - val_accuracy: 0.9793 - lr: 4.0000e-05\n",
      "Epoch 283/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 284/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9824 - val_loss: 0.0812 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 285/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9830 - val_loss: 0.0808 - val_accuracy: 0.9802 - lr: 4.0000e-05\n",
      "Epoch 286/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9827 - val_loss: 0.0808 - val_accuracy: 0.9799 - lr: 4.0000e-05\n",
      "Epoch 287/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 0.0808 - val_accuracy: 0.9802 - lr: 8.0000e-06\n",
      "Epoch 288/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9832 - val_loss: 0.0809 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 289/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9825 - val_loss: 0.0811 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 290/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9824 - val_loss: 0.0808 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 291/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9821 - val_loss: 0.0807 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 292/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9827 - val_loss: 0.0805 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 293/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9824 - val_loss: 0.0804 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 294/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9823 - val_loss: 0.0806 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 295/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.0807 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 296/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0803 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 297/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9827 - val_loss: 0.0808 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 298/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9830 - val_loss: 0.0807 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 299/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9827 - val_loss: 0.0806 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 300/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 0.0806 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 301/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9827 - val_loss: 0.0812 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 302/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 0.0809 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 303/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0808 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 304/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9823 - val_loss: 0.0806 - val_accuracy: 0.9788 - lr: 8.0000e-06\n",
      "Epoch 305/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0810 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 306/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9821 - val_loss: 0.0811 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 307/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9827 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 308/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9821 - val_loss: 0.0806 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 309/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9826 - val_loss: 0.0809 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 310/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9825 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 311/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9832 - val_loss: 0.0809 - val_accuracy: 0.9799 - lr: 8.0000e-06\n",
      "Epoch 312/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9824 - val_loss: 0.0811 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 313/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9830 - val_loss: 0.0810 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 314/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9824 - val_loss: 0.0809 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 315/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9830 - val_loss: 0.0807 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 316/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9834 - val_loss: 0.0812 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 317/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9827 - val_loss: 0.0811 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 318/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9830 - val_loss: 0.0809 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 319/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 0.0812 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 320/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9824 - val_loss: 0.0808 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 321/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9822 - val_loss: 0.0807 - val_accuracy: 0.9796 - lr: 8.0000e-06\n",
      "Epoch 322/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9827 - val_loss: 0.0808 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 323/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9827 - val_loss: 0.0812 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 324/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9824 - val_loss: 0.0811 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 325/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.0812 - val_accuracy: 0.9791 - lr: 8.0000e-06\n",
      "Epoch 326/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 8.0000e-06\n",
      "Epoch 327/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9827 - val_loss: 0.0812 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 328/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.0809 - val_accuracy: 0.9793 - lr: 1.6000e-06\n",
      "Epoch 329/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9823 - val_loss: 0.0814 - val_accuracy: 0.9788 - lr: 1.6000e-06\n",
      "Epoch 330/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9829 - val_loss: 0.0813 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 331/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0812 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 332/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.0810 - val_accuracy: 0.9788 - lr: 1.6000e-06\n",
      "Epoch 333/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9827 - val_loss: 0.0813 - val_accuracy: 0.9788 - lr: 1.6000e-06\n",
      "Epoch 334/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9827 - val_loss: 0.0813 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 335/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 0.0811 - val_accuracy: 0.9793 - lr: 1.6000e-06\n",
      "Epoch 336/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.0810 - val_accuracy: 0.9788 - lr: 1.6000e-06\n",
      "Epoch 337/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9825 - val_loss: 0.0809 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 338/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9827 - val_loss: 0.0810 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 339/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0808 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 340/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9830 - val_loss: 0.0813 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 341/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9825 - val_loss: 0.0811 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 342/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9822 - val_loss: 0.0807 - val_accuracy: 0.9793 - lr: 1.6000e-06\n",
      "Epoch 343/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 0.0813 - val_accuracy: 0.9793 - lr: 1.6000e-06\n",
      "Epoch 344/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9824 - val_loss: 0.0806 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 345/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.0810 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "Epoch 346/500\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0810 - val_accuracy: 0.9791 - lr: 1.6000e-06\n",
      "112/112 [==============================] - 0s 661us/step\n",
      "Accuracy: 0.9790502786636353\n",
      " MSE: 0.08102613687515259\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),  # Dropout 추가\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),  # Dropout 추가\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1/L2 정규화 추가\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model4.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='val_loss', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model4.fit(X_trains, y_train, epochs=500, batch_size=32, verbose=1, \n",
    "          validation_data=(X_tests, y_test), callbacks=[es, rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model4.predict(X_tests)\n",
    "    \n",
    "loss, accuracy = model4.evaluate(X_tests, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy}\\n MSE: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1432/1432 [==============================] - 7s 3ms/step - loss: 5.0973 - accuracy: 0.9544 - val_loss: 2.3414 - val_accuracy: 0.9712 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 1.5394 - accuracy: 0.9742 - val_loss: 1.1034 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.8465 - accuracy: 0.9740 - val_loss: 0.6698 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.5799 - accuracy: 0.9721 - val_loss: 0.4904 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.4340 - accuracy: 0.9738 - val_loss: 0.3823 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.3392 - accuracy: 0.9749 - val_loss: 0.3120 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.2795 - accuracy: 0.9757 - val_loss: 0.2689 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.2317 - accuracy: 0.9770 - val_loss: 0.2013 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.2067 - accuracy: 0.9768 - val_loss: 0.2120 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1837 - accuracy: 0.9770 - val_loss: 0.1764 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1689 - accuracy: 0.9772 - val_loss: 0.1672 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9769 - val_loss: 0.1625 - val_accuracy: 0.9735 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9772 - val_loss: 0.1710 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9772 - val_loss: 0.1601 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1373 - accuracy: 0.9778 - val_loss: 0.1322 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1330 - accuracy: 0.9765 - val_loss: 0.1259 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1240 - accuracy: 0.9786 - val_loss: 0.1440 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9781 - val_loss: 0.1218 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1189 - accuracy: 0.9778 - val_loss: 0.1079 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9772 - val_loss: 0.1049 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1121 - accuracy: 0.9786 - val_loss: 0.1123 - val_accuracy: 0.9746 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9781 - val_loss: 0.1191 - val_accuracy: 0.9746 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1086 - accuracy: 0.9791 - val_loss: 0.1331 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1094 - accuracy: 0.9783 - val_loss: 0.0989 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1080 - accuracy: 0.9788 - val_loss: 0.1063 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1041 - accuracy: 0.9788 - val_loss: 0.1341 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1033 - accuracy: 0.9780 - val_loss: 0.1017 - val_accuracy: 0.9785 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1052 - accuracy: 0.9785 - val_loss: 0.1011 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1001 - accuracy: 0.9783 - val_loss: 0.1114 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0994 - accuracy: 0.9784 - val_loss: 0.1008 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0999 - accuracy: 0.9781 - val_loss: 0.1021 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0996 - accuracy: 0.9789 - val_loss: 0.1167 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1023 - accuracy: 0.9788 - val_loss: 0.0932 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0975 - accuracy: 0.9794 - val_loss: 0.0963 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0948 - accuracy: 0.9792 - val_loss: 0.1047 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1432/1432 [==============================] - 6s 4ms/step - loss: 0.0958 - accuracy: 0.9789 - val_loss: 0.0968 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.1012 - accuracy: 0.9797 - val_loss: 0.1021 - val_accuracy: 0.9763 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.0946 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0937 - accuracy: 0.9794 - val_loss: 0.1118 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0960 - accuracy: 0.9787 - val_loss: 0.0979 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.0913 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0928 - accuracy: 0.9797 - val_loss: 0.0973 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0944 - accuracy: 0.9803 - val_loss: 0.0930 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.0890 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0938 - accuracy: 0.9804 - val_loss: 0.0999 - val_accuracy: 0.9754 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0914 - accuracy: 0.9787 - val_loss: 0.0939 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0957 - accuracy: 0.9790 - val_loss: 0.0915 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0935 - accuracy: 0.9790 - val_loss: 0.1032 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0936 - accuracy: 0.9788 - val_loss: 0.1116 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0936 - accuracy: 0.9795 - val_loss: 0.0918 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0913 - accuracy: 0.9791 - val_loss: 0.0978 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0941 - accuracy: 0.9789 - val_loss: 0.0994 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0930 - accuracy: 0.9793 - val_loss: 0.0989 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0924 - accuracy: 0.9786 - val_loss: 0.0895 - val_accuracy: 0.9813 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0924 - accuracy: 0.9800 - val_loss: 0.0872 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9800 - val_loss: 0.0955 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0929 - accuracy: 0.9789 - val_loss: 0.1157 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0922 - accuracy: 0.9803 - val_loss: 0.1051 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0919 - accuracy: 0.9796 - val_loss: 0.1110 - val_accuracy: 0.9757 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0923 - accuracy: 0.9790 - val_loss: 0.1171 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0942 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0934 - accuracy: 0.9786 - val_loss: 0.4254 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0924 - accuracy: 0.9790 - val_loss: 0.0925 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0929 - accuracy: 0.9790 - val_loss: 0.1001 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0923 - accuracy: 0.9788 - val_loss: 0.0889 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0914 - accuracy: 0.9807 - val_loss: 0.0966 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0930 - accuracy: 0.9790 - val_loss: 0.0856 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0888 - accuracy: 0.9791 - val_loss: 0.0893 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0934 - accuracy: 0.9800 - val_loss: 0.0901 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0904 - accuracy: 0.9793 - val_loss: 0.0933 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0921 - accuracy: 0.9796 - val_loss: 0.0946 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0888 - accuracy: 0.9800 - val_loss: 0.0972 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0918 - accuracy: 0.9797 - val_loss: 0.0934 - val_accuracy: 0.9785 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0923 - accuracy: 0.9795 - val_loss: 0.0948 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0903 - accuracy: 0.9801 - val_loss: 0.1020 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0925 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0905 - accuracy: 0.9801 - val_loss: 0.0927 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0908 - accuracy: 0.9795 - val_loss: 0.0918 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0877 - accuracy: 0.9796 - val_loss: 0.1024 - val_accuracy: 0.9791 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0920 - accuracy: 0.9802 - val_loss: 0.0935 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0894 - accuracy: 0.9799 - val_loss: 0.0982 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0917 - accuracy: 0.9790 - val_loss: 0.0957 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0914 - accuracy: 0.9800 - val_loss: 0.0945 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0916 - accuracy: 0.9790 - val_loss: 0.0941 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0912 - accuracy: 0.9799 - val_loss: 0.0896 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0922 - accuracy: 0.9794 - val_loss: 0.0988 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0889 - accuracy: 0.9790 - val_loss: 0.0986 - val_accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0925 - accuracy: 0.9790 - val_loss: 0.0894 - val_accuracy: 0.9816 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0904 - accuracy: 0.9797 - val_loss: 0.0927 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0924 - accuracy: 0.9795 - val_loss: 0.0962 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0905 - accuracy: 0.9794 - val_loss: 0.0956 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "1432/1432 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9794 - val_loss: 0.1010 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0908 - accuracy: 0.9796 - val_loss: 0.0915 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0884 - accuracy: 0.9800 - val_loss: 0.1002 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0898 - accuracy: 0.9792 - val_loss: 0.0924 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0901 - accuracy: 0.9798 - val_loss: 0.0905 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0897 - accuracy: 0.9800 - val_loss: 0.0918 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0906 - accuracy: 0.9791 - val_loss: 0.0906 - val_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0919 - accuracy: 0.9795 - val_loss: 0.0943 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "1432/1432 [==============================] - 4s 3ms/step - loss: 0.0914 - accuracy: 0.9809 - val_loss: 0.1034 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "112/112 [==============================] - 0s 946us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_tests)\n\u001b[1;32m     38\u001b[0m y_pred_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(y_pred)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred_classes)\n\u001b[1;32m     40\u001b[0m loss \u001b[39m=\u001b[39m log_loss(y_test, y_pred)\n\u001b[1;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mLog Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='LeakyReLU', input_shape=(X_trains.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(256, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(128, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(64, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(32, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(16, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  # L1, L2 정규화 적용\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.001),  # 드롭아웃 추가\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "rlrp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=40, mode='min')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_trains, y_train, epochs=100, batch_size=10, verbose=1, \n",
    "          validation_data=(X_tests, y_test), callbacks=[rlrp])\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_tests)\n",
    "y_pred_classes = np.round(y_pred).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\nLog Loss: {loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
